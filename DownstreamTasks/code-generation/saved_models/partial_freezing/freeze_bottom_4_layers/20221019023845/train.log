10/19/2022 02:38:53 - INFO - __main__ -   device: cuda, n_gpu: 1
10/19/2022 02:38:55 - DEBUG - filelock -   Attempting to acquire lock 140067875362368 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:38:55 - DEBUG - filelock -   Lock 140067875362368 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   4%|▍         | 40.0k/916k [00:00<00:02, 404kB/s]Downloading:  18%|█▊        | 169k/916k [00:00<00:00, 919kB/s] Downloading:  76%|███████▌  | 697k/916k [00:00<00:00, 2.89MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 3.00MB/s]
10/19/2022 02:38:55 - DEBUG - filelock -   Attempting to release lock 140067875362368 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:38:55 - DEBUG - filelock -   Lock 140067875362368 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:38:56 - DEBUG - filelock -   Attempting to acquire lock 140067873554096 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:38:56 - DEBUG - filelock -   Lock 140067873554096 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:   6%|▋         | 28.0k/434k [00:00<00:01, 279kB/s]Downloading:  41%|████▏     | 180k/434k [00:00<00:00, 1.00MB/s]Downloading: 100%|██████████| 434k/434k [00:00<00:00, 1.71MB/s]
10/19/2022 02:38:56 - DEBUG - filelock -   Attempting to release lock 140067873554096 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:38:56 - DEBUG - filelock -   Lock 140067873554096 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Attempting to acquire lock 140067873601424 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Lock 140067873601424 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 563kB/s]
10/19/2022 02:38:57 - DEBUG - filelock -   Attempting to release lock 140067873601424 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Lock 140067873601424 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Attempting to acquire lock 140067875361696 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Lock 140067875361696 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 1.00MB/s]
10/19/2022 02:38:57 - DEBUG - filelock -   Attempting to release lock 140067875361696 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:38:57 - DEBUG - filelock -   Lock 140067875361696 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:38:58 - DEBUG - filelock -   Attempting to acquire lock 140067873554240 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:38:58 - DEBUG - filelock -   Lock 140067873554240 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 441kB/s]
10/19/2022 02:38:58 - DEBUG - filelock -   Attempting to release lock 140067873554240 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:38:58 - DEBUG - filelock -   Lock 140067873554240 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:38:59 - DEBUG - filelock -   Attempting to acquire lock 140067772392592 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:38:59 - DEBUG - filelock -   Lock 140067772392592 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   1%|          | 5.16M/480M [00:00<00:09, 54.1MB/s]Downloading:   3%|▎         | 15.1M/480M [00:00<00:05, 83.3MB/s]Downloading:   5%|▍         | 23.6M/480M [00:00<00:05, 86.2MB/s]Downloading:   7%|▋         | 31.8M/480M [00:00<00:06, 73.4MB/s]Downloading:   8%|▊         | 39.9M/480M [00:00<00:05, 77.0MB/s]Downloading:  10%|▉         | 47.4M/480M [00:00<00:05, 77.5MB/s]Downloading:  12%|█▏        | 56.3M/480M [00:00<00:05, 82.2MB/s]Downloading:  13%|█▎        | 64.4M/480M [00:00<00:05, 83.1MB/s]Downloading:  15%|█▌        | 72.4M/480M [00:00<00:05, 82.0MB/s]Downloading:  17%|█▋        | 80.2M/480M [00:01<00:05, 79.7MB/s]Downloading:  18%|█▊        | 87.9M/480M [00:01<00:05, 69.1MB/s]Downloading:  20%|█▉        | 94.7M/480M [00:01<00:06, 64.4MB/s]Downloading:  22%|██▏       | 105M/480M [00:01<00:05, 74.7MB/s] Downloading:  24%|██▎       | 113M/480M [00:01<00:04, 79.2MB/s]Downloading:  25%|██▌       | 122M/480M [00:01<00:04, 80.0MB/s]Downloading:  27%|██▋       | 129M/480M [00:01<00:04, 80.1MB/s]Downloading:  29%|██▊       | 138M/480M [00:01<00:04, 82.2MB/s]Downloading:  30%|███       | 146M/480M [00:01<00:04, 82.1MB/s]Downloading:  32%|███▏      | 154M/480M [00:02<00:04, 71.3MB/s]Downloading:  34%|███▎      | 161M/480M [00:02<00:04, 74.3MB/s]Downloading:  35%|███▌      | 170M/480M [00:02<00:04, 77.5MB/s]Downloading:  37%|███▋      | 178M/480M [00:02<00:03, 80.3MB/s]Downloading:  39%|███▊      | 186M/480M [00:02<00:03, 80.7MB/s]Downloading:  40%|████      | 194M/480M [00:02<00:03, 78.2MB/s]Downloading:  42%|████▏     | 201M/480M [00:02<00:04, 73.1MB/s]Downloading:  44%|████▎     | 209M/480M [00:02<00:03, 76.9MB/s]Downloading:  45%|████▌     | 218M/480M [00:02<00:03, 80.6MB/s]Downloading:  47%|████▋     | 226M/480M [00:03<00:03, 82.2MB/s]Downloading:  49%|████▊     | 234M/480M [00:03<00:03, 82.2MB/s]Downloading:  50%|█████     | 242M/480M [00:03<00:02, 83.7MB/s]Downloading:  52%|█████▏    | 251M/480M [00:03<00:02, 85.1MB/s]Downloading:  54%|█████▍    | 260M/480M [00:03<00:02, 87.3MB/s]Downloading:  56%|█████▌    | 268M/480M [00:03<00:02, 85.3MB/s]Downloading:  58%|█████▊    | 276M/480M [00:03<00:02, 83.2MB/s]Downloading:  59%|█████▉    | 284M/480M [00:03<00:02, 80.2MB/s]Downloading:  61%|██████    | 292M/480M [00:03<00:02, 80.7MB/s]Downloading:  63%|██████▎   | 300M/480M [00:03<00:02, 82.6MB/s]Downloading:  64%|██████▍   | 309M/480M [00:04<00:02, 84.2MB/s]Downloading:  66%|██████▌   | 317M/480M [00:04<00:02, 84.1MB/s]Downloading:  68%|██████▊   | 325M/480M [00:04<00:01, 85.0MB/s]Downloading:  70%|██████▉   | 334M/480M [00:04<00:01, 87.5MB/s]Downloading:  71%|███████▏  | 342M/480M [00:04<00:01, 84.3MB/s]Downloading:  73%|███████▎  | 351M/480M [00:04<00:01, 79.0MB/s]Downloading:  75%|███████▍  | 359M/480M [00:04<00:01, 82.2MB/s]Downloading:  76%|███████▋  | 367M/480M [00:04<00:01, 77.4MB/s]Downloading:  78%|███████▊  | 375M/480M [00:04<00:01, 80.0MB/s]Downloading:  80%|███████▉  | 384M/480M [00:05<00:01, 83.1MB/s]Downloading:  82%|████████▏ | 392M/480M [00:05<00:01, 83.5MB/s]Downloading:  83%|████████▎ | 400M/480M [00:05<00:01, 79.0MB/s]Downloading:  85%|████████▌ | 408M/480M [00:05<00:00, 81.4MB/s]Downloading:  87%|████████▋ | 417M/480M [00:05<00:00, 82.7MB/s]Downloading:  88%|████████▊ | 425M/480M [00:05<00:00, 84.0MB/s]Downloading:  90%|█████████ | 433M/480M [00:05<00:00, 83.7MB/s]Downloading:  92%|█████████▏| 441M/480M [00:05<00:00, 84.3MB/s]Downloading:  94%|█████████▎| 449M/480M [00:05<00:00, 78.1MB/s]Downloading:  95%|█████████▌| 457M/480M [00:05<00:00, 78.8MB/s]Downloading:  97%|█████████▋| 466M/480M [00:06<00:00, 82.6MB/s]Downloading:  99%|█████████▊| 474M/480M [00:06<00:00, 82.1MB/s]Downloading: 100%|██████████| 480M/480M [00:06<00:00, 80.4MB/s]
10/19/2022 02:39:05 - DEBUG - filelock -   Attempting to release lock 140067772392592 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:39:05 - DEBUG - filelock -   Lock 140067772392592 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:39:12 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, beam_size=3, debug=False, dev_filename='dataset/new/dev.json', device=device(type='cuda'), do_eval=True, do_test=True, do_train=True, eval_batch_size=32, freeze_bottom_k_layer_index=4, gradient_accumulation_steps=1, learning_rate=5e-05, max_grad_norm=1.0, max_source_length=350, max_target_length=150, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, no_cuda=False, num_train_epochs=30, output_dir='saved_models/code-gen/unixcoder/partial_freezing/freeze_bottom_4_layers/20221019023845', seed=123456, test_filename='dataset/new/test.json', train_batch_size=32, train_filename='dataset/train.json', weight_decay=0.0)
10/19/2022 02:39:12 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.4.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.4.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.4.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.4.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.4.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.4.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.4.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.4.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.4.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.5.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.5.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.5.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.5.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.5.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.5.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.6.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.6.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.6.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.6.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.7.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.7.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.7.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.7.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
| dense.weight                                               |   [768, 768] |  589824 |
| dense.bias                                                 |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/19/2022 02:39:12 - INFO - __main__ -   The model has 57884160 trainable parameters
10/19/2022 02:39:15 - INFO - __main__ -   *** Example ***
10/19/2022 02:39:15 - INFO - __main__ -   idx: 0
10/19/2022 02:39:15 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', 'check', '_if', '_details', '_are', '_parsed', '_.', '_con', 'code', '_', 'field', '_', 'sep', '_Container', '_parent', '_con', 'code', '_', 'elem', '_', 'sep', '_boolean', '_is', 'Parsed', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_offset', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_content', 'StartPosition', '_con', 'code', '_', 'elem', '_', 'sep', '_ByteBuffer', '_dead', 'Bytes', '_con', 'code', '_', 'elem', '_', 'sep', '_boolean', '_is', 'Read', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_mem', 'Map', 'Size', '_con', 'code', '_', 'elem', '_', 'sep', '_Logger', '_LOG', '_con', 'code', '_', 'elem', '_', 'sep', '_byte', '[]', '_user', 'Type', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_type', '_con', 'code', '_', 'elem', '_', 'sep', '_ByteBuffer', '_content', '_con', 'code', '_', 'elem', '_', 'sep', '_File', 'Channel', '_file', 'Channel', '_con', 'code', '_', 'field', '_', 'sep', '_Container', '_getParent', '_con', 'code', '_', 'elem', '_', 'sep', '_byte', '[]', '_getUser', 'Type', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_read', 'Content', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_get', 'Offset', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_getContent', 'Size', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_getContent', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'Dead', 'Bytes', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_parse', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_get', 'Header', '_con', 'code', '_', 'elem', '_', 'sep', '_long', '_getSize', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_parse', 'Details', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_getType', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '__', 'parse', 'Details', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_getPath', '_con', 'code', '_', 'elem', '_', 'sep', '_boolean', '_verify', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'Parent', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_get', 'Box', '_con', 'code', '_', 'elem', '_', 'sep', '_boolean', '_is', 'Small', 'Box', '<mask0>', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   source_ids: 0 5 2 1471 462 6768 1147 5654 746 549 780 181 1372 181 7421 10976 2201 549 780 181 4641 181 7421 2116 555 13885 549 780 181 4641 181 7421 1534 1805 549 780 181 4641 181 7421 1534 2264 31713 549 780 181 4641 181 7421 16980 10168 2240 549 780 181 4641 181 7421 2116 555 1616 549 780 181 4641 181 7421 1534 1835 1281 939 549 780 181 4641 181 7421 10641 5610 549 780 181 4641 181 7421 2134 1039 1695 641 549 780 181 4641 181 7421 1167 889 549 780 181 4641 181 7421 16980 2264 549 780 181 4641 181 7421 2536 3267 1012 3267 549 780 181 1372 181 7421 10976 19354 549 780 181 4641 181 7421 2134 1039 25533 641 549 780 181 4641 181 7421 723 1557 1646 549 780 181 4641 181 7421 1534 744 1884 549 780 181 4641 181 7421 1534 31482 939 549 780 181 4641 181 7421 723 31482 549 780 181 4641 181 7421 723 827 10099 2240 549 780 181 4641 181 7421 723 2467 549 780 181 4641 181 7421 723 744 1764 549 780 181 4641 181 7421 1534 34727 549 780 181 4641 181 7421 723 2467 5173 549 780 181 4641 181 7421 1167 15866 549 780 181 4641 181 7421 723 623 1783 5173 549 780 181 4641 181 7421 1167 33237 549 780 181 4641 181 7421 2116 5864 549 780 181 4641 181 7421 723 827 2645 549 780 181 4641 181 7421 723 744 1903 549 780 181 4641 181 7421 2116 555 8088 1903 19 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   target_tokens: ['<mask0>', 'boolean', '_function', '_(', '_)', '_{', '_return', '_is', 'Parsed', '_;', '_}', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   target_ids: 19 3763 603 400 743 399 483 555 13885 2476 425 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   *** Example ***
10/19/2022 02:39:15 - INFO - __main__ -   idx: 1
10/19/2022 02:39:15 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', 'answer', '_the', '_library', '_file', '_defining', '_the', '_library', '_containing', '_the', '_compilation', '_unit', '_to', '_be', '_indexed', '_or', '_null', '_if', '_the', '_library', '_is', '_not', '_on', '_disk', '_con', 'code', '_', 'field', '_', 'sep', '_Index', 'Store', '_index', 'Store', '_con', 'code', '_', 'elem', '_', 'sep', '_Index', 'Performance', 'Recorder', '_performance', 'Recorder', '_con', 'code', '_', 'elem', '_', 'sep', '_D', 'art', 'Unit', '_unit', '_con', 'code', '_', 'elem', '_', 'sep', '_Compilation', 'Unit', '_compilation', 'Unit', '_con', 'code', '_', 'elem', '_', 'sep', '_Resource', '_resource', '_con', 'code', '_', 'elem', '_', 'sep', '_File', '_library', 'File', '_con', 'code', '_', 'field', '_', 'sep', '_boolean', '_remove', 'When', 'Resource', 'Removed', '_con', 'code', '_', 'elem', '_', 'sep', '_Compilation', 'Unit', '_get', 'CompilationUnit', '_con', 'code', '_', 'elem', '_', 'sep', '_boolean', '_is', 'Query', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_toString', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_perform', 'Operation', '<mask0>', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   source_ids: 0 5 2 7856 448 7971 1012 25118 448 7971 4275 448 16703 5108 508 661 15907 872 700 462 448 7971 555 800 854 8236 549 780 181 1372 181 7421 6257 2767 1442 2767 549 780 181 4641 181 7421 6257 18643 17391 12217 17391 549 780 181 4641 181 7421 614 605 2762 5108 549 780 181 4641 181 7421 43024 2762 16703 2762 549 780 181 4641 181 7421 7606 2377 549 780 181 4641 181 7421 2536 7971 956 549 780 181 1372 181 7421 2116 3033 7422 1755 12070 549 780 181 4641 181 7421 43024 2762 744 36587 549 780 181 4641 181 7421 2116 555 1538 549 780 181 4641 181 7421 1167 14696 549 780 181 4641 181 7421 723 4729 2783 19 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   target_tokens: ['<mask0>', 'File', '_function', '_(', '_)', '_{', '_return', '_library', 'File', '_;', '_}', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   target_ids: 19 956 603 400 743 399 483 7971 956 2476 425 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   *** Example ***
10/19/2022 02:39:15 - INFO - __main__ -   idx: 2
10/19/2022 02:39:15 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', 'this', '_method', '_deletes', '_index', '_files', '_of', '_the', '_@', 'link', 'plain', '_index', 'commit', '_for', '_the', '_specified', '_generation', '_number', '_.', '_con', 'code', '_', 'field', '_', 'sep', '_Logger', '_log', '_con', 'code', '_', 'field', '_', 'sep', '_void', '_delete', 'Non', 'Snapshot', 'Index', 'Files', '_con', 'code', '_', 'elem', '_', 'sep', '_Map', '<', 'String', ',', 'Integer', '>', '_build', 'Ref', 'Counts', '<mask0>', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   source_ids: 0 5 2 490 1454 19028 1442 2966 595 448 890 1378 7687 1442 6140 563 448 2314 13490 1635 746 549 780 181 1372 181 7421 10641 1592 549 780 181 1372 181 7421 723 2821 3579 7597 1052 3765 549 780 181 4641 181 7421 4595 146 684 130 3215 148 3300 1725 13656 19 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   target_tokens: ['<mask0>', 'void', '_function', '_(', '_Directory', '_arg', '0', '_,', '_Collection', '_<', '_Snapshot', 'MetaData', '_>', '_arg', '1', '_,', '_long', '_arg', '2', '_)', '_{', '_List', '_<', '_Index', 'Commit', '_>', '_loc', '0', '_=', '_Directory', 'Reader', '_.', '_list', 'Comm', 'its', '_(', '_arg', '0', '_)', '_;', '_Map', '_<', '_String', '_,', '_Integer', '_>', '_loc', '1', '_=', '_build', 'Ref', 'Counts', '_(', '_arg', '1', '_,', '_loc', '0', '_)', '_;', '_for', '_(', '_Index', 'Commit', '_loc', '2', '_:', '_loc', '0', '_)', '_{', '_if', '_(', '_loc', '2', '_.', '_get', 'Generation', '_(', '_)', '_==', '_arg', '2', '_)', '_{', '_delete', 'Index', 'Files', '_(', '_arg', '0', '_,', '_loc', '1', '_,', '_loc', '2', '_)', '_;', '_break', '_;', '_}', '_}', '_}', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   target_ids: 19 895 603 400 11227 1238 134 2019 7079 517 29055 12247 711 1238 135 2019 1534 1238 136 743 399 2068 517 6257 8455 711 4893 134 385 11227 2692 746 1182 10268 1204 400 1238 134 743 2476 4595 517 1167 2019 5325 711 4893 135 385 3300 1725 13656 400 1238 135 2019 4893 134 743 2476 563 400 6257 8455 4893 136 545 4893 134 743 399 462 400 4893 136 746 744 13446 400 743 550 1238 136 743 399 2821 1052 3765 400 1238 134 2019 4893 135 2019 4893 136 743 2476 1127 2476 425 425 425 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   *** Example ***
10/19/2022 02:39:15 - INFO - __main__ -   idx: 3
10/19/2022 02:39:15 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', 'do', '_n', "'t", '_use', '_this', '_.', '_no', '_,', '_really', '_,', '_do', '_n', "'t", '_use', '_this', '_.', '_you', '_already', '_have', '_an', '_authentication', 'token', '_with', '_org', '.', 'apache', '.', 'accum', 'ulo', '.', 'core', '.', 'client', '.', 'map', 'reduce', '.', 'lib', '.', 'impl', '.', 'configurator', 'base', '_#', 'get', 'authentication', 'token', '_class', '_,', '_configuration', '_.', '_you', '_do', '_n', "'t", '_need', '_to', '_construct', '_it', '_your', 'self', '_.', '_gets', '_the', '_password', '_from', '_the', '_configuration', '_.', '_warning', '_:', '_the', '_password', '_is', '_stored', '_in', '_the', '_configuration', '_and', '_shared', '_with', '_all', '_map', 'reduce', '_tasks', '_;', '_it', '_is', '_base', '64', '_encoded', '_to', '_provide', '_a', '_charset', '_safe', '_conversion', '_to', '_a', '_string', '_,', '_and', '_is', '_not', '_intended', '_to', '_be', '_secure', '_.', '_con', 'code', '_', 'field', '_', 'sep', '_Place', 'Holder', '_place', 'Holder', '_con', 'code', '_', 'field', '_', 'sep', '_String', '_get', 'Principal', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'LogLevel', '_con', 'code', '_', 'elem', '_', 'sep', '_Level', '_get', 'LogLevel', '_con', 'code', '_', 'elem', '_', 'sep', '_Boolean', '_is', 'Connector', 'Info', 'Set', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_getToken', 'Class', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'Z', 'oo', 'Keeper', 'Instance', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'Mock', 'Instance', '_con', 'code', '_', 'elem', '_', 'sep', '_Instance', '_getInstance', '_con', 'code', '_', 'elem', '_', 'sep', '_String', '_enum', 'To', 'Conf', 'Key', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_set', 'Connector', 'Info', '<mask0>', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   source_ids: 0 5 2 1440 416 1340 1393 547 746 1375 2019 9339 2019 1000 416 1340 1393 547 746 2713 2916 1577 817 11367 1363 918 6584 132 10521 132 14938 18976 132 1853 132 1590 132 1051 10137 132 1930 132 5218 132 49243 1118 830 459 16570 1363 1503 2019 4045 746 2713 1000 416 1340 2105 508 8669 835 4862 1733 746 8180 448 5724 1029 448 4045 746 5893 545 448 5724 555 6788 488 448 4045 706 6880 918 1345 1910 10137 10143 2476 835 555 1712 848 7040 508 6634 434 8862 7248 7661 508 434 724 2019 706 555 800 17482 508 661 17880 746 549 780 181 1372 181 7421 15454 8162 5002 8162 549 780 181 1372 181 7421 1167 744 13764 549 780 181 4641 181 7421 723 827 17614 549 780 181 4641 181 7421 11690 744 17614 549 780 181 4641 181 7421 6845 555 12479 986 815 549 780 181 4641 181 7421 1167 39081 1128 549 780 181 4641 181 7421 723 827 176 2799 26456 1562 549 780 181 4641 181 7421 723 827 3002 1562 549 780 181 4641 181 7421 10631 17183 549 780 181 4641 181 7421 1167 4020 687 4579 927 549 780 181 4641 181 7421 723 827 12479 986 19 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   target_tokens: ['<mask0>', 'byte', '_[', '_]', '_function', '_(', '_Class', '_<', '_?', '_>', '_arg', '0', '_,', '_Configuration', '_arg', '1', '_)', '_{', '_return', '_Authentication', 'Token', 'Serializer', '_.', '_serialize', '_(', '_org', '_.', '_a', 'pache', '_.', '_accum', 'ulo', '_.', '_core', '_.', '_client', '_.', '_map', 'reduce', '_.', '_lib', '_.', '_impl', '_.', '_Config', 'urator', 'Base', '_.', '_get', 'Authentication', 'Token', '_(', '_arg', '0', '_,', '_arg', '1', '_)', '_)', '_;', '_}', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   target_ids: 19 1106 626 2406 603 400 4807 517 999 711 1238 134 2019 9337 1238 135 743 399 483 19810 1367 7570 746 11160 400 6584 746 434 23566 746 12027 18976 746 6152 746 2234 746 1910 10137 746 3295 746 12606 746 4555 19726 1737 746 744 9832 1367 400 1238 134 2019 1238 135 743 743 2476 425 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   *** Example ***
10/19/2022 02:39:15 - INFO - __main__ -   idx: 4
10/19/2022 02:39:15 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', 'force', '_the', '_event', 'bus', '_from', '_am', 'bar', 'i', 'event', 'publisher', '_to', '_be', '_serial', 'and', '_synchronous', '_.', '_con', 'code', '_', 'field', '_', 'sep', '_Place', 'Holder', '_place', 'Holder', '_con', 'code', '_', 'field', '_', 'sep', '_void', '_register', 'Alert', 'Listeners', '_con', 'code', '_', 'elem', '_', 'sep', '_Event', 'Bus', '_synchronize', 'Alert', 'Event', 'Publisher', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_replace', 'Event', 'Bus', '_con', 'code', '_', 'elem', '_', 'sep', '_void', '_register', 'Amb', 'ari', 'Listeners', '<mask0>', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   source_ids: 0 5 2 5104 448 1488 3083 1029 4000 1829 191 1357 26072 508 661 9706 501 18791 746 549 780 181 1372 181 7421 15454 8162 5002 8162 549 780 181 1372 181 7421 723 2882 9203 8396 549 780 181 4641 181 7421 3916 7663 35717 9203 1089 17883 549 780 181 4641 181 7421 723 4126 1089 7663 549 780 181 4641 181 7421 723 2882 19443 11215 8396 19 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:39:15 - INFO - __main__ -   target_tokens: ['<mask0>', 'void', '_function', '_(', '_Binder', '_arg', '0', '_)', '_{', '_Event', 'Bus', '_loc', '0', '_=', '_new', '_Event', 'Bus', '_(', '_)', '_;', '_A', 'mb', 'ari', 'Event', 'Publisher', '_loc', '1', '_=', '_new', '_A', 'mb', 'ari', 'Event', 'Publisher', '_(', '_)', '_;', '_replace', 'Event', 'Bus', '_(', '_A', 'mb', 'ari', 'Event', 'Publisher', '_.', '_class', '_,', '_loc', '1', '_,', '_loc', '0', '_)', '_;', '_arg', '0', '_.', '_bind', '_(', '_A', 'mb', 'ari', 'Event', 'Publisher', '_.', '_class', '_)', '_.', '_to', 'Instance', '_(', '_loc', '1', '_)', '_;', '_}', '</s>']
10/19/2022 02:39:15 - INFO - __main__ -   target_ids: 19 895 603 400 43863 1238 134 743 399 3916 7663 4893 134 385 579 3916 7663 400 743 2476 553 1228 11215 1089 17883 4893 135 385 579 553 1228 11215 1089 17883 400 743 2476 4126 1089 7663 400 553 1228 11215 1089 17883 746 1503 2019 4893 135 2019 4893 134 743 2476 1238 134 746 6679 400 553 1228 11215 1089 17883 746 1503 743 746 508 1562 400 4893 135 743 2476 425 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:41:31 - INFO - __main__ -   ***** Running training *****
10/19/2022 02:41:31 - INFO - __main__ -     Num examples = 100000
10/19/2022 02:41:31 - INFO - __main__ -     Batch size = 32
10/19/2022 02:41:31 - INFO - __main__ -     Num epoch = 30
10/19/2022 02:41:50 - INFO - __main__ -   epoch 0 step 100 loss 2.8985
10/19/2022 02:42:09 - INFO - __main__ -   epoch 0 step 200 loss 2.0964
10/19/2022 02:42:27 - INFO - __main__ -   epoch 0 step 300 loss 1.4626
10/19/2022 02:42:46 - INFO - __main__ -   epoch 0 step 400 loss 1.1621
10/19/2022 02:43:04 - INFO - __main__ -   epoch 0 step 500 loss 1.0209
10/19/2022 02:43:23 - INFO - __main__ -   epoch 0 step 600 loss 0.9
10/19/2022 02:43:42 - INFO - __main__ -   epoch 0 step 700 loss 0.8525
10/19/2022 02:44:00 - INFO - __main__ -   epoch 0 step 800 loss 0.7979
10/19/2022 02:44:19 - INFO - __main__ -   epoch 0 step 900 loss 0.7774
10/19/2022 02:44:37 - INFO - __main__ -   epoch 0 step 1000 loss 0.757
10/19/2022 02:44:56 - INFO - __main__ -   epoch 0 step 1100 loss 0.7507
10/19/2022 02:45:14 - INFO - __main__ -   epoch 0 step 1200 loss 0.7114
10/19/2022 02:45:33 - INFO - __main__ -   epoch 0 step 1300 loss 0.713
10/19/2022 02:45:52 - INFO - __main__ -   epoch 0 step 1400 loss 0.6967
10/19/2022 02:46:10 - INFO - __main__ -   epoch 0 step 1500 loss 0.6798
10/19/2022 02:46:29 - INFO - __main__ -   epoch 0 step 1600 loss 0.6734
10/19/2022 02:46:47 - INFO - __main__ -   epoch 0 step 1700 loss 0.673
10/19/2022 02:47:06 - INFO - __main__ -   epoch 0 step 1800 loss 0.6621
10/19/2022 02:47:24 - INFO - __main__ -   epoch 0 step 1900 loss 0.6399
10/19/2022 02:47:43 - INFO - __main__ -   epoch 0 step 2000 loss 0.654
10/19/2022 02:48:02 - INFO - __main__ -   epoch 0 step 2100 loss 0.6456
10/19/2022 02:48:20 - INFO - __main__ -   epoch 0 step 2200 loss 0.6339
10/19/2022 02:48:39 - INFO - __main__ -   epoch 0 step 2300 loss 0.6403
10/19/2022 02:48:58 - INFO - __main__ -   epoch 0 step 2400 loss 0.635
10/19/2022 02:49:16 - INFO - __main__ -   epoch 0 step 2500 loss 0.612
10/19/2022 02:49:35 - INFO - __main__ -   epoch 0 step 2600 loss 0.6083
10/19/2022 02:49:53 - INFO - __main__ -   epoch 0 step 2700 loss 0.6288
10/19/2022 02:50:12 - INFO - __main__ -   epoch 0 step 2800 loss 0.6036
10/19/2022 02:50:31 - INFO - __main__ -   epoch 0 step 2900 loss 0.6083
10/19/2022 02:50:49 - INFO - __main__ -   epoch 0 step 3000 loss 0.6105
10/19/2022 02:51:08 - INFO - __main__ -   epoch 0 step 3100 loss 0.6018
10/19/2022 02:51:15 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 02:51:15 - INFO - __main__ -     Num examples = 1000
10/19/2022 02:51:15 - INFO - __main__ -     Batch size = 32
10/19/2022 02:51:17 - INFO - __main__ -     eval_ppl = 1.98163
10/19/2022 02:51:17 - INFO - __main__ -     ********************
/sci_1/t-enshengshi/interpretability/sync_repo/bertviz/code-generation/model.py:190: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
10/19/2022 03:00:08 - INFO - __main__ -     bleu-4 = 29.23 
10/19/2022 03:00:08 - INFO - __main__ -     EM = 16.5 
10/19/2022 03:00:08 - INFO - __main__ -     ********************
10/19/2022 03:00:08 - INFO - __main__ -     Best score:45.730000000000004
10/19/2022 03:00:08 - INFO - __main__ -     ********************
10/19/2022 03:00:31 - INFO - __main__ -   epoch 1 step 3200 loss 0.5822
10/19/2022 03:00:49 - INFO - __main__ -   epoch 1 step 3300 loss 0.5786
10/19/2022 03:01:08 - INFO - __main__ -   epoch 1 step 3400 loss 0.596
10/19/2022 03:01:26 - INFO - __main__ -   epoch 1 step 3500 loss 0.5706
10/19/2022 03:01:45 - INFO - __main__ -   epoch 1 step 3600 loss 0.5726
10/19/2022 03:02:04 - INFO - __main__ -   epoch 1 step 3700 loss 0.5753
10/19/2022 03:02:22 - INFO - __main__ -   epoch 1 step 3800 loss 0.5548
10/19/2022 03:02:41 - INFO - __main__ -   epoch 1 step 3900 loss 0.5712
10/19/2022 03:02:59 - INFO - __main__ -   epoch 1 step 4000 loss 0.5617
10/19/2022 03:03:18 - INFO - __main__ -   epoch 1 step 4100 loss 0.5408
10/19/2022 03:03:36 - INFO - __main__ -   epoch 1 step 4200 loss 0.5504
10/19/2022 03:03:55 - INFO - __main__ -   epoch 1 step 4300 loss 0.5511
10/19/2022 03:04:13 - INFO - __main__ -   epoch 1 step 4400 loss 0.547
10/19/2022 03:04:32 - INFO - __main__ -   epoch 1 step 4500 loss 0.556
10/19/2022 03:04:51 - INFO - __main__ -   epoch 1 step 4600 loss 0.5404
10/19/2022 03:05:09 - INFO - __main__ -   epoch 1 step 4700 loss 0.5467
10/19/2022 03:05:28 - INFO - __main__ -   epoch 1 step 4800 loss 0.5416
10/19/2022 03:05:46 - INFO - __main__ -   epoch 1 step 4900 loss 0.5437
10/19/2022 03:06:05 - INFO - __main__ -   epoch 1 step 5000 loss 0.5502
10/19/2022 03:06:23 - INFO - __main__ -   epoch 1 step 5100 loss 0.5554
10/19/2022 03:06:42 - INFO - __main__ -   epoch 1 step 5200 loss 0.5189
10/19/2022 03:07:01 - INFO - __main__ -   epoch 1 step 5300 loss 0.5286
10/19/2022 03:07:19 - INFO - __main__ -   epoch 1 step 5400 loss 0.5223
10/19/2022 03:07:38 - INFO - __main__ -   epoch 1 step 5500 loss 0.5182
10/19/2022 03:07:56 - INFO - __main__ -   epoch 1 step 5600 loss 0.5166
10/19/2022 03:08:15 - INFO - __main__ -   epoch 1 step 5700 loss 0.5211
10/19/2022 03:08:33 - INFO - __main__ -   epoch 1 step 5800 loss 0.5189
10/19/2022 03:08:52 - INFO - __main__ -   epoch 1 step 5900 loss 0.5214
10/19/2022 03:09:11 - INFO - __main__ -   epoch 1 step 6000 loss 0.5114
10/19/2022 03:09:29 - INFO - __main__ -   epoch 1 step 6100 loss 0.5028
10/19/2022 03:09:48 - INFO - __main__ -   epoch 1 step 6200 loss 0.5107
10/19/2022 03:09:57 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:09:57 - INFO - __main__ -     Num examples = 1000
10/19/2022 03:09:57 - INFO - __main__ -     Batch size = 32
10/19/2022 03:10:00 - INFO - __main__ -     eval_ppl = 1.93446
10/19/2022 03:10:00 - INFO - __main__ -     ********************
10/19/2022 03:17:38 - INFO - __main__ -     bleu-4 = 30.01 
10/19/2022 03:17:38 - INFO - __main__ -     EM = 18.0 
10/19/2022 03:17:38 - INFO - __main__ -     ********************
10/19/2022 03:17:38 - INFO - __main__ -     Best score:48.010000000000005
10/19/2022 03:17:38 - INFO - __main__ -     ********************
10/19/2022 03:17:57 - INFO - __main__ -   epoch 2 step 6300 loss 0.5017
10/19/2022 03:18:15 - INFO - __main__ -   epoch 2 step 6400 loss 0.4689
10/19/2022 03:18:34 - INFO - __main__ -   epoch 2 step 6500 loss 0.4705
10/19/2022 03:18:52 - INFO - __main__ -   epoch 2 step 6600 loss 0.4701
10/19/2022 03:19:11 - INFO - __main__ -   epoch 2 step 6700 loss 0.4904
10/19/2022 03:19:29 - INFO - __main__ -   epoch 2 step 6800 loss 0.4669
10/19/2022 03:19:48 - INFO - __main__ -   epoch 2 step 6900 loss 0.4603
10/19/2022 03:20:06 - INFO - __main__ -   epoch 2 step 7000 loss 0.4745
10/19/2022 03:20:25 - INFO - __main__ -   epoch 2 step 7100 loss 0.4817
10/19/2022 03:20:43 - INFO - __main__ -   epoch 2 step 7200 loss 0.4682
10/19/2022 03:21:02 - INFO - __main__ -   epoch 2 step 7300 loss 0.4643
10/19/2022 03:21:20 - INFO - __main__ -   epoch 2 step 7400 loss 0.4767
10/19/2022 03:21:39 - INFO - __main__ -   epoch 2 step 7500 loss 0.462
10/19/2022 03:21:58 - INFO - __main__ -   epoch 2 step 7600 loss 0.4689
10/19/2022 03:22:16 - INFO - __main__ -   epoch 2 step 7700 loss 0.4602
10/19/2022 03:22:35 - INFO - __main__ -   epoch 2 step 7800 loss 0.4618
10/19/2022 03:22:53 - INFO - __main__ -   epoch 2 step 7900 loss 0.4617
10/19/2022 03:23:12 - INFO - __main__ -   epoch 2 step 8000 loss 0.4532
10/19/2022 03:23:30 - INFO - __main__ -   epoch 2 step 8100 loss 0.4574
10/19/2022 03:23:49 - INFO - __main__ -   epoch 2 step 8200 loss 0.451
10/19/2022 03:24:07 - INFO - __main__ -   epoch 2 step 8300 loss 0.4565
10/19/2022 03:24:26 - INFO - __main__ -   epoch 2 step 8400 loss 0.4609
10/19/2022 03:24:44 - INFO - __main__ -   epoch 2 step 8500 loss 0.459
10/19/2022 03:25:03 - INFO - __main__ -   epoch 2 step 8600 loss 0.4618
10/19/2022 03:25:22 - INFO - __main__ -   epoch 2 step 8700 loss 0.4509
10/19/2022 03:25:40 - INFO - __main__ -   epoch 2 step 8800 loss 0.4725
10/19/2022 03:25:59 - INFO - __main__ -   epoch 2 step 8900 loss 0.4543
10/19/2022 03:26:17 - INFO - __main__ -   epoch 2 step 9000 loss 0.4539
10/19/2022 03:26:36 - INFO - __main__ -   epoch 2 step 9100 loss 0.4632
10/19/2022 03:26:54 - INFO - __main__ -   epoch 2 step 9200 loss 0.4505
10/19/2022 03:27:13 - INFO - __main__ -   epoch 2 step 9300 loss 0.4562
10/19/2022 03:27:27 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:27:27 - INFO - __main__ -     Num examples = 1000
10/19/2022 03:27:27 - INFO - __main__ -     Batch size = 32
10/19/2022 03:27:29 - INFO - __main__ -     eval_ppl = 1.93912
10/19/2022 03:27:29 - INFO - __main__ -     ********************
10/19/2022 03:34:23 - INFO - __main__ -     bleu-4 = 30.45 
10/19/2022 03:34:23 - INFO - __main__ -     EM = 19.0 
10/19/2022 03:34:23 - INFO - __main__ -     ********************
10/19/2022 03:34:23 - INFO - __main__ -     Best score:49.45
10/19/2022 03:34:23 - INFO - __main__ -     ********************
10/19/2022 03:34:36 - INFO - __main__ -   epoch 3 step 9400 loss 0.4383
10/19/2022 03:34:55 - INFO - __main__ -   epoch 3 step 9500 loss 0.3844
10/19/2022 03:35:13 - INFO - __main__ -   epoch 3 step 9600 loss 0.3958
10/19/2022 03:35:32 - INFO - __main__ -   epoch 3 step 9700 loss 0.3895
10/19/2022 03:35:50 - INFO - __main__ -   epoch 3 step 9800 loss 0.3984
10/19/2022 03:36:09 - INFO - __main__ -   epoch 3 step 9900 loss 0.3939
10/19/2022 03:36:27 - INFO - __main__ -   epoch 3 step 10000 loss 0.4088
10/19/2022 03:36:46 - INFO - __main__ -   epoch 3 step 10100 loss 0.3802
10/19/2022 03:37:04 - INFO - __main__ -   epoch 3 step 10200 loss 0.3969
10/19/2022 03:37:23 - INFO - __main__ -   epoch 3 step 10300 loss 0.3958
10/19/2022 03:37:41 - INFO - __main__ -   epoch 3 step 10400 loss 0.3875
10/19/2022 03:38:00 - INFO - __main__ -   epoch 3 step 10500 loss 0.4023
10/19/2022 03:38:19 - INFO - __main__ -   epoch 3 step 10600 loss 0.4001
10/19/2022 03:38:37 - INFO - __main__ -   epoch 3 step 10700 loss 0.3921
10/19/2022 03:38:56 - INFO - __main__ -   epoch 3 step 10800 loss 0.3949
10/19/2022 03:39:14 - INFO - __main__ -   epoch 3 step 10900 loss 0.3946
10/19/2022 03:39:33 - INFO - __main__ -   epoch 3 step 11000 loss 0.4042
10/19/2022 03:39:51 - INFO - __main__ -   epoch 3 step 11100 loss 0.3884
10/19/2022 03:40:10 - INFO - __main__ -   epoch 3 step 11200 loss 0.4014
10/19/2022 03:40:28 - INFO - __main__ -   epoch 3 step 11300 loss 0.3904
10/19/2022 03:40:47 - INFO - __main__ -   epoch 3 step 11400 loss 0.402
10/19/2022 03:41:05 - INFO - __main__ -   epoch 3 step 11500 loss 0.3959
10/19/2022 03:41:24 - INFO - __main__ -   epoch 3 step 11600 loss 0.41
10/19/2022 03:41:42 - INFO - __main__ -   epoch 3 step 11700 loss 0.4006
10/19/2022 03:42:01 - INFO - __main__ -   epoch 3 step 11800 loss 0.3894
10/19/2022 03:42:20 - INFO - __main__ -   epoch 3 step 11900 loss 0.3854
10/19/2022 03:42:38 - INFO - __main__ -   epoch 3 step 12000 loss 0.3906
10/19/2022 03:42:57 - INFO - __main__ -   epoch 3 step 12100 loss 0.394
10/19/2022 03:43:15 - INFO - __main__ -   epoch 3 step 12200 loss 0.3991
10/19/2022 03:43:34 - INFO - __main__ -   epoch 3 step 12300 loss 0.3747
10/19/2022 03:43:52 - INFO - __main__ -   epoch 3 step 12400 loss 0.3969
10/19/2022 03:44:11 - INFO - __main__ -   epoch 3 step 12500 loss 0.3918
10/19/2022 03:44:11 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:44:11 - INFO - __main__ -     Num examples = 1000
10/19/2022 03:44:11 - INFO - __main__ -     Batch size = 32
10/19/2022 03:44:14 - INFO - __main__ -     eval_ppl = 1.94288
10/19/2022 03:44:14 - INFO - __main__ -     ********************
10/19/2022 03:52:05 - INFO - __main__ -     bleu-4 = 30.46 
10/19/2022 03:52:05 - INFO - __main__ -     EM = 18.7 
10/19/2022 03:52:05 - INFO - __main__ -     ********************
10/19/2022 03:52:24 - INFO - __main__ -   epoch 4 step 12600 loss 0.3273
10/19/2022 03:52:42 - INFO - __main__ -   epoch 4 step 12700 loss 0.3166
10/19/2022 03:53:01 - INFO - __main__ -   epoch 4 step 12800 loss 0.3324
10/19/2022 03:53:20 - INFO - __main__ -   epoch 4 step 12900 loss 0.3363
10/19/2022 03:53:38 - INFO - __main__ -   epoch 4 step 13000 loss 0.3294
10/19/2022 03:53:57 - INFO - __main__ -   epoch 4 step 13100 loss 0.3162
10/19/2022 03:54:16 - INFO - __main__ -   epoch 4 step 13200 loss 0.3227
10/19/2022 03:54:35 - INFO - __main__ -   epoch 4 step 13300 loss 0.3305
10/19/2022 03:54:53 - INFO - __main__ -   epoch 4 step 13400 loss 0.3398
10/19/2022 03:55:12 - INFO - __main__ -   epoch 4 step 13500 loss 0.3248
10/19/2022 03:55:31 - INFO - __main__ -   epoch 4 step 13600 loss 0.3371
10/19/2022 03:55:49 - INFO - __main__ -   epoch 4 step 13700 loss 0.3411
10/19/2022 03:56:08 - INFO - __main__ -   epoch 4 step 13800 loss 0.3447
10/19/2022 03:56:26 - INFO - __main__ -   epoch 4 step 13900 loss 0.3253
10/19/2022 03:56:45 - INFO - __main__ -   epoch 4 step 14000 loss 0.3268
10/19/2022 03:57:04 - INFO - __main__ -   epoch 4 step 14100 loss 0.3294
10/19/2022 03:57:22 - INFO - __main__ -   epoch 4 step 14200 loss 0.346
10/19/2022 03:57:41 - INFO - __main__ -   epoch 4 step 14300 loss 0.3334
10/19/2022 03:57:59 - INFO - __main__ -   epoch 4 step 14400 loss 0.3432
10/19/2022 03:58:18 - INFO - __main__ -   epoch 4 step 14500 loss 0.3291
10/19/2022 03:58:36 - INFO - __main__ -   epoch 4 step 14600 loss 0.3335
10/19/2022 03:58:55 - INFO - __main__ -   epoch 4 step 14700 loss 0.3384
10/19/2022 03:59:14 - INFO - __main__ -   epoch 4 step 14800 loss 0.3279
10/19/2022 03:59:32 - INFO - __main__ -   epoch 4 step 14900 loss 0.3351
10/19/2022 03:59:51 - INFO - __main__ -   epoch 4 step 15000 loss 0.3303
10/19/2022 04:00:09 - INFO - __main__ -   epoch 4 step 15100 loss 0.3329
10/19/2022 04:00:28 - INFO - __main__ -   epoch 4 step 15200 loss 0.3295
10/19/2022 04:00:47 - INFO - __main__ -   epoch 4 step 15300 loss 0.3219
10/19/2022 04:01:05 - INFO - __main__ -   epoch 4 step 15400 loss 0.3286
10/19/2022 04:01:24 - INFO - __main__ -   epoch 4 step 15500 loss 0.3359
10/19/2022 04:01:42 - INFO - __main__ -   epoch 4 step 15600 loss 0.3511
10/19/2022 04:01:47 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 04:01:47 - INFO - __main__ -     Num examples = 1000
10/19/2022 04:01:47 - INFO - __main__ -     Batch size = 32
10/19/2022 04:01:50 - INFO - __main__ -     eval_ppl = 1.97597
10/19/2022 04:01:50 - INFO - __main__ -     ********************
10/19/2022 04:09:43 - INFO - __main__ -     bleu-4 = 32.97 
10/19/2022 04:09:43 - INFO - __main__ -     EM = 17.8 
10/19/2022 04:09:43 - INFO - __main__ -     ********************
10/19/2022 04:09:43 - INFO - __main__ -     Best score:50.769999999999996
10/19/2022 04:09:43 - INFO - __main__ -     ********************
10/19/2022 04:10:07 - INFO - __main__ -   epoch 5 step 15700 loss 0.2846
10/19/2022 04:10:25 - INFO - __main__ -   epoch 5 step 15800 loss 0.2696
10/19/2022 04:10:44 - INFO - __main__ -   epoch 5 step 15900 loss 0.2686
10/19/2022 04:11:02 - INFO - __main__ -   epoch 5 step 16000 loss 0.2725
10/19/2022 04:11:21 - INFO - __main__ -   epoch 5 step 16100 loss 0.2791
10/19/2022 04:11:40 - INFO - __main__ -   epoch 5 step 16200 loss 0.2761
10/19/2022 04:11:58 - INFO - __main__ -   epoch 5 step 16300 loss 0.2785
10/19/2022 04:12:17 - INFO - __main__ -   epoch 5 step 16400 loss 0.2748
10/19/2022 04:12:35 - INFO - __main__ -   epoch 5 step 16500 loss 0.288
10/19/2022 04:12:54 - INFO - __main__ -   epoch 5 step 16600 loss 0.2692
10/19/2022 04:13:12 - INFO - __main__ -   epoch 5 step 16700 loss 0.2854
10/19/2022 04:13:31 - INFO - __main__ -   epoch 5 step 16800 loss 0.2785
10/19/2022 04:13:50 - INFO - __main__ -   epoch 5 step 16900 loss 0.2784
10/19/2022 04:14:08 - INFO - __main__ -   epoch 5 step 17000 loss 0.2915
10/19/2022 04:14:27 - INFO - __main__ -   epoch 5 step 17100 loss 0.2783
10/19/2022 04:14:45 - INFO - __main__ -   epoch 5 step 17200 loss 0.2889
10/19/2022 04:15:04 - INFO - __main__ -   epoch 5 step 17300 loss 0.2807
10/19/2022 04:15:23 - INFO - __main__ -   epoch 5 step 17400 loss 0.294
10/19/2022 04:15:41 - INFO - __main__ -   epoch 5 step 17500 loss 0.2911
10/19/2022 04:16:00 - INFO - __main__ -   epoch 5 step 17600 loss 0.2911
10/19/2022 04:16:18 - INFO - __main__ -   epoch 5 step 17700 loss 0.2851
10/19/2022 04:16:37 - INFO - __main__ -   epoch 5 step 17800 loss 0.2875
10/19/2022 04:16:56 - INFO - __main__ -   epoch 5 step 17900 loss 0.2923
10/19/2022 04:17:14 - INFO - __main__ -   epoch 5 step 18000 loss 0.28
10/19/2022 04:17:33 - INFO - __main__ -   epoch 5 step 18100 loss 0.2876
10/19/2022 04:17:51 - INFO - __main__ -   epoch 5 step 18200 loss 0.2896
10/19/2022 04:18:10 - INFO - __main__ -   epoch 5 step 18300 loss 0.2926
10/19/2022 04:18:29 - INFO - __main__ -   epoch 5 step 18400 loss 0.297
10/19/2022 04:18:47 - INFO - __main__ -   epoch 5 step 18500 loss 0.2897
10/19/2022 04:19:06 - INFO - __main__ -   epoch 5 step 18600 loss 0.2852
10/19/2022 04:19:24 - INFO - __main__ -   epoch 5 step 18700 loss 0.2854
10/19/2022 04:19:34 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 04:19:34 - INFO - __main__ -     Num examples = 1000
10/19/2022 04:19:34 - INFO - __main__ -     Batch size = 32
10/19/2022 04:19:36 - INFO - __main__ -     eval_ppl = 2.05587
10/19/2022 04:19:36 - INFO - __main__ -     ********************
10/19/2022 04:26:45 - INFO - __main__ -     bleu-4 = 32.39 
10/19/2022 04:26:45 - INFO - __main__ -     EM = 18.4 
10/19/2022 04:26:45 - INFO - __main__ -     ********************
10/19/2022 04:26:45 - INFO - __main__ -     Best score:50.79
10/19/2022 04:26:45 - INFO - __main__ -     ********************
10/19/2022 04:27:03 - INFO - __main__ -   epoch 6 step 18800 loss 0.2642
10/19/2022 04:27:21 - INFO - __main__ -   epoch 6 step 18900 loss 0.2341
10/19/2022 04:27:40 - INFO - __main__ -   epoch 6 step 19000 loss 0.2272
10/19/2022 04:27:59 - INFO - __main__ -   epoch 6 step 19100 loss 0.2288
10/19/2022 04:28:17 - INFO - __main__ -   epoch 6 step 19200 loss 0.236
10/19/2022 04:28:36 - INFO - __main__ -   epoch 6 step 19300 loss 0.2363
10/19/2022 04:28:54 - INFO - __main__ -   epoch 6 step 19400 loss 0.2296
10/19/2022 04:29:13 - INFO - __main__ -   epoch 6 step 19500 loss 0.2426
10/19/2022 04:29:31 - INFO - __main__ -   epoch 6 step 19600 loss 0.2325
10/19/2022 04:29:50 - INFO - __main__ -   epoch 6 step 19700 loss 0.243
10/19/2022 04:30:09 - INFO - __main__ -   epoch 6 step 19800 loss 0.2412
10/19/2022 04:30:27 - INFO - __main__ -   epoch 6 step 19900 loss 0.241
10/19/2022 04:30:46 - INFO - __main__ -   epoch 6 step 20000 loss 0.2496
10/19/2022 04:31:04 - INFO - __main__ -   epoch 6 step 20100 loss 0.2541
10/19/2022 04:31:23 - INFO - __main__ -   epoch 6 step 20200 loss 0.243
10/19/2022 04:31:41 - INFO - __main__ -   epoch 6 step 20300 loss 0.2409
10/19/2022 04:32:00 - INFO - __main__ -   epoch 6 step 20400 loss 0.2397
10/19/2022 04:32:19 - INFO - __main__ -   epoch 6 step 20500 loss 0.2527
10/19/2022 04:32:37 - INFO - __main__ -   epoch 6 step 20600 loss 0.2487
10/19/2022 04:32:56 - INFO - __main__ -   epoch 6 step 20700 loss 0.242
10/19/2022 04:33:14 - INFO - __main__ -   epoch 6 step 20800 loss 0.2462
10/19/2022 04:33:33 - INFO - __main__ -   epoch 6 step 20900 loss 0.2452
10/19/2022 04:33:51 - INFO - __main__ -   epoch 6 step 21000 loss 0.2425
10/19/2022 04:34:10 - INFO - __main__ -   epoch 6 step 21100 loss 0.2506
10/19/2022 04:34:28 - INFO - __main__ -   epoch 6 step 21200 loss 0.2465
10/19/2022 04:34:47 - INFO - __main__ -   epoch 6 step 21300 loss 0.2541
10/19/2022 04:35:06 - INFO - __main__ -   epoch 6 step 21400 loss 0.2464
10/19/2022 04:35:24 - INFO - __main__ -   epoch 6 step 21500 loss 0.2473
10/19/2022 04:35:43 - INFO - __main__ -   epoch 6 step 21600 loss 0.2518
10/19/2022 04:36:02 - INFO - __main__ -   epoch 6 step 21700 loss 0.2487
10/19/2022 04:36:20 - INFO - __main__ -   epoch 6 step 21800 loss 0.2521
10/19/2022 04:36:34 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 04:36:34 - INFO - __main__ -     Num examples = 1000
10/19/2022 04:36:34 - INFO - __main__ -     Batch size = 32
10/19/2022 04:36:37 - INFO - __main__ -     eval_ppl = 2.077
10/19/2022 04:36:37 - INFO - __main__ -     ********************
10/19/2022 04:43:51 - INFO - __main__ -     bleu-4 = 32.84 
10/19/2022 04:43:51 - INFO - __main__ -     EM = 17.7 
10/19/2022 04:43:51 - INFO - __main__ -     ********************
10/19/2022 04:43:55 - INFO - __main__ -   epoch 7 step 21900 loss 0.2373
10/19/2022 04:44:14 - INFO - __main__ -   epoch 7 step 22000 loss 0.1993
10/19/2022 04:44:32 - INFO - __main__ -   epoch 7 step 22100 loss 0.2069
10/19/2022 04:44:51 - INFO - __main__ -   epoch 7 step 22200 loss 0.1954
10/19/2022 04:45:09 - INFO - __main__ -   epoch 7 step 22300 loss 0.1975
10/19/2022 04:45:28 - INFO - __main__ -   epoch 7 step 22400 loss 0.2002
10/19/2022 04:45:47 - INFO - __main__ -   epoch 7 step 22500 loss 0.2007
10/19/2022 04:46:05 - INFO - __main__ -   epoch 7 step 22600 loss 0.2045
10/19/2022 04:46:24 - INFO - __main__ -   epoch 7 step 22700 loss 0.2079
10/19/2022 04:46:42 - INFO - __main__ -   epoch 7 step 22800 loss 0.2156
10/19/2022 04:47:01 - INFO - __main__ -   epoch 7 step 22900 loss 0.2052
10/19/2022 04:47:19 - INFO - __main__ -   epoch 7 step 23000 loss 0.2085
10/19/2022 04:47:38 - INFO - __main__ -   epoch 7 step 23100 loss 0.2055
10/19/2022 04:47:56 - INFO - __main__ -   epoch 7 step 23200 loss 0.2099
10/19/2022 04:48:15 - INFO - __main__ -   epoch 7 step 23300 loss 0.2081
10/19/2022 04:48:34 - INFO - __main__ -   epoch 7 step 23400 loss 0.2157
10/19/2022 04:48:52 - INFO - __main__ -   epoch 7 step 23500 loss 0.2162
10/19/2022 04:49:11 - INFO - __main__ -   epoch 7 step 23600 loss 0.2156
10/19/2022 04:49:29 - INFO - __main__ -   epoch 7 step 23700 loss 0.2127
10/19/2022 04:49:48 - INFO - __main__ -   epoch 7 step 23800 loss 0.2062
10/19/2022 04:50:06 - INFO - __main__ -   epoch 7 step 23900 loss 0.2169
10/19/2022 04:50:25 - INFO - __main__ -   epoch 7 step 24000 loss 0.2153
10/19/2022 04:50:44 - INFO - __main__ -   epoch 7 step 24100 loss 0.2104
10/19/2022 04:51:02 - INFO - __main__ -   epoch 7 step 24200 loss 0.216
10/19/2022 04:51:21 - INFO - __main__ -   epoch 7 step 24300 loss 0.2127
10/19/2022 04:51:39 - INFO - __main__ -   epoch 7 step 24400 loss 0.2135
10/19/2022 04:51:58 - INFO - __main__ -   epoch 7 step 24500 loss 0.222
10/19/2022 04:52:16 - INFO - __main__ -   epoch 7 step 24600 loss 0.2243
10/19/2022 04:52:35 - INFO - __main__ -   epoch 7 step 24700 loss 0.2087
10/19/2022 04:52:54 - INFO - __main__ -   epoch 7 step 24800 loss 0.2171
10/19/2022 04:53:12 - INFO - __main__ -   epoch 7 step 24900 loss 0.2156
10/19/2022 04:53:31 - INFO - __main__ -   epoch 7 step 25000 loss 0.2215
10/19/2022 04:53:31 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 04:53:31 - INFO - __main__ -     Num examples = 1000
10/19/2022 04:53:31 - INFO - __main__ -     Batch size = 32
10/19/2022 04:53:33 - INFO - __main__ -     eval_ppl = 2.14755
10/19/2022 04:53:33 - INFO - __main__ -     ********************
10/19/2022 05:00:34 - INFO - __main__ -     bleu-4 = 32.45 
10/19/2022 05:00:34 - INFO - __main__ -     EM = 18.2 
10/19/2022 05:00:34 - INFO - __main__ -     ********************
10/19/2022 05:00:52 - INFO - __main__ -   epoch 8 step 25100 loss 0.17
10/19/2022 05:01:11 - INFO - __main__ -   epoch 8 step 25200 loss 0.175
10/19/2022 05:01:29 - INFO - __main__ -   epoch 8 step 25300 loss 0.1706
10/19/2022 05:01:48 - INFO - __main__ -   epoch 8 step 25400 loss 0.1708
10/19/2022 05:02:07 - INFO - __main__ -   epoch 8 step 25500 loss 0.1703
10/19/2022 05:02:25 - INFO - __main__ -   epoch 8 step 25600 loss 0.177
10/19/2022 05:02:44 - INFO - __main__ -   epoch 8 step 25700 loss 0.174
10/19/2022 05:03:02 - INFO - __main__ -   epoch 8 step 25800 loss 0.1894
10/19/2022 05:03:21 - INFO - __main__ -   epoch 8 step 25900 loss 0.1845
10/19/2022 05:03:40 - INFO - __main__ -   epoch 8 step 26000 loss 0.1785
10/19/2022 05:03:58 - INFO - __main__ -   epoch 8 step 26100 loss 0.1801
10/19/2022 05:04:17 - INFO - __main__ -   epoch 8 step 26200 loss 0.185
10/19/2022 05:04:35 - INFO - __main__ -   epoch 8 step 26300 loss 0.1755
10/19/2022 05:04:54 - INFO - __main__ -   epoch 8 step 26400 loss 0.1761
10/19/2022 05:05:13 - INFO - __main__ -   epoch 8 step 26500 loss 0.1833
10/19/2022 05:05:31 - INFO - __main__ -   epoch 8 step 26600 loss 0.1851
10/19/2022 05:05:50 - INFO - __main__ -   epoch 8 step 26700 loss 0.1821
10/19/2022 05:06:08 - INFO - __main__ -   epoch 8 step 26800 loss 0.1738
10/19/2022 05:06:27 - INFO - __main__ -   epoch 8 step 26900 loss 0.1802
10/19/2022 05:06:45 - INFO - __main__ -   epoch 8 step 27000 loss 0.182
10/19/2022 05:07:04 - INFO - __main__ -   epoch 8 step 27100 loss 0.1763
10/19/2022 05:07:23 - INFO - __main__ -   epoch 8 step 27200 loss 0.1951
10/19/2022 05:07:41 - INFO - __main__ -   epoch 8 step 27300 loss 0.1776
10/19/2022 05:08:00 - INFO - __main__ -   epoch 8 step 27400 loss 0.1866
10/19/2022 05:08:18 - INFO - __main__ -   epoch 8 step 27500 loss 0.1956
10/19/2022 05:08:37 - INFO - __main__ -   epoch 8 step 27600 loss 0.1876
10/19/2022 05:08:56 - INFO - __main__ -   epoch 8 step 27700 loss 0.1877
10/19/2022 05:09:14 - INFO - __main__ -   epoch 8 step 27800 loss 0.19
10/19/2022 05:09:33 - INFO - __main__ -   epoch 8 step 27900 loss 0.1927
10/19/2022 05:09:51 - INFO - __main__ -   epoch 8 step 28000 loss 0.1891
10/19/2022 05:10:10 - INFO - __main__ -   epoch 8 step 28100 loss 0.1848
10/19/2022 05:10:15 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 05:10:15 - INFO - __main__ -     Num examples = 1000
10/19/2022 05:10:15 - INFO - __main__ -     Batch size = 32
10/19/2022 05:10:17 - INFO - __main__ -     eval_ppl = 2.20156
10/19/2022 05:10:17 - INFO - __main__ -     ********************
10/19/2022 05:17:53 - INFO - __main__ -     bleu-4 = 32.73 
10/19/2022 05:17:53 - INFO - __main__ -     EM = 18.4 
10/19/2022 05:17:53 - INFO - __main__ -     ********************
10/19/2022 05:17:53 - INFO - __main__ -     Best score:51.129999999999995
10/19/2022 05:17:53 - INFO - __main__ -     ********************
10/19/2022 05:18:13 - INFO - __main__ -   epoch 9 step 28200 loss 0.1592
10/19/2022 05:18:32 - INFO - __main__ -   epoch 9 step 28300 loss 0.1534
10/19/2022 05:18:51 - INFO - __main__ -   epoch 9 step 28400 loss 0.1492
10/19/2022 05:19:09 - INFO - __main__ -   epoch 9 step 28500 loss 0.1518
10/19/2022 05:19:28 - INFO - __main__ -   epoch 9 step 28600 loss 0.1552
10/19/2022 05:19:46 - INFO - __main__ -   epoch 9 step 28700 loss 0.1481
10/19/2022 05:20:05 - INFO - __main__ -   epoch 9 step 28800 loss 0.149
10/19/2022 05:20:24 - INFO - __main__ -   epoch 9 step 28900 loss 0.1504
10/19/2022 05:20:42 - INFO - __main__ -   epoch 9 step 29000 loss 0.1499
10/19/2022 05:21:01 - INFO - __main__ -   epoch 9 step 29100 loss 0.1495
10/19/2022 05:21:19 - INFO - __main__ -   epoch 9 step 29200 loss 0.1488
10/19/2022 05:21:38 - INFO - __main__ -   epoch 9 step 29300 loss 0.1536
10/19/2022 05:21:57 - INFO - __main__ -   epoch 9 step 29400 loss 0.1552
10/19/2022 05:22:15 - INFO - __main__ -   epoch 9 step 29500 loss 0.1585
10/19/2022 05:22:34 - INFO - __main__ -   epoch 9 step 29600 loss 0.1534
10/19/2022 05:22:52 - INFO - __main__ -   epoch 9 step 29700 loss 0.1667
10/19/2022 05:23:11 - INFO - __main__ -   epoch 9 step 29800 loss 0.1618
10/19/2022 05:23:30 - INFO - __main__ -   epoch 9 step 29900 loss 0.1596
10/19/2022 05:23:49 - INFO - __main__ -   epoch 9 step 30000 loss 0.1547
10/19/2022 05:24:07 - INFO - __main__ -   epoch 9 step 30100 loss 0.1609
10/19/2022 05:24:26 - INFO - __main__ -   epoch 9 step 30200 loss 0.1613
10/19/2022 05:24:45 - INFO - __main__ -   epoch 9 step 30300 loss 0.161
10/19/2022 05:25:03 - INFO - __main__ -   epoch 9 step 30400 loss 0.1632
10/19/2022 05:25:22 - INFO - __main__ -   epoch 9 step 30500 loss 0.171
10/19/2022 05:25:40 - INFO - __main__ -   epoch 9 step 30600 loss 0.1702
10/19/2022 05:25:59 - INFO - __main__ -   epoch 9 step 30700 loss 0.1727
10/19/2022 05:26:18 - INFO - __main__ -   epoch 9 step 30800 loss 0.1627
10/19/2022 05:26:36 - INFO - __main__ -   epoch 9 step 30900 loss 0.1653
10/19/2022 05:26:55 - INFO - __main__ -   epoch 9 step 31000 loss 0.1612
10/19/2022 05:27:13 - INFO - __main__ -   epoch 9 step 31100 loss 0.1619
10/19/2022 05:27:32 - INFO - __main__ -   epoch 9 step 31200 loss 0.1601
10/19/2022 05:27:41 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 05:27:41 - INFO - __main__ -     Num examples = 1000
10/19/2022 05:27:41 - INFO - __main__ -     Batch size = 32
10/19/2022 05:27:44 - INFO - __main__ -     eval_ppl = 2.32098
10/19/2022 05:27:44 - INFO - __main__ -     ********************
10/19/2022 05:34:45 - INFO - __main__ -     bleu-4 = 32.0 
10/19/2022 05:34:45 - INFO - __main__ -     EM = 17.6 
10/19/2022 05:34:45 - INFO - __main__ -     ********************
10/19/2022 05:34:55 - INFO - __main__ -   epoch 10 step 31300 loss 0.1452
10/19/2022 05:35:13 - INFO - __main__ -   epoch 10 step 31400 loss 0.1242
10/19/2022 05:35:32 - INFO - __main__ -   epoch 10 step 31500 loss 0.1305
10/19/2022 05:35:50 - INFO - __main__ -   epoch 10 step 31600 loss 0.1309
10/19/2022 05:36:09 - INFO - __main__ -   epoch 10 step 31700 loss 0.1308
10/19/2022 05:36:27 - INFO - __main__ -   epoch 10 step 31800 loss 0.1341
10/19/2022 05:36:46 - INFO - __main__ -   epoch 10 step 31900 loss 0.1335
10/19/2022 05:37:04 - INFO - __main__ -   epoch 10 step 32000 loss 0.1346
10/19/2022 05:37:23 - INFO - __main__ -   epoch 10 step 32100 loss 0.1366
10/19/2022 05:37:41 - INFO - __main__ -   epoch 10 step 32200 loss 0.1345
10/19/2022 05:38:00 - INFO - __main__ -   epoch 10 step 32300 loss 0.1355
10/19/2022 05:38:19 - INFO - __main__ -   epoch 10 step 32400 loss 0.1388
10/19/2022 05:38:37 - INFO - __main__ -   epoch 10 step 32500 loss 0.1316
10/19/2022 05:38:56 - INFO - __main__ -   epoch 10 step 32600 loss 0.1391
10/19/2022 05:39:14 - INFO - __main__ -   epoch 10 step 32700 loss 0.1369
10/19/2022 05:39:33 - INFO - __main__ -   epoch 10 step 32800 loss 0.1328
10/19/2022 05:39:52 - INFO - __main__ -   epoch 10 step 32900 loss 0.1419
10/19/2022 05:40:10 - INFO - __main__ -   epoch 10 step 33000 loss 0.1343
10/19/2022 05:40:29 - INFO - __main__ -   epoch 10 step 33100 loss 0.1425
10/19/2022 05:40:47 - INFO - __main__ -   epoch 10 step 33200 loss 0.1364
10/19/2022 05:41:06 - INFO - __main__ -   epoch 10 step 33300 loss 0.1411
10/19/2022 05:41:24 - INFO - __main__ -   epoch 10 step 33400 loss 0.1419
10/19/2022 05:41:43 - INFO - __main__ -   epoch 10 step 33500 loss 0.1453
10/19/2022 05:42:01 - INFO - __main__ -   epoch 10 step 33600 loss 0.141
10/19/2022 05:42:20 - INFO - __main__ -   epoch 10 step 33700 loss 0.1448
10/19/2022 05:42:39 - INFO - __main__ -   epoch 10 step 33800 loss 0.139
10/19/2022 05:42:57 - INFO - __main__ -   epoch 10 step 33900 loss 0.1453
10/19/2022 05:43:16 - INFO - __main__ -   epoch 10 step 34000 loss 0.1434
10/19/2022 05:43:34 - INFO - __main__ -   epoch 10 step 34100 loss 0.1439
10/19/2022 05:43:53 - INFO - __main__ -   epoch 10 step 34200 loss 0.1399
10/19/2022 05:44:11 - INFO - __main__ -   epoch 10 step 34300 loss 0.1426
10/19/2022 05:44:25 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 05:44:25 - INFO - __main__ -     Num examples = 1000
10/19/2022 05:44:25 - INFO - __main__ -     Batch size = 32
10/19/2022 05:44:28 - INFO - __main__ -     eval_ppl = 2.4092
10/19/2022 05:44:28 - INFO - __main__ -     ********************
10/19/2022 05:51:35 - INFO - __main__ -     bleu-4 = 32.37 
10/19/2022 05:51:35 - INFO - __main__ -     EM = 17.8 
10/19/2022 05:51:35 - INFO - __main__ -     ********************
10/19/2022 05:51:40 - INFO - __main__ -   epoch 11 step 34400 loss 0.1355
10/19/2022 05:51:59 - INFO - __main__ -   epoch 11 step 34500 loss 0.1137
10/19/2022 05:52:17 - INFO - __main__ -   epoch 11 step 34600 loss 0.1127
10/19/2022 05:52:36 - INFO - __main__ -   epoch 11 step 34700 loss 0.1133
10/19/2022 05:52:54 - INFO - __main__ -   epoch 11 step 34800 loss 0.1132
10/19/2022 05:53:13 - INFO - __main__ -   epoch 11 step 34900 loss 0.1164
10/19/2022 05:53:31 - INFO - __main__ -   epoch 11 step 35000 loss 0.1105
10/19/2022 05:53:50 - INFO - __main__ -   epoch 11 step 35100 loss 0.116
10/19/2022 05:54:08 - INFO - __main__ -   epoch 11 step 35200 loss 0.1134
10/19/2022 05:54:27 - INFO - __main__ -   epoch 11 step 35300 loss 0.1187
10/19/2022 05:54:45 - INFO - __main__ -   epoch 11 step 35400 loss 0.1176
10/19/2022 05:55:04 - INFO - __main__ -   epoch 11 step 35500 loss 0.1196
10/19/2022 05:55:23 - INFO - __main__ -   epoch 11 step 35600 loss 0.1148
10/19/2022 05:55:41 - INFO - __main__ -   epoch 11 step 35700 loss 0.1176
10/19/2022 05:56:00 - INFO - __main__ -   epoch 11 step 35800 loss 0.1214
10/19/2022 05:56:18 - INFO - __main__ -   epoch 11 step 35900 loss 0.1175
10/19/2022 05:56:37 - INFO - __main__ -   epoch 11 step 36000 loss 0.1192
10/19/2022 05:56:55 - INFO - __main__ -   epoch 11 step 36100 loss 0.1195
10/19/2022 05:57:14 - INFO - __main__ -   epoch 11 step 36200 loss 0.1206
10/19/2022 05:57:33 - INFO - __main__ -   epoch 11 step 36300 loss 0.1203
10/19/2022 05:57:51 - INFO - __main__ -   epoch 11 step 36400 loss 0.1282
10/19/2022 05:58:10 - INFO - __main__ -   epoch 11 step 36500 loss 0.124
10/19/2022 05:58:28 - INFO - __main__ -   epoch 11 step 36600 loss 0.1229
10/19/2022 05:58:47 - INFO - __main__ -   epoch 11 step 36700 loss 0.1201
10/19/2022 05:59:05 - INFO - __main__ -   epoch 11 step 36800 loss 0.1244
10/19/2022 05:59:24 - INFO - __main__ -   epoch 11 step 36900 loss 0.1231
10/19/2022 05:59:43 - INFO - __main__ -   epoch 11 step 37000 loss 0.1223
10/19/2022 06:00:01 - INFO - __main__ -   epoch 11 step 37100 loss 0.1253
10/19/2022 06:00:20 - INFO - __main__ -   epoch 11 step 37200 loss 0.1228
10/19/2022 06:00:38 - INFO - __main__ -   epoch 11 step 37300 loss 0.1263
10/19/2022 06:00:57 - INFO - __main__ -   epoch 11 step 37400 loss 0.1272
10/19/2022 06:01:15 - INFO - __main__ -   epoch 11 step 37500 loss 0.1314
10/19/2022 06:01:16 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 06:01:16 - INFO - __main__ -     Num examples = 1000
10/19/2022 06:01:16 - INFO - __main__ -     Batch size = 32
10/19/2022 06:01:18 - INFO - __main__ -     eval_ppl = 2.46329
10/19/2022 06:01:18 - INFO - __main__ -     ********************
10/19/2022 06:08:26 - INFO - __main__ -     bleu-4 = 33.16 
10/19/2022 06:08:26 - INFO - __main__ -     EM = 18.6 
10/19/2022 06:08:26 - INFO - __main__ -     ********************
10/19/2022 06:08:26 - INFO - __main__ -     Best score:51.76
10/19/2022 06:08:26 - INFO - __main__ -     ********************
10/19/2022 06:08:54 - INFO - __main__ -   epoch 12 step 37600 loss 0.0985
10/19/2022 06:09:12 - INFO - __main__ -   epoch 12 step 37700 loss 0.0975
10/19/2022 06:09:31 - INFO - __main__ -   epoch 12 step 37800 loss 0.0963
10/19/2022 06:09:49 - INFO - __main__ -   epoch 12 step 37900 loss 0.0999
10/19/2022 06:10:08 - INFO - __main__ -   epoch 12 step 38000 loss 0.099
10/19/2022 06:10:26 - INFO - __main__ -   epoch 12 step 38100 loss 0.0995
10/19/2022 06:10:45 - INFO - __main__ -   epoch 12 step 38200 loss 0.104
10/19/2022 06:11:03 - INFO - __main__ -   epoch 12 step 38300 loss 0.1082
10/19/2022 06:11:22 - INFO - __main__ -   epoch 12 step 38400 loss 0.1027
10/19/2022 06:11:41 - INFO - __main__ -   epoch 12 step 38500 loss 0.1014
10/19/2022 06:11:59 - INFO - __main__ -   epoch 12 step 38600 loss 0.1035
10/19/2022 06:12:18 - INFO - __main__ -   epoch 12 step 38700 loss 0.1038
10/19/2022 06:12:36 - INFO - __main__ -   epoch 12 step 38800 loss 0.1029
10/19/2022 06:12:55 - INFO - __main__ -   epoch 12 step 38900 loss 0.1051
10/19/2022 06:13:13 - INFO - __main__ -   epoch 12 step 39000 loss 0.1055
10/19/2022 06:13:32 - INFO - __main__ -   epoch 12 step 39100 loss 0.1059
10/19/2022 06:13:50 - INFO - __main__ -   epoch 12 step 39200 loss 0.1067
10/19/2022 06:14:09 - INFO - __main__ -   epoch 12 step 39300 loss 0.1041
10/19/2022 06:14:27 - INFO - __main__ -   epoch 12 step 39400 loss 0.107
10/19/2022 06:14:46 - INFO - __main__ -   epoch 12 step 39500 loss 0.1083
10/19/2022 06:15:04 - INFO - __main__ -   epoch 12 step 39600 loss 0.1083
10/19/2022 06:15:23 - INFO - __main__ -   epoch 12 step 39700 loss 0.1063
10/19/2022 06:15:41 - INFO - __main__ -   epoch 12 step 39800 loss 0.1113
10/19/2022 06:16:00 - INFO - __main__ -   epoch 12 step 39900 loss 0.1116
10/19/2022 06:16:19 - INFO - __main__ -   epoch 12 step 40000 loss 0.109
10/19/2022 06:16:37 - INFO - __main__ -   epoch 12 step 40100 loss 0.1078
10/19/2022 06:16:56 - INFO - __main__ -   epoch 12 step 40200 loss 0.1104
10/19/2022 06:17:14 - INFO - __main__ -   epoch 12 step 40300 loss 0.1056
10/19/2022 06:17:33 - INFO - __main__ -   epoch 12 step 40400 loss 0.1071
10/19/2022 06:17:51 - INFO - __main__ -   epoch 12 step 40500 loss 0.1103
10/19/2022 06:18:10 - INFO - __main__ -   epoch 12 step 40600 loss 0.1068
10/19/2022 06:18:15 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 06:18:15 - INFO - __main__ -     Num examples = 1000
10/19/2022 06:18:15 - INFO - __main__ -     Batch size = 32
10/19/2022 06:18:17 - INFO - __main__ -     eval_ppl = 2.54578
10/19/2022 06:18:17 - INFO - __main__ -     ********************
10/19/2022 06:25:41 - INFO - __main__ -     bleu-4 = 32.89 
10/19/2022 06:25:41 - INFO - __main__ -     EM = 17.9 
10/19/2022 06:25:41 - INFO - __main__ -     ********************
10/19/2022 06:25:55 - INFO - __main__ -   epoch 13 step 40700 loss 0.0906
10/19/2022 06:26:14 - INFO - __main__ -   epoch 13 step 40800 loss 0.0854
10/19/2022 06:26:32 - INFO - __main__ -   epoch 13 step 40900 loss 0.0841
10/19/2022 06:26:51 - INFO - __main__ -   epoch 13 step 41000 loss 0.0844
10/19/2022 06:27:09 - INFO - __main__ -   epoch 13 step 41100 loss 0.0875
10/19/2022 06:27:28 - INFO - __main__ -   epoch 13 step 41200 loss 0.085
10/19/2022 06:27:46 - INFO - __main__ -   epoch 13 step 41300 loss 0.0892
10/19/2022 06:28:05 - INFO - __main__ -   epoch 13 step 41400 loss 0.0888
10/19/2022 06:28:24 - INFO - __main__ -   epoch 13 step 41500 loss 0.0891
10/19/2022 06:28:42 - INFO - __main__ -   epoch 13 step 41600 loss 0.0906
10/19/2022 06:29:01 - INFO - __main__ -   epoch 13 step 41700 loss 0.09
10/19/2022 06:29:19 - INFO - __main__ -   epoch 13 step 41800 loss 0.0925
10/19/2022 06:29:38 - INFO - __main__ -   epoch 13 step 41900 loss 0.0878
10/19/2022 06:29:56 - INFO - __main__ -   epoch 13 step 42000 loss 0.0909
10/19/2022 06:30:15 - INFO - __main__ -   epoch 13 step 42100 loss 0.091
10/19/2022 06:30:33 - INFO - __main__ -   epoch 13 step 42200 loss 0.0919
10/19/2022 06:30:52 - INFO - __main__ -   epoch 13 step 42300 loss 0.0918
10/19/2022 06:31:11 - INFO - __main__ -   epoch 13 step 42400 loss 0.0947
10/19/2022 06:31:29 - INFO - __main__ -   epoch 13 step 42500 loss 0.0916
10/19/2022 06:31:48 - INFO - __main__ -   epoch 13 step 42600 loss 0.0922
10/19/2022 06:32:06 - INFO - __main__ -   epoch 13 step 42700 loss 0.0975
10/19/2022 06:32:25 - INFO - __main__ -   epoch 13 step 42800 loss 0.0971
10/19/2022 06:32:43 - INFO - __main__ -   epoch 13 step 42900 loss 0.0977
10/19/2022 06:33:02 - INFO - __main__ -   epoch 13 step 43000 loss 0.0953
10/19/2022 06:33:20 - INFO - __main__ -   epoch 13 step 43100 loss 0.0935
10/19/2022 06:33:39 - INFO - __main__ -   epoch 13 step 43200 loss 0.0974
10/19/2022 06:33:58 - INFO - __main__ -   epoch 13 step 43300 loss 0.0967
10/19/2022 06:34:16 - INFO - __main__ -   epoch 13 step 43400 loss 0.0945
10/19/2022 06:34:35 - INFO - __main__ -   epoch 13 step 43500 loss 0.097
10/19/2022 06:34:53 - INFO - __main__ -   epoch 13 step 43600 loss 0.098
10/19/2022 06:35:12 - INFO - __main__ -   epoch 13 step 43700 loss 0.0967
10/19/2022 06:35:21 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 06:35:21 - INFO - __main__ -     Num examples = 1000
10/19/2022 06:35:21 - INFO - __main__ -     Batch size = 32
10/19/2022 06:35:24 - INFO - __main__ -     eval_ppl = 2.64399
10/19/2022 06:35:24 - INFO - __main__ -     ********************
10/19/2022 06:42:34 - INFO - __main__ -     bleu-4 = 32.98 
10/19/2022 06:42:34 - INFO - __main__ -     EM = 17.5 
10/19/2022 06:42:34 - INFO - __main__ -     ********************
10/19/2022 06:42:43 - INFO - __main__ -   epoch 14 step 43800 loss 0.0871
10/19/2022 06:43:01 - INFO - __main__ -   epoch 14 step 43900 loss 0.0739
10/19/2022 06:43:20 - INFO - __main__ -   epoch 14 step 44000 loss 0.0779
10/19/2022 06:43:38 - INFO - __main__ -   epoch 14 step 44100 loss 0.077
10/19/2022 06:43:57 - INFO - __main__ -   epoch 14 step 44200 loss 0.0778
10/19/2022 06:44:16 - INFO - __main__ -   epoch 14 step 44300 loss 0.0816
10/19/2022 06:44:34 - INFO - __main__ -   epoch 14 step 44400 loss 0.0765
10/19/2022 06:44:53 - INFO - __main__ -   epoch 14 step 44500 loss 0.0785
10/19/2022 06:45:11 - INFO - __main__ -   epoch 14 step 44600 loss 0.074
10/19/2022 06:45:30 - INFO - __main__ -   epoch 14 step 44700 loss 0.0791
10/19/2022 06:45:48 - INFO - __main__ -   epoch 14 step 44800 loss 0.0774
10/19/2022 06:46:07 - INFO - __main__ -   epoch 14 step 44900 loss 0.0781
10/19/2022 06:46:26 - INFO - __main__ -   epoch 14 step 45000 loss 0.0813
10/19/2022 06:46:44 - INFO - __main__ -   epoch 14 step 45100 loss 0.0826
10/19/2022 06:47:03 - INFO - __main__ -   epoch 14 step 45200 loss 0.0799
10/19/2022 06:47:21 - INFO - __main__ -   epoch 14 step 45300 loss 0.0803
10/19/2022 06:47:40 - INFO - __main__ -   epoch 14 step 45400 loss 0.0819
10/19/2022 06:47:58 - INFO - __main__ -   epoch 14 step 45500 loss 0.0797
10/19/2022 06:48:17 - INFO - __main__ -   epoch 14 step 45600 loss 0.0821
10/19/2022 06:48:35 - INFO - __main__ -   epoch 14 step 45700 loss 0.0804
10/19/2022 06:48:54 - INFO - __main__ -   epoch 14 step 45800 loss 0.0801
10/19/2022 06:49:13 - INFO - __main__ -   epoch 14 step 45900 loss 0.0842
10/19/2022 06:49:31 - INFO - __main__ -   epoch 14 step 46000 loss 0.0789
10/19/2022 06:49:50 - INFO - __main__ -   epoch 14 step 46100 loss 0.0845
10/19/2022 06:50:08 - INFO - __main__ -   epoch 14 step 46200 loss 0.0851
10/19/2022 06:50:27 - INFO - __main__ -   epoch 14 step 46300 loss 0.0818
10/19/2022 06:50:45 - INFO - __main__ -   epoch 14 step 46400 loss 0.0854
10/19/2022 06:51:04 - INFO - __main__ -   epoch 14 step 46500 loss 0.0836
10/19/2022 06:51:23 - INFO - __main__ -   epoch 14 step 46600 loss 0.0865
10/19/2022 06:51:41 - INFO - __main__ -   epoch 14 step 46700 loss 0.0874
10/19/2022 06:52:00 - INFO - __main__ -   epoch 14 step 46800 loss 0.0872
10/19/2022 06:52:14 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 06:52:14 - INFO - __main__ -     Num examples = 1000
10/19/2022 06:52:14 - INFO - __main__ -     Batch size = 32
10/19/2022 06:52:16 - INFO - __main__ -     eval_ppl = 2.66644
10/19/2022 06:52:16 - INFO - __main__ -     ********************
10/19/2022 06:59:47 - INFO - __main__ -     bleu-4 = 33.37 
10/19/2022 06:59:47 - INFO - __main__ -     EM = 17.2 
10/19/2022 06:59:47 - INFO - __main__ -     ********************
10/19/2022 06:59:51 - INFO - __main__ -   epoch 15 step 46900 loss 0.0824
10/19/2022 07:00:10 - INFO - __main__ -   epoch 15 step 47000 loss 0.0668
10/19/2022 07:00:28 - INFO - __main__ -   epoch 15 step 47100 loss 0.0659
10/19/2022 07:00:47 - INFO - __main__ -   epoch 15 step 47200 loss 0.0697
10/19/2022 07:01:05 - INFO - __main__ -   epoch 15 step 47300 loss 0.0667
10/19/2022 07:01:24 - INFO - __main__ -   epoch 15 step 47400 loss 0.0676
10/19/2022 07:01:42 - INFO - __main__ -   epoch 15 step 47500 loss 0.0691
10/19/2022 07:02:01 - INFO - __main__ -   epoch 15 step 47600 loss 0.0696
10/19/2022 07:02:20 - INFO - __main__ -   epoch 15 step 47700 loss 0.0664
10/19/2022 07:02:38 - INFO - __main__ -   epoch 15 step 47800 loss 0.067
10/19/2022 07:02:57 - INFO - __main__ -   epoch 15 step 47900 loss 0.0692
10/19/2022 07:03:15 - INFO - __main__ -   epoch 15 step 48000 loss 0.0721
10/19/2022 07:03:34 - INFO - __main__ -   epoch 15 step 48100 loss 0.0696
10/19/2022 07:03:52 - INFO - __main__ -   epoch 15 step 48200 loss 0.0702
10/19/2022 07:04:11 - INFO - __main__ -   epoch 15 step 48300 loss 0.0734
10/19/2022 07:04:30 - INFO - __main__ -   epoch 15 step 48400 loss 0.0701
10/19/2022 07:04:48 - INFO - __main__ -   epoch 15 step 48500 loss 0.074
10/19/2022 07:05:07 - INFO - __main__ -   epoch 15 step 48600 loss 0.0745
10/19/2022 07:05:25 - INFO - __main__ -   epoch 15 step 48700 loss 0.0718
10/19/2022 07:05:44 - INFO - __main__ -   epoch 15 step 48800 loss 0.0745
10/19/2022 07:06:02 - INFO - __main__ -   epoch 15 step 48900 loss 0.0723
10/19/2022 07:06:21 - INFO - __main__ -   epoch 15 step 49000 loss 0.0739
10/19/2022 07:06:40 - INFO - __main__ -   epoch 15 step 49100 loss 0.0753
10/19/2022 07:06:58 - INFO - __main__ -   epoch 15 step 49200 loss 0.0735
10/19/2022 07:07:17 - INFO - __main__ -   epoch 15 step 49300 loss 0.0769
10/19/2022 07:07:35 - INFO - __main__ -   epoch 15 step 49400 loss 0.08
10/19/2022 07:07:54 - INFO - __main__ -   epoch 15 step 49500 loss 0.0766
10/19/2022 07:08:13 - INFO - __main__ -   epoch 15 step 49600 loss 0.0746
10/19/2022 07:08:31 - INFO - __main__ -   epoch 15 step 49700 loss 0.0743
10/19/2022 07:08:50 - INFO - __main__ -   epoch 15 step 49800 loss 0.073
10/19/2022 07:09:08 - INFO - __main__ -   epoch 15 step 49900 loss 0.0732
10/19/2022 07:09:27 - INFO - __main__ -   epoch 15 step 50000 loss 0.0716
10/19/2022 07:09:27 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 07:09:27 - INFO - __main__ -     Num examples = 1000
10/19/2022 07:09:27 - INFO - __main__ -     Batch size = 32
10/19/2022 07:09:29 - INFO - __main__ -     eval_ppl = 2.75266
10/19/2022 07:09:29 - INFO - __main__ -     ********************
10/19/2022 07:16:47 - INFO - __main__ -     bleu-4 = 33.14 
10/19/2022 07:16:47 - INFO - __main__ -     EM = 16.7 
10/19/2022 07:16:47 - INFO - __main__ -     ********************
10/19/2022 07:17:05 - INFO - __main__ -   epoch 16 step 50100 loss 0.0595
10/19/2022 07:17:24 - INFO - __main__ -   epoch 16 step 50200 loss 0.0601
10/19/2022 07:17:42 - INFO - __main__ -   epoch 16 step 50300 loss 0.0615
10/19/2022 07:18:01 - INFO - __main__ -   epoch 16 step 50400 loss 0.0605
10/19/2022 07:18:19 - INFO - __main__ -   epoch 16 step 50500 loss 0.0603
10/19/2022 07:18:38 - INFO - __main__ -   epoch 16 step 50600 loss 0.0582
10/19/2022 07:18:56 - INFO - __main__ -   epoch 16 step 50700 loss 0.06
10/19/2022 07:19:15 - INFO - __main__ -   epoch 16 step 50800 loss 0.0575
10/19/2022 07:19:34 - INFO - __main__ -   epoch 16 step 50900 loss 0.0633
10/19/2022 07:19:52 - INFO - __main__ -   epoch 16 step 51000 loss 0.0602
10/19/2022 07:20:11 - INFO - __main__ -   epoch 16 step 51100 loss 0.0639
10/19/2022 07:20:29 - INFO - __main__ -   epoch 16 step 51200 loss 0.0658
10/19/2022 07:20:48 - INFO - __main__ -   epoch 16 step 51300 loss 0.0644
10/19/2022 07:21:06 - INFO - __main__ -   epoch 16 step 51400 loss 0.0614
10/19/2022 07:21:25 - INFO - __main__ -   epoch 16 step 51500 loss 0.0633
10/19/2022 07:21:44 - INFO - __main__ -   epoch 16 step 51600 loss 0.0653
10/19/2022 07:22:02 - INFO - __main__ -   epoch 16 step 51700 loss 0.0673
10/19/2022 07:22:21 - INFO - __main__ -   epoch 16 step 51800 loss 0.0637
10/19/2022 07:22:39 - INFO - __main__ -   epoch 16 step 51900 loss 0.0643
10/19/2022 07:22:58 - INFO - __main__ -   epoch 16 step 52000 loss 0.0642
10/19/2022 07:23:17 - INFO - __main__ -   epoch 16 step 52100 loss 0.0645
10/19/2022 07:23:35 - INFO - __main__ -   epoch 16 step 52200 loss 0.0624
10/19/2022 07:23:54 - INFO - __main__ -   epoch 16 step 52300 loss 0.0634
10/19/2022 07:24:13 - INFO - __main__ -   epoch 16 step 52400 loss 0.0663
10/19/2022 07:24:32 - INFO - __main__ -   epoch 16 step 52500 loss 0.0653
10/19/2022 07:24:50 - INFO - __main__ -   epoch 16 step 52600 loss 0.0655
10/19/2022 07:25:09 - INFO - __main__ -   epoch 16 step 52700 loss 0.0666
10/19/2022 07:25:28 - INFO - __main__ -   epoch 16 step 52800 loss 0.0703
10/19/2022 07:25:46 - INFO - __main__ -   epoch 16 step 52900 loss 0.0671
10/19/2022 07:26:05 - INFO - __main__ -   epoch 16 step 53000 loss 0.0682
10/19/2022 07:26:24 - INFO - __main__ -   epoch 16 step 53100 loss 0.0646
10/19/2022 07:26:28 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 07:26:28 - INFO - __main__ -     Num examples = 1000
10/19/2022 07:26:28 - INFO - __main__ -     Batch size = 32
10/19/2022 07:26:31 - INFO - __main__ -     eval_ppl = 2.82165
10/19/2022 07:26:31 - INFO - __main__ -     ********************
10/19/2022 07:33:49 - INFO - __main__ -     bleu-4 = 33.36 
10/19/2022 07:33:49 - INFO - __main__ -     EM = 17.1 
10/19/2022 07:33:49 - INFO - __main__ -     ********************
10/19/2022 07:34:03 - INFO - __main__ -   epoch 17 step 53200 loss 0.0575
10/19/2022 07:34:21 - INFO - __main__ -   epoch 17 step 53300 loss 0.0539
10/19/2022 07:34:40 - INFO - __main__ -   epoch 17 step 53400 loss 0.0542
10/19/2022 07:34:58 - INFO - __main__ -   epoch 17 step 53500 loss 0.0546
10/19/2022 07:35:17 - INFO - __main__ -   epoch 17 step 53600 loss 0.0526
10/19/2022 07:35:35 - INFO - __main__ -   epoch 17 step 53700 loss 0.0528
10/19/2022 07:35:54 - INFO - __main__ -   epoch 17 step 53800 loss 0.0564
10/19/2022 07:36:12 - INFO - __main__ -   epoch 17 step 53900 loss 0.0563
10/19/2022 07:36:31 - INFO - __main__ -   epoch 17 step 54000 loss 0.0562
10/19/2022 07:36:49 - INFO - __main__ -   epoch 17 step 54100 loss 0.0536
10/19/2022 07:37:08 - INFO - __main__ -   epoch 17 step 54200 loss 0.0554
10/19/2022 07:37:27 - INFO - __main__ -   epoch 17 step 54300 loss 0.0539
10/19/2022 07:37:45 - INFO - __main__ -   epoch 17 step 54400 loss 0.0569
10/19/2022 07:38:04 - INFO - __main__ -   epoch 17 step 54500 loss 0.0578
10/19/2022 07:38:22 - INFO - __main__ -   epoch 17 step 54600 loss 0.0562
10/19/2022 07:38:41 - INFO - __main__ -   epoch 17 step 54700 loss 0.0596
10/19/2022 07:38:59 - INFO - __main__ -   epoch 17 step 54800 loss 0.0562
10/19/2022 07:39:18 - INFO - __main__ -   epoch 17 step 54900 loss 0.0572
10/19/2022 07:39:37 - INFO - __main__ -   epoch 17 step 55000 loss 0.0575
10/19/2022 07:39:55 - INFO - __main__ -   epoch 17 step 55100 loss 0.0568
10/19/2022 07:40:14 - INFO - __main__ -   epoch 17 step 55200 loss 0.0588
10/19/2022 07:40:32 - INFO - __main__ -   epoch 17 step 55300 loss 0.0575
10/19/2022 07:40:51 - INFO - __main__ -   epoch 17 step 55400 loss 0.0592
10/19/2022 07:41:09 - INFO - __main__ -   epoch 17 step 55500 loss 0.0601
10/19/2022 07:41:28 - INFO - __main__ -   epoch 17 step 55600 loss 0.0559
10/19/2022 07:41:47 - INFO - __main__ -   epoch 17 step 55700 loss 0.0592
10/19/2022 07:42:05 - INFO - __main__ -   epoch 17 step 55800 loss 0.0601
10/19/2022 07:42:24 - INFO - __main__ -   epoch 17 step 55900 loss 0.0591
10/19/2022 07:42:42 - INFO - __main__ -   epoch 17 step 56000 loss 0.0601
10/19/2022 07:43:01 - INFO - __main__ -   epoch 17 step 56100 loss 0.06
10/19/2022 07:43:19 - INFO - __main__ -   epoch 17 step 56200 loss 0.0605
10/19/2022 07:43:29 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 07:43:29 - INFO - __main__ -     Num examples = 1000
10/19/2022 07:43:29 - INFO - __main__ -     Batch size = 32
10/19/2022 07:43:31 - INFO - __main__ -     eval_ppl = 2.86834
10/19/2022 07:43:31 - INFO - __main__ -     ********************
10/19/2022 07:50:33 - INFO - __main__ -     bleu-4 = 33.25 
10/19/2022 07:50:33 - INFO - __main__ -     EM = 17.1 
10/19/2022 07:50:33 - INFO - __main__ -     ********************
10/19/2022 07:50:42 - INFO - __main__ -   epoch 18 step 56300 loss 0.0526
10/19/2022 07:51:00 - INFO - __main__ -   epoch 18 step 56400 loss 0.049
10/19/2022 07:51:19 - INFO - __main__ -   epoch 18 step 56500 loss 0.05
10/19/2022 07:51:37 - INFO - __main__ -   epoch 18 step 56600 loss 0.0472
10/19/2022 07:51:56 - INFO - __main__ -   epoch 18 step 56700 loss 0.0487
10/19/2022 07:52:14 - INFO - __main__ -   epoch 18 step 56800 loss 0.0494
10/19/2022 07:52:33 - INFO - __main__ -   epoch 18 step 56900 loss 0.0502
10/19/2022 07:52:52 - INFO - __main__ -   epoch 18 step 57000 loss 0.0492
10/19/2022 07:53:10 - INFO - __main__ -   epoch 18 step 57100 loss 0.0491
10/19/2022 07:53:29 - INFO - __main__ -   epoch 18 step 57200 loss 0.0491
10/19/2022 07:53:47 - INFO - __main__ -   epoch 18 step 57300 loss 0.0479
10/19/2022 07:54:06 - INFO - __main__ -   epoch 18 step 57400 loss 0.0515
10/19/2022 07:54:24 - INFO - __main__ -   epoch 18 step 57500 loss 0.0504
10/19/2022 07:54:43 - INFO - __main__ -   epoch 18 step 57600 loss 0.0501
10/19/2022 07:55:01 - INFO - __main__ -   epoch 18 step 57700 loss 0.0506
10/19/2022 07:55:20 - INFO - __main__ -   epoch 18 step 57800 loss 0.0521
10/19/2022 07:55:39 - INFO - __main__ -   epoch 18 step 57900 loss 0.05
10/19/2022 07:55:57 - INFO - __main__ -   epoch 18 step 58000 loss 0.0502
10/19/2022 07:56:16 - INFO - __main__ -   epoch 18 step 58100 loss 0.0508
10/19/2022 07:56:34 - INFO - __main__ -   epoch 18 step 58200 loss 0.0518
10/19/2022 07:56:53 - INFO - __main__ -   epoch 18 step 58300 loss 0.0521
10/19/2022 07:57:11 - INFO - __main__ -   epoch 18 step 58400 loss 0.0535
10/19/2022 07:57:30 - INFO - __main__ -   epoch 18 step 58500 loss 0.0509
10/19/2022 07:57:49 - INFO - __main__ -   epoch 18 step 58600 loss 0.053
10/19/2022 07:58:07 - INFO - __main__ -   epoch 18 step 58700 loss 0.051
10/19/2022 07:58:26 - INFO - __main__ -   epoch 18 step 58800 loss 0.05
10/19/2022 07:58:44 - INFO - __main__ -   epoch 18 step 58900 loss 0.0529
10/19/2022 07:59:03 - INFO - __main__ -   epoch 18 step 59000 loss 0.0539
10/19/2022 07:59:21 - INFO - __main__ -   epoch 18 step 59100 loss 0.051
10/19/2022 07:59:40 - INFO - __main__ -   epoch 18 step 59200 loss 0.0534
10/19/2022 07:59:59 - INFO - __main__ -   epoch 18 step 59300 loss 0.0562
10/19/2022 08:00:13 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 08:00:13 - INFO - __main__ -     Num examples = 1000
10/19/2022 08:00:13 - INFO - __main__ -     Batch size = 32
10/19/2022 08:00:15 - INFO - __main__ -     eval_ppl = 2.91896
10/19/2022 08:00:15 - INFO - __main__ -     ********************
10/19/2022 08:07:48 - INFO - __main__ -     bleu-4 = 34.03 
10/19/2022 08:07:48 - INFO - __main__ -     EM = 17.5 
10/19/2022 08:07:48 - INFO - __main__ -     ********************
10/19/2022 08:07:53 - INFO - __main__ -   epoch 19 step 59400 loss 0.0532
10/19/2022 08:08:11 - INFO - __main__ -   epoch 19 step 59500 loss 0.0418
10/19/2022 08:08:30 - INFO - __main__ -   epoch 19 step 59600 loss 0.0418
10/19/2022 08:08:48 - INFO - __main__ -   epoch 19 step 59700 loss 0.043
10/19/2022 08:09:07 - INFO - __main__ -   epoch 19 step 59800 loss 0.0422
10/19/2022 08:09:25 - INFO - __main__ -   epoch 19 step 59900 loss 0.0435
10/19/2022 08:09:44 - INFO - __main__ -   epoch 19 step 60000 loss 0.043
10/19/2022 08:10:02 - INFO - __main__ -   epoch 19 step 60100 loss 0.0449
10/19/2022 08:10:21 - INFO - __main__ -   epoch 19 step 60200 loss 0.0471
10/19/2022 08:10:40 - INFO - __main__ -   epoch 19 step 60300 loss 0.0451
10/19/2022 08:10:58 - INFO - __main__ -   epoch 19 step 60400 loss 0.0453
10/19/2022 08:11:17 - INFO - __main__ -   epoch 19 step 60500 loss 0.0456
10/19/2022 08:11:35 - INFO - __main__ -   epoch 19 step 60600 loss 0.047
10/19/2022 08:11:54 - INFO - __main__ -   epoch 19 step 60700 loss 0.0462
10/19/2022 08:12:12 - INFO - __main__ -   epoch 19 step 60800 loss 0.0482
10/19/2022 08:12:31 - INFO - __main__ -   epoch 19 step 60900 loss 0.0444
10/19/2022 08:12:50 - INFO - __main__ -   epoch 19 step 61000 loss 0.0445
10/19/2022 08:13:08 - INFO - __main__ -   epoch 19 step 61100 loss 0.0452
10/19/2022 08:13:27 - INFO - __main__ -   epoch 19 step 61200 loss 0.0464
10/19/2022 08:13:45 - INFO - __main__ -   epoch 19 step 61300 loss 0.0459
10/19/2022 08:14:04 - INFO - __main__ -   epoch 19 step 61400 loss 0.0457
10/19/2022 08:14:22 - INFO - __main__ -   epoch 19 step 61500 loss 0.049
10/19/2022 08:14:41 - INFO - __main__ -   epoch 19 step 61600 loss 0.0465
10/19/2022 08:15:00 - INFO - __main__ -   epoch 19 step 61700 loss 0.0475
10/19/2022 08:15:18 - INFO - __main__ -   epoch 19 step 61800 loss 0.0472
10/19/2022 08:15:37 - INFO - __main__ -   epoch 19 step 61900 loss 0.0471
10/19/2022 08:15:55 - INFO - __main__ -   epoch 19 step 62000 loss 0.0491
10/19/2022 08:16:14 - INFO - __main__ -   epoch 19 step 62100 loss 0.0478
10/19/2022 08:16:32 - INFO - __main__ -   epoch 19 step 62200 loss 0.0493
10/19/2022 08:16:51 - INFO - __main__ -   epoch 19 step 62300 loss 0.0447
10/19/2022 08:17:09 - INFO - __main__ -   epoch 19 step 62400 loss 0.0474
10/19/2022 08:17:28 - INFO - __main__ -   epoch 19 step 62500 loss 0.0481
10/19/2022 08:17:28 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 08:17:28 - INFO - __main__ -     Num examples = 1000
10/19/2022 08:17:28 - INFO - __main__ -     Batch size = 32
10/19/2022 08:17:31 - INFO - __main__ -     eval_ppl = 2.98398
10/19/2022 08:17:31 - INFO - __main__ -     ********************
10/19/2022 08:24:45 - INFO - __main__ -     bleu-4 = 33.8 
10/19/2022 08:24:45 - INFO - __main__ -     EM = 17.2 
10/19/2022 08:24:45 - INFO - __main__ -     ********************
10/19/2022 08:25:04 - INFO - __main__ -   epoch 20 step 62600 loss 0.0386
10/19/2022 08:25:22 - INFO - __main__ -   epoch 20 step 62700 loss 0.0401
10/19/2022 08:25:41 - INFO - __main__ -   epoch 20 step 62800 loss 0.0391
10/19/2022 08:25:59 - INFO - __main__ -   epoch 20 step 62900 loss 0.0398
10/19/2022 08:26:18 - INFO - __main__ -   epoch 20 step 63000 loss 0.0394
10/19/2022 08:26:36 - INFO - __main__ -   epoch 20 step 63100 loss 0.041
10/19/2022 08:26:55 - INFO - __main__ -   epoch 20 step 63200 loss 0.0395
10/19/2022 08:27:13 - INFO - __main__ -   epoch 20 step 63300 loss 0.0405
10/19/2022 08:27:32 - INFO - __main__ -   epoch 20 step 63400 loss 0.0398
10/19/2022 08:27:50 - INFO - __main__ -   epoch 20 step 63500 loss 0.0421
10/19/2022 08:28:09 - INFO - __main__ -   epoch 20 step 63600 loss 0.0395
10/19/2022 08:28:27 - INFO - __main__ -   epoch 20 step 63700 loss 0.0419
10/19/2022 08:28:46 - INFO - __main__ -   epoch 20 step 63800 loss 0.041
10/19/2022 08:29:05 - INFO - __main__ -   epoch 20 step 63900 loss 0.0416
10/19/2022 08:29:23 - INFO - __main__ -   epoch 20 step 64000 loss 0.04
10/19/2022 08:29:42 - INFO - __main__ -   epoch 20 step 64100 loss 0.0413
10/19/2022 08:30:00 - INFO - __main__ -   epoch 20 step 64200 loss 0.0414
10/19/2022 08:30:19 - INFO - __main__ -   epoch 20 step 64300 loss 0.0401
10/19/2022 08:30:38 - INFO - __main__ -   epoch 20 step 64400 loss 0.0411
10/19/2022 08:30:56 - INFO - __main__ -   epoch 20 step 64500 loss 0.042
10/19/2022 08:31:15 - INFO - __main__ -   epoch 20 step 64600 loss 0.0412
10/19/2022 08:31:33 - INFO - __main__ -   epoch 20 step 64700 loss 0.0436
10/19/2022 08:31:52 - INFO - __main__ -   epoch 20 step 64800 loss 0.0433
10/19/2022 08:32:11 - INFO - __main__ -   epoch 20 step 64900 loss 0.0461
10/19/2022 08:32:29 - INFO - __main__ -   epoch 20 step 65000 loss 0.0421
10/19/2022 08:32:48 - INFO - __main__ -   epoch 20 step 65100 loss 0.0412
10/19/2022 08:33:06 - INFO - __main__ -   epoch 20 step 65200 loss 0.0436
10/19/2022 08:33:25 - INFO - __main__ -   epoch 20 step 65300 loss 0.0408
10/19/2022 08:33:43 - INFO - __main__ -   epoch 20 step 65400 loss 0.0424
10/19/2022 08:34:02 - INFO - __main__ -   epoch 20 step 65500 loss 0.0419
10/19/2022 08:34:21 - INFO - __main__ -   epoch 20 step 65600 loss 0.0422
10/19/2022 08:34:25 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 08:34:25 - INFO - __main__ -     Num examples = 1000
10/19/2022 08:34:25 - INFO - __main__ -     Batch size = 32
10/19/2022 08:34:28 - INFO - __main__ -     eval_ppl = 3.02582
10/19/2022 08:34:28 - INFO - __main__ -     ********************
10/19/2022 08:41:27 - INFO - __main__ -     bleu-4 = 32.85 
10/19/2022 08:41:27 - INFO - __main__ -     EM = 16.6 
10/19/2022 08:41:27 - INFO - __main__ -     ********************
10/19/2022 08:41:41 - INFO - __main__ -   epoch 21 step 65700 loss 0.0378
10/19/2022 08:41:59 - INFO - __main__ -   epoch 21 step 65800 loss 0.0354
10/19/2022 08:42:18 - INFO - __main__ -   epoch 21 step 65900 loss 0.0365
10/19/2022 08:42:36 - INFO - __main__ -   epoch 21 step 66000 loss 0.0381
10/19/2022 08:42:55 - INFO - __main__ -   epoch 21 step 66100 loss 0.0359
10/19/2022 08:43:13 - INFO - __main__ -   epoch 21 step 66200 loss 0.0366
10/19/2022 08:43:32 - INFO - __main__ -   epoch 21 step 66300 loss 0.0369
10/19/2022 08:43:50 - INFO - __main__ -   epoch 21 step 66400 loss 0.0364
10/19/2022 08:44:09 - INFO - __main__ -   epoch 21 step 66500 loss 0.0366
10/19/2022 08:44:28 - INFO - __main__ -   epoch 21 step 66600 loss 0.0365
10/19/2022 08:44:46 - INFO - __main__ -   epoch 21 step 66700 loss 0.0375
10/19/2022 08:45:05 - INFO - __main__ -   epoch 21 step 66800 loss 0.0376
10/19/2022 08:45:23 - INFO - __main__ -   epoch 21 step 66900 loss 0.0354
10/19/2022 08:45:42 - INFO - __main__ -   epoch 21 step 67000 loss 0.0391
10/19/2022 08:46:00 - INFO - __main__ -   epoch 21 step 67100 loss 0.0383
10/19/2022 08:46:19 - INFO - __main__ -   epoch 21 step 67200 loss 0.0381
10/19/2022 08:46:38 - INFO - __main__ -   epoch 21 step 67300 loss 0.0381
10/19/2022 08:46:56 - INFO - __main__ -   epoch 21 step 67400 loss 0.0377
10/19/2022 08:47:15 - INFO - __main__ -   epoch 21 step 67500 loss 0.0382
10/19/2022 08:47:33 - INFO - __main__ -   epoch 21 step 67600 loss 0.0397
10/19/2022 08:47:52 - INFO - __main__ -   epoch 21 step 67700 loss 0.0373
10/19/2022 08:48:10 - INFO - __main__ -   epoch 21 step 67800 loss 0.0382
10/19/2022 08:48:29 - INFO - __main__ -   epoch 21 step 67900 loss 0.0369
10/19/2022 08:48:48 - INFO - __main__ -   epoch 21 step 68000 loss 0.0375
10/19/2022 08:49:06 - INFO - __main__ -   epoch 21 step 68100 loss 0.04
10/19/2022 08:49:25 - INFO - __main__ -   epoch 21 step 68200 loss 0.0367
10/19/2022 08:49:43 - INFO - __main__ -   epoch 21 step 68300 loss 0.0377
10/19/2022 08:50:02 - INFO - __main__ -   epoch 21 step 68400 loss 0.0367
10/19/2022 08:50:21 - INFO - __main__ -   epoch 21 step 68500 loss 0.0369
10/19/2022 08:50:39 - INFO - __main__ -   epoch 21 step 68600 loss 0.0377
10/19/2022 08:50:58 - INFO - __main__ -   epoch 21 step 68700 loss 0.0386
10/19/2022 08:51:07 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 08:51:07 - INFO - __main__ -     Num examples = 1000
10/19/2022 08:51:07 - INFO - __main__ -     Batch size = 32
10/19/2022 08:51:10 - INFO - __main__ -     eval_ppl = 3.06672
10/19/2022 08:51:10 - INFO - __main__ -     ********************
10/19/2022 08:58:13 - INFO - __main__ -     bleu-4 = 33.12 
10/19/2022 08:58:13 - INFO - __main__ -     EM = 17.6 
10/19/2022 08:58:13 - INFO - __main__ -     ********************
10/19/2022 08:58:22 - INFO - __main__ -   epoch 22 step 68800 loss 0.0362
10/19/2022 08:58:40 - INFO - __main__ -   epoch 22 step 68900 loss 0.0325
10/19/2022 08:58:59 - INFO - __main__ -   epoch 22 step 69000 loss 0.0329
10/19/2022 08:59:17 - INFO - __main__ -   epoch 22 step 69100 loss 0.0344
10/19/2022 08:59:36 - INFO - __main__ -   epoch 22 step 69200 loss 0.0326
10/19/2022 08:59:55 - INFO - __main__ -   epoch 22 step 69300 loss 0.0333
10/19/2022 09:00:13 - INFO - __main__ -   epoch 22 step 69400 loss 0.033
10/19/2022 09:00:32 - INFO - __main__ -   epoch 22 step 69500 loss 0.0329
10/19/2022 09:00:50 - INFO - __main__ -   epoch 22 step 69600 loss 0.0325
10/19/2022 09:01:09 - INFO - __main__ -   epoch 22 step 69700 loss 0.0326
10/19/2022 09:01:27 - INFO - __main__ -   epoch 22 step 69800 loss 0.0342
10/19/2022 09:01:46 - INFO - __main__ -   epoch 22 step 69900 loss 0.0325
10/19/2022 09:02:05 - INFO - __main__ -   epoch 22 step 70000 loss 0.0333
10/19/2022 09:02:23 - INFO - __main__ -   epoch 22 step 70100 loss 0.0336
10/19/2022 09:02:42 - INFO - __main__ -   epoch 22 step 70200 loss 0.0331
10/19/2022 09:03:00 - INFO - __main__ -   epoch 22 step 70300 loss 0.0341
10/19/2022 09:03:19 - INFO - __main__ -   epoch 22 step 70400 loss 0.0348
10/19/2022 09:03:37 - INFO - __main__ -   epoch 22 step 70500 loss 0.035
10/19/2022 09:03:56 - INFO - __main__ -   epoch 22 step 70600 loss 0.0354
10/19/2022 09:04:15 - INFO - __main__ -   epoch 22 step 70700 loss 0.035
10/19/2022 09:04:33 - INFO - __main__ -   epoch 22 step 70800 loss 0.0343
10/19/2022 09:04:52 - INFO - __main__ -   epoch 22 step 70900 loss 0.0352
10/19/2022 09:05:10 - INFO - __main__ -   epoch 22 step 71000 loss 0.0333
10/19/2022 09:05:29 - INFO - __main__ -   epoch 22 step 71100 loss 0.0338
10/19/2022 09:05:47 - INFO - __main__ -   epoch 22 step 71200 loss 0.0346
10/19/2022 09:06:06 - INFO - __main__ -   epoch 22 step 71300 loss 0.0348
10/19/2022 09:06:25 - INFO - __main__ -   epoch 22 step 71400 loss 0.0355
10/19/2022 09:06:43 - INFO - __main__ -   epoch 22 step 71500 loss 0.0346
10/19/2022 09:07:02 - INFO - __main__ -   epoch 22 step 71600 loss 0.0357
10/19/2022 09:07:20 - INFO - __main__ -   epoch 22 step 71700 loss 0.0354
10/19/2022 09:07:39 - INFO - __main__ -   epoch 22 step 71800 loss 0.036
10/19/2022 09:07:53 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 09:07:53 - INFO - __main__ -     Num examples = 1000
10/19/2022 09:07:53 - INFO - __main__ -     Batch size = 32
10/19/2022 09:07:55 - INFO - __main__ -     eval_ppl = 3.09885
10/19/2022 09:07:55 - INFO - __main__ -     ********************
10/19/2022 09:15:13 - INFO - __main__ -     bleu-4 = 33.88 
10/19/2022 09:15:13 - INFO - __main__ -     EM = 18.1 
10/19/2022 09:15:13 - INFO - __main__ -     ********************
10/19/2022 09:15:13 - INFO - __main__ -     Best score:51.980000000000004
10/19/2022 09:15:13 - INFO - __main__ -     ********************
10/19/2022 09:15:31 - INFO - __main__ -   epoch 23 step 71900 loss 0.0336
10/19/2022 09:15:50 - INFO - __main__ -   epoch 23 step 72000 loss 0.0298
10/19/2022 09:16:08 - INFO - __main__ -   epoch 23 step 72100 loss 0.0297
10/19/2022 09:16:27 - INFO - __main__ -   epoch 23 step 72200 loss 0.0299
10/19/2022 09:16:46 - INFO - __main__ -   epoch 23 step 72300 loss 0.0296
10/19/2022 09:17:04 - INFO - __main__ -   epoch 23 step 72400 loss 0.0302
10/19/2022 09:17:23 - INFO - __main__ -   epoch 23 step 72500 loss 0.0288
10/19/2022 09:17:41 - INFO - __main__ -   epoch 23 step 72600 loss 0.0297
10/19/2022 09:18:00 - INFO - __main__ -   epoch 23 step 72700 loss 0.0294
10/19/2022 09:18:18 - INFO - __main__ -   epoch 23 step 72800 loss 0.0311
10/19/2022 09:18:37 - INFO - __main__ -   epoch 23 step 72900 loss 0.0315
10/19/2022 09:18:56 - INFO - __main__ -   epoch 23 step 73000 loss 0.031
10/19/2022 09:19:14 - INFO - __main__ -   epoch 23 step 73100 loss 0.03
10/19/2022 09:19:33 - INFO - __main__ -   epoch 23 step 73200 loss 0.0309
10/19/2022 09:19:51 - INFO - __main__ -   epoch 23 step 73300 loss 0.0302
10/19/2022 09:20:10 - INFO - __main__ -   epoch 23 step 73400 loss 0.0319
10/19/2022 09:20:28 - INFO - __main__ -   epoch 23 step 73500 loss 0.0322
10/19/2022 09:20:47 - INFO - __main__ -   epoch 23 step 73600 loss 0.0316
10/19/2022 09:21:06 - INFO - __main__ -   epoch 23 step 73700 loss 0.0311
10/19/2022 09:21:24 - INFO - __main__ -   epoch 23 step 73800 loss 0.0309
10/19/2022 09:21:43 - INFO - __main__ -   epoch 23 step 73900 loss 0.0322
10/19/2022 09:22:01 - INFO - __main__ -   epoch 23 step 74000 loss 0.0311
10/19/2022 09:22:20 - INFO - __main__ -   epoch 23 step 74100 loss 0.032
10/19/2022 09:22:38 - INFO - __main__ -   epoch 23 step 74200 loss 0.0316
10/19/2022 09:22:57 - INFO - __main__ -   epoch 23 step 74300 loss 0.0318
10/19/2022 09:23:16 - INFO - __main__ -   epoch 23 step 74400 loss 0.032
10/19/2022 09:23:34 - INFO - __main__ -   epoch 23 step 74500 loss 0.0309
10/19/2022 09:23:53 - INFO - __main__ -   epoch 23 step 74600 loss 0.0315
10/19/2022 09:24:11 - INFO - __main__ -   epoch 23 step 74700 loss 0.0321
10/19/2022 09:24:30 - INFO - __main__ -   epoch 23 step 74800 loss 0.0308
10/19/2022 09:24:48 - INFO - __main__ -   epoch 23 step 74900 loss 0.0302
10/19/2022 09:25:07 - INFO - __main__ -   epoch 23 step 75000 loss 0.0321
10/19/2022 09:25:07 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 09:25:07 - INFO - __main__ -     Num examples = 1000
10/19/2022 09:25:07 - INFO - __main__ -     Batch size = 32
10/19/2022 09:25:10 - INFO - __main__ -     eval_ppl = 3.14917
10/19/2022 09:25:10 - INFO - __main__ -     ********************
10/19/2022 09:32:23 - INFO - __main__ -     bleu-4 = 33.55 
10/19/2022 09:32:23 - INFO - __main__ -     EM = 17.5 
10/19/2022 09:32:23 - INFO - __main__ -     ********************
10/19/2022 09:32:41 - INFO - __main__ -   epoch 24 step 75100 loss 0.0271
10/19/2022 09:33:00 - INFO - __main__ -   epoch 24 step 75200 loss 0.0287
10/19/2022 09:33:18 - INFO - __main__ -   epoch 24 step 75300 loss 0.0275
10/19/2022 09:33:37 - INFO - __main__ -   epoch 24 step 75400 loss 0.0268
10/19/2022 09:33:55 - INFO - __main__ -   epoch 24 step 75500 loss 0.0279
10/19/2022 09:34:14 - INFO - __main__ -   epoch 24 step 75600 loss 0.0292
10/19/2022 09:34:33 - INFO - __main__ -   epoch 24 step 75700 loss 0.0291
10/19/2022 09:34:51 - INFO - __main__ -   epoch 24 step 75800 loss 0.0282
10/19/2022 09:35:10 - INFO - __main__ -   epoch 24 step 75900 loss 0.0279
10/19/2022 09:35:28 - INFO - __main__ -   epoch 24 step 76000 loss 0.0284
10/19/2022 09:35:47 - INFO - __main__ -   epoch 24 step 76100 loss 0.0287
10/19/2022 09:36:05 - INFO - __main__ -   epoch 24 step 76200 loss 0.0279
10/19/2022 09:36:24 - INFO - __main__ -   epoch 24 step 76300 loss 0.0291
10/19/2022 09:36:43 - INFO - __main__ -   epoch 24 step 76400 loss 0.0276
10/19/2022 09:37:01 - INFO - __main__ -   epoch 24 step 76500 loss 0.0272
10/19/2022 09:37:20 - INFO - __main__ -   epoch 24 step 76600 loss 0.0276
10/19/2022 09:37:38 - INFO - __main__ -   epoch 24 step 76700 loss 0.0298
10/19/2022 09:37:57 - INFO - __main__ -   epoch 24 step 76800 loss 0.0289
10/19/2022 09:38:16 - INFO - __main__ -   epoch 24 step 76900 loss 0.0289
10/19/2022 09:38:34 - INFO - __main__ -   epoch 24 step 77000 loss 0.0294
10/19/2022 09:38:53 - INFO - __main__ -   epoch 24 step 77100 loss 0.0277
10/19/2022 09:39:11 - INFO - __main__ -   epoch 24 step 77200 loss 0.0275
10/19/2022 09:39:30 - INFO - __main__ -   epoch 24 step 77300 loss 0.0283
10/19/2022 09:39:48 - INFO - __main__ -   epoch 24 step 77400 loss 0.0284
10/19/2022 09:40:07 - INFO - __main__ -   epoch 24 step 77500 loss 0.0288
10/19/2022 09:40:26 - INFO - __main__ -   epoch 24 step 77600 loss 0.0284
10/19/2022 09:40:44 - INFO - __main__ -   epoch 24 step 77700 loss 0.0282
10/19/2022 09:41:03 - INFO - __main__ -   epoch 24 step 77800 loss 0.0283
10/19/2022 09:41:21 - INFO - __main__ -   epoch 24 step 77900 loss 0.029
10/19/2022 09:41:40 - INFO - __main__ -   epoch 24 step 78000 loss 0.0286
10/19/2022 09:41:59 - INFO - __main__ -   epoch 24 step 78100 loss 0.0286
10/19/2022 09:42:03 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 09:42:03 - INFO - __main__ -     Num examples = 1000
10/19/2022 09:42:03 - INFO - __main__ -     Batch size = 32
10/19/2022 09:42:06 - INFO - __main__ -     eval_ppl = 3.18302
10/19/2022 09:42:06 - INFO - __main__ -     ********************
10/19/2022 09:49:24 - INFO - __main__ -     bleu-4 = 33.82 
10/19/2022 09:49:24 - INFO - __main__ -     EM = 17.3 
10/19/2022 09:49:24 - INFO - __main__ -     ********************
10/19/2022 09:49:38 - INFO - __main__ -   epoch 25 step 78200 loss 0.0258
10/19/2022 09:49:56 - INFO - __main__ -   epoch 25 step 78300 loss 0.0262
10/19/2022 09:50:15 - INFO - __main__ -   epoch 25 step 78400 loss 0.0259
10/19/2022 09:50:33 - INFO - __main__ -   epoch 25 step 78500 loss 0.0262
10/19/2022 09:50:52 - INFO - __main__ -   epoch 25 step 78600 loss 0.0264
10/19/2022 09:51:10 - INFO - __main__ -   epoch 25 step 78700 loss 0.0247
10/19/2022 09:51:29 - INFO - __main__ -   epoch 25 step 78800 loss 0.0261
10/19/2022 09:51:48 - INFO - __main__ -   epoch 25 step 78900 loss 0.0253
10/19/2022 09:52:06 - INFO - __main__ -   epoch 25 step 79000 loss 0.0269
10/19/2022 09:52:25 - INFO - __main__ -   epoch 25 step 79100 loss 0.0267
10/19/2022 09:52:44 - INFO - __main__ -   epoch 25 step 79200 loss 0.0257
10/19/2022 09:53:02 - INFO - __main__ -   epoch 25 step 79300 loss 0.0254
10/19/2022 09:53:21 - INFO - __main__ -   epoch 25 step 79400 loss 0.0263
10/19/2022 09:53:40 - INFO - __main__ -   epoch 25 step 79500 loss 0.0251
10/19/2022 09:53:58 - INFO - __main__ -   epoch 25 step 79600 loss 0.0261
10/19/2022 09:54:17 - INFO - __main__ -   epoch 25 step 79700 loss 0.026
10/19/2022 09:54:35 - INFO - __main__ -   epoch 25 step 79800 loss 0.0243
10/19/2022 09:54:54 - INFO - __main__ -   epoch 25 step 79900 loss 0.0262
10/19/2022 09:55:13 - INFO - __main__ -   epoch 25 step 80000 loss 0.0264
10/19/2022 09:55:31 - INFO - __main__ -   epoch 25 step 80100 loss 0.0253
10/19/2022 09:55:50 - INFO - __main__ -   epoch 25 step 80200 loss 0.027
10/19/2022 09:56:09 - INFO - __main__ -   epoch 25 step 80300 loss 0.0254
10/19/2022 09:56:27 - INFO - __main__ -   epoch 25 step 80400 loss 0.0279
10/19/2022 09:56:46 - INFO - __main__ -   epoch 25 step 80500 loss 0.0252
10/19/2022 09:57:05 - INFO - __main__ -   epoch 25 step 80600 loss 0.0259
10/19/2022 09:57:23 - INFO - __main__ -   epoch 25 step 80700 loss 0.0272
10/19/2022 09:57:42 - INFO - __main__ -   epoch 25 step 80800 loss 0.0275
10/19/2022 09:58:01 - INFO - __main__ -   epoch 25 step 80900 loss 0.026
10/19/2022 09:58:19 - INFO - __main__ -   epoch 25 step 81000 loss 0.0257
10/19/2022 09:58:38 - INFO - __main__ -   epoch 25 step 81100 loss 0.0275
10/19/2022 09:58:56 - INFO - __main__ -   epoch 25 step 81200 loss 0.0276
10/19/2022 09:59:06 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 09:59:06 - INFO - __main__ -     Num examples = 1000
10/19/2022 09:59:06 - INFO - __main__ -     Batch size = 32
10/19/2022 09:59:08 - INFO - __main__ -     eval_ppl = 3.21605
10/19/2022 09:59:08 - INFO - __main__ -     ********************
10/19/2022 10:06:10 - INFO - __main__ -     bleu-4 = 33.85 
10/19/2022 10:06:10 - INFO - __main__ -     EM = 17.5 
10/19/2022 10:06:10 - INFO - __main__ -     ********************
10/19/2022 10:06:19 - INFO - __main__ -   epoch 26 step 81300 loss 0.0253
10/19/2022 10:06:38 - INFO - __main__ -   epoch 26 step 81400 loss 0.0244
10/19/2022 10:06:56 - INFO - __main__ -   epoch 26 step 81500 loss 0.0228
10/19/2022 10:07:15 - INFO - __main__ -   epoch 26 step 81600 loss 0.023
10/19/2022 10:07:34 - INFO - __main__ -   epoch 26 step 81700 loss 0.0238
10/19/2022 10:07:52 - INFO - __main__ -   epoch 26 step 81800 loss 0.0237
10/19/2022 10:08:11 - INFO - __main__ -   epoch 26 step 81900 loss 0.023
10/19/2022 10:08:29 - INFO - __main__ -   epoch 26 step 82000 loss 0.0226
10/19/2022 10:08:48 - INFO - __main__ -   epoch 26 step 82100 loss 0.0258
10/19/2022 10:09:06 - INFO - __main__ -   epoch 26 step 82200 loss 0.0241
10/19/2022 10:09:25 - INFO - __main__ -   epoch 26 step 82300 loss 0.0249
10/19/2022 10:09:44 - INFO - __main__ -   epoch 26 step 82400 loss 0.0247
10/19/2022 10:10:02 - INFO - __main__ -   epoch 26 step 82500 loss 0.0241
10/19/2022 10:10:21 - INFO - __main__ -   epoch 26 step 82600 loss 0.0235
10/19/2022 10:10:39 - INFO - __main__ -   epoch 26 step 82700 loss 0.0257
10/19/2022 10:10:58 - INFO - __main__ -   epoch 26 step 82800 loss 0.0242
10/19/2022 10:11:16 - INFO - __main__ -   epoch 26 step 82900 loss 0.0239
10/19/2022 10:11:35 - INFO - __main__ -   epoch 26 step 83000 loss 0.0254
10/19/2022 10:11:54 - INFO - __main__ -   epoch 26 step 83100 loss 0.0246
10/19/2022 10:12:12 - INFO - __main__ -   epoch 26 step 83200 loss 0.0225
10/19/2022 10:12:31 - INFO - __main__ -   epoch 26 step 83300 loss 0.0246
10/19/2022 10:12:49 - INFO - __main__ -   epoch 26 step 83400 loss 0.0248
10/19/2022 10:13:08 - INFO - __main__ -   epoch 26 step 83500 loss 0.0253
10/19/2022 10:13:26 - INFO - __main__ -   epoch 26 step 83600 loss 0.0235
10/19/2022 10:13:45 - INFO - __main__ -   epoch 26 step 83700 loss 0.0239
10/19/2022 10:14:04 - INFO - __main__ -   epoch 26 step 83800 loss 0.0238
10/19/2022 10:14:22 - INFO - __main__ -   epoch 26 step 83900 loss 0.0246
10/19/2022 10:14:41 - INFO - __main__ -   epoch 26 step 84000 loss 0.0246
10/19/2022 10:14:59 - INFO - __main__ -   epoch 26 step 84100 loss 0.0253
10/19/2022 10:15:18 - INFO - __main__ -   epoch 26 step 84200 loss 0.0248
10/19/2022 10:15:36 - INFO - __main__ -   epoch 26 step 84300 loss 0.0233
10/19/2022 10:15:50 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 10:15:50 - INFO - __main__ -     Num examples = 1000
10/19/2022 10:15:50 - INFO - __main__ -     Batch size = 32
10/19/2022 10:15:53 - INFO - __main__ -     eval_ppl = 3.2491
10/19/2022 10:15:53 - INFO - __main__ -     ********************
10/19/2022 10:23:07 - INFO - __main__ -     bleu-4 = 33.61 
10/19/2022 10:23:07 - INFO - __main__ -     EM = 17.1 
10/19/2022 10:23:07 - INFO - __main__ -     ********************
10/19/2022 10:23:11 - INFO - __main__ -   epoch 27 step 84400 loss 0.0256
10/19/2022 10:23:30 - INFO - __main__ -   epoch 27 step 84500 loss 0.0219
10/19/2022 10:23:48 - INFO - __main__ -   epoch 27 step 84600 loss 0.0218
10/19/2022 10:24:07 - INFO - __main__ -   epoch 27 step 84700 loss 0.0228
10/19/2022 10:24:26 - INFO - __main__ -   epoch 27 step 84800 loss 0.0221
10/19/2022 10:24:44 - INFO - __main__ -   epoch 27 step 84900 loss 0.0222
10/19/2022 10:25:03 - INFO - __main__ -   epoch 27 step 85000 loss 0.0226
10/19/2022 10:25:21 - INFO - __main__ -   epoch 27 step 85100 loss 0.0231
10/19/2022 10:25:40 - INFO - __main__ -   epoch 27 step 85200 loss 0.0217
10/19/2022 10:25:58 - INFO - __main__ -   epoch 27 step 85300 loss 0.0229
10/19/2022 10:26:17 - INFO - __main__ -   epoch 27 step 85400 loss 0.0236
10/19/2022 10:26:36 - INFO - __main__ -   epoch 27 step 85500 loss 0.0218
10/19/2022 10:26:54 - INFO - __main__ -   epoch 27 step 85600 loss 0.0223
10/19/2022 10:27:13 - INFO - __main__ -   epoch 27 step 85700 loss 0.0233
10/19/2022 10:27:31 - INFO - __main__ -   epoch 27 step 85800 loss 0.0218
10/19/2022 10:27:50 - INFO - __main__ -   epoch 27 step 85900 loss 0.0225
10/19/2022 10:28:09 - INFO - __main__ -   epoch 27 step 86000 loss 0.0222
10/19/2022 10:28:27 - INFO - __main__ -   epoch 27 step 86100 loss 0.0219
10/19/2022 10:28:46 - INFO - __main__ -   epoch 27 step 86200 loss 0.022
10/19/2022 10:29:04 - INFO - __main__ -   epoch 27 step 86300 loss 0.023
10/19/2022 10:29:23 - INFO - __main__ -   epoch 27 step 86400 loss 0.0225
10/19/2022 10:29:41 - INFO - __main__ -   epoch 27 step 86500 loss 0.023
10/19/2022 10:30:00 - INFO - __main__ -   epoch 27 step 86600 loss 0.0228
10/19/2022 10:30:19 - INFO - __main__ -   epoch 27 step 86700 loss 0.0228
10/19/2022 10:30:37 - INFO - __main__ -   epoch 27 step 86800 loss 0.0228
10/19/2022 10:30:56 - INFO - __main__ -   epoch 27 step 86900 loss 0.022
10/19/2022 10:31:14 - INFO - __main__ -   epoch 27 step 87000 loss 0.0237
10/19/2022 10:31:33 - INFO - __main__ -   epoch 27 step 87100 loss 0.0231
10/19/2022 10:31:52 - INFO - __main__ -   epoch 27 step 87200 loss 0.0239
10/19/2022 10:32:10 - INFO - __main__ -   epoch 27 step 87300 loss 0.021
10/19/2022 10:32:29 - INFO - __main__ -   epoch 27 step 87400 loss 0.0232
10/19/2022 10:32:47 - INFO - __main__ -   epoch 27 step 87500 loss 0.0214
10/19/2022 10:32:47 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 10:32:47 - INFO - __main__ -     Num examples = 1000
10/19/2022 10:32:47 - INFO - __main__ -     Batch size = 32
10/19/2022 10:32:50 - INFO - __main__ -     eval_ppl = 3.26948
10/19/2022 10:32:50 - INFO - __main__ -     ********************
10/19/2022 10:39:55 - INFO - __main__ -     bleu-4 = 33.91 
10/19/2022 10:39:55 - INFO - __main__ -     EM = 17.4 
10/19/2022 10:39:55 - INFO - __main__ -     ********************
10/19/2022 10:40:14 - INFO - __main__ -   epoch 28 step 87600 loss 0.0199
10/19/2022 10:40:32 - INFO - __main__ -   epoch 28 step 87700 loss 0.0222
10/19/2022 10:40:51 - INFO - __main__ -   epoch 28 step 87800 loss 0.0208
10/19/2022 10:41:10 - INFO - __main__ -   epoch 28 step 87900 loss 0.0215
10/19/2022 10:41:28 - INFO - __main__ -   epoch 28 step 88000 loss 0.0207
10/19/2022 10:41:47 - INFO - __main__ -   epoch 28 step 88100 loss 0.0219
10/19/2022 10:42:05 - INFO - __main__ -   epoch 28 step 88200 loss 0.0213
10/19/2022 10:42:24 - INFO - __main__ -   epoch 28 step 88300 loss 0.0211
10/19/2022 10:42:42 - INFO - __main__ -   epoch 28 step 88400 loss 0.021
10/19/2022 10:43:01 - INFO - __main__ -   epoch 28 step 88500 loss 0.0222
10/19/2022 10:43:19 - INFO - __main__ -   epoch 28 step 88600 loss 0.0213
10/19/2022 10:43:38 - INFO - __main__ -   epoch 28 step 88700 loss 0.0211
10/19/2022 10:43:57 - INFO - __main__ -   epoch 28 step 88800 loss 0.0208
10/19/2022 10:44:15 - INFO - __main__ -   epoch 28 step 88900 loss 0.0212
10/19/2022 10:44:34 - INFO - __main__ -   epoch 28 step 89000 loss 0.0221
10/19/2022 10:44:52 - INFO - __main__ -   epoch 28 step 89100 loss 0.0214
10/19/2022 10:45:11 - INFO - __main__ -   epoch 28 step 89200 loss 0.0221
10/19/2022 10:45:30 - INFO - __main__ -   epoch 28 step 89300 loss 0.0213
10/19/2022 10:45:48 - INFO - __main__ -   epoch 28 step 89400 loss 0.021
10/19/2022 10:46:07 - INFO - __main__ -   epoch 28 step 89500 loss 0.0208
10/19/2022 10:46:25 - INFO - __main__ -   epoch 28 step 89600 loss 0.0221
10/19/2022 10:46:44 - INFO - __main__ -   epoch 28 step 89700 loss 0.021
10/19/2022 10:47:03 - INFO - __main__ -   epoch 28 step 89800 loss 0.0203
10/19/2022 10:47:21 - INFO - __main__ -   epoch 28 step 89900 loss 0.0211
10/19/2022 10:47:40 - INFO - __main__ -   epoch 28 step 90000 loss 0.0206
10/19/2022 10:47:58 - INFO - __main__ -   epoch 28 step 90100 loss 0.0201
10/19/2022 10:48:17 - INFO - __main__ -   epoch 28 step 90200 loss 0.0203
10/19/2022 10:48:35 - INFO - __main__ -   epoch 28 step 90300 loss 0.0224
10/19/2022 10:48:54 - INFO - __main__ -   epoch 28 step 90400 loss 0.0214
10/19/2022 10:49:13 - INFO - __main__ -   epoch 28 step 90500 loss 0.0203
10/19/2022 10:49:31 - INFO - __main__ -   epoch 28 step 90600 loss 0.0222
10/19/2022 10:49:36 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 10:49:36 - INFO - __main__ -     Num examples = 1000
10/19/2022 10:49:36 - INFO - __main__ -     Batch size = 32
10/19/2022 10:49:38 - INFO - __main__ -     eval_ppl = 3.2752
10/19/2022 10:49:38 - INFO - __main__ -     ********************
10/19/2022 10:56:42 - INFO - __main__ -     bleu-4 = 33.95 
10/19/2022 10:56:42 - INFO - __main__ -     EM = 17.8 
10/19/2022 10:56:42 - INFO - __main__ -     ********************
10/19/2022 10:56:55 - INFO - __main__ -   epoch 29 step 90700 loss 0.0205
10/19/2022 10:57:14 - INFO - __main__ -   epoch 29 step 90800 loss 0.0203
10/19/2022 10:57:32 - INFO - __main__ -   epoch 29 step 90900 loss 0.0199
10/19/2022 10:57:51 - INFO - __main__ -   epoch 29 step 91000 loss 0.0205
10/19/2022 10:58:09 - INFO - __main__ -   epoch 29 step 91100 loss 0.0202
10/19/2022 10:58:28 - INFO - __main__ -   epoch 29 step 91200 loss 0.0192
10/19/2022 10:58:47 - INFO - __main__ -   epoch 29 step 91300 loss 0.0196
10/19/2022 10:59:05 - INFO - __main__ -   epoch 29 step 91400 loss 0.0203
10/19/2022 10:59:24 - INFO - __main__ -   epoch 29 step 91500 loss 0.0208
10/19/2022 10:59:42 - INFO - __main__ -   epoch 29 step 91600 loss 0.0201
10/19/2022 11:00:01 - INFO - __main__ -   epoch 29 step 91700 loss 0.0198
10/19/2022 11:00:20 - INFO - __main__ -   epoch 29 step 91800 loss 0.0204
10/19/2022 11:00:38 - INFO - __main__ -   epoch 29 step 91900 loss 0.0195
10/19/2022 11:00:57 - INFO - __main__ -   epoch 29 step 92000 loss 0.0196
10/19/2022 11:01:16 - INFO - __main__ -   epoch 29 step 92100 loss 0.0201
10/19/2022 11:01:34 - INFO - __main__ -   epoch 29 step 92200 loss 0.021
10/19/2022 11:01:53 - INFO - __main__ -   epoch 29 step 92300 loss 0.0209
10/19/2022 11:02:12 - INFO - __main__ -   epoch 29 step 92400 loss 0.0202
10/19/2022 11:02:30 - INFO - __main__ -   epoch 29 step 92500 loss 0.0201
10/19/2022 11:02:49 - INFO - __main__ -   epoch 29 step 92600 loss 0.0197
10/19/2022 11:03:08 - INFO - __main__ -   epoch 29 step 92700 loss 0.0204
10/19/2022 11:03:27 - INFO - __main__ -   epoch 29 step 92800 loss 0.0202
10/19/2022 11:03:45 - INFO - __main__ -   epoch 29 step 92900 loss 0.0198
10/19/2022 11:04:04 - INFO - __main__ -   epoch 29 step 93000 loss 0.0202
10/19/2022 11:04:23 - INFO - __main__ -   epoch 29 step 93100 loss 0.0194
10/19/2022 11:04:41 - INFO - __main__ -   epoch 29 step 93200 loss 0.0196
10/19/2022 11:05:00 - INFO - __main__ -   epoch 29 step 93300 loss 0.021
10/19/2022 11:05:19 - INFO - __main__ -   epoch 29 step 93400 loss 0.0197
10/19/2022 11:05:37 - INFO - __main__ -   epoch 29 step 93500 loss 0.0211
10/19/2022 11:05:56 - INFO - __main__ -   epoch 29 step 93600 loss 0.0204
10/19/2022 11:06:15 - INFO - __main__ -   epoch 29 step 93700 loss 0.0199
10/19/2022 11:06:24 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 11:06:24 - INFO - __main__ -     Num examples = 1000
10/19/2022 11:06:24 - INFO - __main__ -     Batch size = 32
10/19/2022 11:06:27 - INFO - __main__ -     eval_ppl = 3.28624
10/19/2022 11:06:27 - INFO - __main__ -     ********************
10/19/2022 11:13:30 - INFO - __main__ -     bleu-4 = 34.02 
10/19/2022 11:13:30 - INFO - __main__ -     EM = 17.2 
10/19/2022 11:13:30 - INFO - __main__ -     ********************
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [00:15<08:04, 15.62s/it]  6%|▋         | 2/32 [00:30<07:30, 15.03s/it]  9%|▉         | 3/32 [00:44<07:03, 14.59s/it] 12%|█▎        | 4/32 [00:56<06:27, 13.83s/it] 16%|█▌        | 5/32 [01:09<06:01, 13.41s/it] 19%|█▉        | 6/32 [01:22<05:41, 13.13s/it] 22%|██▏       | 7/32 [01:40<06:10, 14.81s/it] 25%|██▌       | 8/32 [01:53<05:43, 14.33s/it] 28%|██▊       | 9/32 [02:08<05:33, 14.50s/it] 31%|███▏      | 10/32 [02:21<05:10, 14.11s/it] 34%|███▍      | 11/32 [02:36<04:59, 14.26s/it] 38%|███▊      | 12/32 [02:48<04:30, 13.53s/it] 41%|████      | 13/32 [03:02<04:20, 13.71s/it] 44%|████▍     | 14/32 [03:16<04:06, 13.71s/it] 47%|████▋     | 15/32 [03:30<03:53, 13.74s/it] 50%|█████     | 16/32 [03:42<03:34, 13.38s/it] 53%|█████▎    | 17/32 [03:55<03:18, 13.26s/it] 56%|█████▋    | 18/32 [04:09<03:07, 13.42s/it] 59%|█████▉    | 19/32 [04:23<02:56, 13.57s/it] 62%|██████▎   | 20/32 [04:34<02:33, 12.76s/it] 66%|██████▌   | 21/32 [04:46<02:20, 12.77s/it] 69%|██████▉   | 22/32 [05:00<02:09, 12.91s/it] 72%|███████▏  | 23/32 [05:14<02:01, 13.49s/it] 75%|███████▌  | 24/32 [05:28<01:47, 13.42s/it] 78%|███████▊  | 25/32 [05:41<01:33, 13.37s/it] 81%|████████▏ | 26/32 [05:56<01:23, 13.86s/it] 84%|████████▍ | 27/32 [06:10<01:09, 13.92s/it] 88%|████████▊ | 28/32 [06:25<00:56, 14.10s/it] 91%|█████████ | 29/32 [06:41<00:44, 14.86s/it] 94%|█████████▍| 30/32 [06:55<00:29, 14.61s/it] 97%|█████████▋| 31/32 [07:13<00:15, 15.59s/it]100%|██████████| 32/32 [07:18<00:00, 12.25s/it]100%|██████████| 32/32 [07:18<00:00, 13.69s/it]
10/19/2022 11:20:50 - INFO - __main__ -   
***** Running testing *****
10/19/2022 11:20:51 - INFO - __main__ -     bleu-4 = 34.02 
10/19/2022 11:20:51 - INFO - __main__ -     EM = 18.6 
10/19/2022 11:20:51 - INFO - __main__ -     ********************
10/19/2022 11:20:52 - INFO - utils -   saved dataset in saved_models/code-gen/unixcoder/partial_freezing/freeze_bottom_4_layers/20221019023845/result.jsonl

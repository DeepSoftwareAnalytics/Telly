10/09/2022 07:02:53 - INFO - __main__ -   device: cuda, n_gpu: 1
10/09/2022 07:02:54 - DEBUG - filelock -   Attempting to acquire lock 139952262709408 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:02:54 - DEBUG - filelock -   Lock 139952262709408 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   3%|▎         | 29.0k/916k [00:00<00:03, 272kB/s]Downloading:  22%|██▏       | 204k/916k [00:00<00:00, 1.06MB/s]Downloading:  96%|█████████▌| 876k/916k [00:00<00:00, 3.40MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 2.80MB/s]
10/09/2022 07:02:54 - DEBUG - filelock -   Attempting to release lock 139952262709408 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:02:54 - DEBUG - filelock -   Lock 139952262709408 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:02:55 - DEBUG - filelock -   Attempting to acquire lock 139952261516592 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:02:55 - DEBUG - filelock -   Lock 139952261516592 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:   9%|▉         | 40.0k/434k [00:00<00:01, 403kB/s]Downloading:  43%|████▎     | 185k/434k [00:00<00:00, 1.02MB/s]Downloading: 100%|██████████| 434k/434k [00:00<00:00, 1.72MB/s]
10/09/2022 07:02:55 - DEBUG - filelock -   Attempting to release lock 139952261516592 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:02:55 - DEBUG - filelock -   Lock 139952261516592 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Attempting to acquire lock 139952263182464 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Lock 139952263182464 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 609kB/s]
10/09/2022 07:02:56 - DEBUG - filelock -   Attempting to release lock 139952263182464 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Lock 139952263182464 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Attempting to acquire lock 139952261516496 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Lock 139952261516496 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 1.09MB/s]
10/09/2022 07:02:56 - DEBUG - filelock -   Attempting to release lock 139952261516496 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:02:56 - DEBUG - filelock -   Lock 139952261516496 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:02:57 - DEBUG - filelock -   Attempting to acquire lock 139952263182464 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:02:57 - DEBUG - filelock -   Lock 139952263182464 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 658kB/s]
10/09/2022 07:02:57 - DEBUG - filelock -   Attempting to release lock 139952263182464 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:02:57 - DEBUG - filelock -   Lock 139952263182464 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:02:58 - DEBUG - filelock -   Attempting to acquire lock 139952261100064 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:02:58 - DEBUG - filelock -   Lock 139952261100064 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   2%|▏         | 7.30M/480M [00:00<00:06, 76.5MB/s]Downloading:   4%|▎         | 17.5M/480M [00:00<00:05, 94.5MB/s]Downloading:   6%|▌         | 27.5M/480M [00:00<00:04, 99.1MB/s]Downloading:   8%|▊         | 37.8M/480M [00:00<00:04, 103MB/s] Downloading:  10%|█         | 48.1M/480M [00:00<00:04, 105MB/s]Downloading:  12%|█▏        | 58.3M/480M [00:00<00:04, 106MB/s]Downloading:  14%|█▍        | 68.8M/480M [00:00<00:04, 107MB/s]Downloading:  16%|█▋        | 79.0M/480M [00:00<00:03, 106MB/s]Downloading:  19%|█▊        | 89.2M/480M [00:00<00:03, 106MB/s]Downloading:  21%|██        | 99.3M/480M [00:01<00:03, 106MB/s]Downloading:  23%|██▎       | 110M/480M [00:01<00:03, 107MB/s] Downloading:  25%|██▍       | 120M/480M [00:01<00:03, 107MB/s]Downloading:  27%|██▋       | 130M/480M [00:01<00:03, 108MB/s]Downloading:  29%|██▉       | 141M/480M [00:01<00:03, 108MB/s]Downloading:  31%|███▏      | 151M/480M [00:01<00:03, 107MB/s]Downloading:  34%|███▎      | 162M/480M [00:01<00:03, 108MB/s]Downloading:  36%|███▌      | 172M/480M [00:01<00:02, 109MB/s]Downloading:  38%|███▊      | 183M/480M [00:01<00:02, 109MB/s]Downloading:  40%|████      | 193M/480M [00:01<00:02, 109MB/s]Downloading:  42%|████▏     | 203M/480M [00:02<00:02, 109MB/s]Downloading:  44%|████▍     | 214M/480M [00:02<00:02, 108MB/s]Downloading:  47%|████▋     | 224M/480M [00:02<00:02, 107MB/s]Downloading:  49%|████▉     | 234M/480M [00:02<00:02, 107MB/s]Downloading:  51%|█████     | 245M/480M [00:02<00:02, 107MB/s]Downloading:  53%|█████▎    | 255M/480M [00:02<00:02, 107MB/s]Downloading:  55%|█████▌    | 265M/480M [00:02<00:02, 109MB/s]Downloading:  57%|█████▋    | 276M/480M [00:02<00:01, 109MB/s]Downloading:  60%|█████▉    | 286M/480M [00:02<00:01, 109MB/s]Downloading:  62%|██████▏   | 297M/480M [00:02<00:01, 109MB/s]Downloading:  64%|██████▍   | 307M/480M [00:03<00:01, 108MB/s]Downloading:  66%|██████▌   | 317M/480M [00:03<00:01, 108MB/s]Downloading:  68%|██████▊   | 328M/480M [00:03<00:01, 109MB/s]Downloading:  70%|███████   | 338M/480M [00:03<00:01, 105MB/s]Downloading:  72%|███████▏  | 348M/480M [00:03<00:01, 106MB/s]Downloading:  75%|███████▍  | 359M/480M [00:03<00:01, 106MB/s]Downloading:  77%|███████▋  | 369M/480M [00:03<00:01, 108MB/s]Downloading:  79%|███████▉  | 380M/480M [00:03<00:00, 109MB/s]Downloading:  81%|████████  | 390M/480M [00:03<00:00, 109MB/s]Downloading:  83%|████████▎ | 401M/480M [00:03<00:00, 109MB/s]Downloading:  86%|████████▌ | 411M/480M [00:04<00:00, 109MB/s]Downloading:  88%|████████▊ | 421M/480M [00:04<00:00, 109MB/s]Downloading:  90%|████████▉ | 432M/480M [00:04<00:00, 109MB/s]Downloading:  92%|█████████▏| 442M/480M [00:04<00:00, 109MB/s]Downloading:  94%|█████████▍| 453M/480M [00:04<00:00, 109MB/s]Downloading:  96%|█████████▋| 463M/480M [00:04<00:00, 109MB/s]Downloading:  99%|█████████▊| 474M/480M [00:04<00:00, 110MB/s]Downloading: 100%|██████████| 480M/480M [00:04<00:00, 107MB/s]
10/09/2022 07:03:03 - DEBUG - filelock -   Attempting to release lock 139952261100064 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:03:03 - DEBUG - filelock -   Lock 139952261100064 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:03:05 - INFO - __main__ -   Training/evaluation parameters Namespace(code_length=256, codebase_file='dataset/CSN/python/codebase.jsonl', config_name='', debug=False, device=device(type='cuda'), do_F2_norm=False, do_eval=True, do_test=True, do_train=True, do_zero_shot=False, eval_batch_size=128, eval_data_file='dataset/CSN/python/valid.jsonl', freeze_bottom_k_layer_index=7, learning_rate=2e-05, max_grad_norm=1.0, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, nl_length=128, num_train_epochs=10, output_dir='saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247', seed=123456, test_data_file='dataset/CSN/python/test.jsonl', tokenizer_name='', train_batch_size=128, train_data_file='dataset/CSN/python/train.jsonl', weight_decay=0.01)
10/09/2022 07:03:05 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.7.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.7.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.7.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.7.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.7.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/09/2022 07:06:36 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:36 - INFO - __main__ -   idx: 0
10/09/2022 07:06:36 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_split', '_', 'phy', 'log', 'en', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_";"', '_)', '_[', '_0', '_]', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   code_ids: 0 6 2 729 5192 181 3258 896 386 207 400 428 2019 3144 385 437 201 120 743 545 3144 385 3144 513 12945 120 1046 385 428 746 5192 400 3144 743 483 1046 626 461 2406 513 3144 513 1046 626 524 2406 746 5192 400 29760 743 626 461 2406 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:36 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Return', '_either', '_the', '_full', '_or', '_truncated', '_version', '_of', '_a', '_Q', 'II', 'ME', '_-', '_formatted', '_taxonomy', '_string', '_.', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   nl_ids: 0 6 2 1675 4759 448 3662 872 19307 2229 595 434 1152 4300 1098 581 10440 29021 724 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:36 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:36 - INFO - __main__ -   idx: 1
10/09/2022 07:06:36 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'akedirs', '_(', '_d', '_)', '_except', '_OSError', '_as', '_oe', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'makedirs', '_#', '_ENOENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_errno', '_==', '_errno', '_.', '_ENOENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '__________________________', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '__________________________', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '__________________________', '_({})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_oe', '_.', '_strerror', '_)', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   code_ids: 0 6 2 729 6229 181 1282 400 480 743 545 462 800 2215 746 1391 746 4534 400 480 743 545 1568 545 2215 746 446 23328 400 480 743 3552 22934 880 44902 545 830 1570 800 7564 918 2215 132 24429 830 41059 144 4038 5632 1012 872 3456 462 2215 746 2341 550 2341 746 41059 545 2345 385 7916 443 400 1638 3533 872 2726 11613 488 448 1391 46072 1000 800 3040 132 1359 317 4584 2713 1147 15323 434 579 3456 563 1721 130 13874 6229 317 4584 1345 1946 11613 488 448 1391 6418 3040 6315 743 483 2345 746 2021 400 480 743 669 545 2345 385 7916 443 400 1638 1088 843 10058 11749 508 1738 448 1721 3456 317 4584 46072 918 1841 144 2334 3947 743 483 2345 746 2021 400 480 2019 44902 746 20115 743 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:36 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catch', 'es', '_OSError', '_exceptions', '_and', '_returns', '_a', '_desc', 'riptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   nl_ids: 0 6 2 1749 508 2002 3984 448 8813 3456 1391 2129 800 3040 462 1769 1738 835 746 1044 1454 2092 482 22934 12300 706 2060 434 2162 44105 1841 4488 595 479 581 47183 448 843 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:36 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:36 - INFO - __main__ -   idx: 2
10/09/2022 07:06:36 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_isinstance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_ValueError', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_elif', '_isinstance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   code_ids: 0 6 2 729 1012 181 2133 400 4065 190 2019 2119 385 437 200 171 120 743 545 2384 385 1938 462 5408 400 4065 190 2019 1012 743 545 462 4065 190 746 8264 545 3085 6052 400 437 1834 1012 555 8264 3508 743 2384 385 4065 190 3625 5408 400 4065 190 2019 1113 743 545 2384 385 2717 400 4065 190 2019 2119 743 483 2384 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:36 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Takes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
10/09/2022 07:06:36 - INFO - __main__ -   nl_ids: 0 6 2 27408 4759 434 1012 1391 872 817 2717 1012 2384 7825 25911 706 2060 817 2717 1012 2384 872 23154 817 7900 2654 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:37 - INFO - __main__ -   ***** Running training *****
10/09/2022 07:06:37 - INFO - __main__ -     Num examples = 251820
10/09/2022 07:06:37 - INFO - __main__ -     Num Epochs = 10
10/09/2022 07:06:37 - INFO - __main__ -     Instantaneous batch size per GPU = 128
10/09/2022 07:06:37 - INFO - __main__ -     Total train batch size  = 128
10/09/2022 07:06:37 - INFO - __main__ -     Total optimization steps = 19680
10/09/2022 07:07:12 - INFO - __main__ -   epoch 0 step 100 loss 0.22538
10/09/2022 07:07:45 - INFO - __main__ -   epoch 0 step 200 loss 0.16235
10/09/2022 07:08:18 - INFO - __main__ -   epoch 0 step 300 loss 0.14875
10/09/2022 07:08:51 - INFO - __main__ -   epoch 0 step 400 loss 0.14073
10/09/2022 07:09:24 - INFO - __main__ -   epoch 0 step 500 loss 0.14563
10/09/2022 07:09:58 - INFO - __main__ -   epoch 0 step 600 loss 0.13964
10/09/2022 07:10:31 - INFO - __main__ -   epoch 0 step 700 loss 0.13547
10/09/2022 07:11:04 - INFO - __main__ -   epoch 0 step 800 loss 0.12521
10/09/2022 07:11:37 - INFO - __main__ -   epoch 0 step 900 loss 0.12406
10/09/2022 07:12:10 - INFO - __main__ -   epoch 0 step 1000 loss 0.11665
10/09/2022 07:12:43 - INFO - __main__ -   epoch 0 step 1100 loss 0.11332
10/09/2022 07:13:16 - INFO - __main__ -   epoch 0 step 1200 loss 0.12698
10/09/2022 07:13:49 - INFO - __main__ -   epoch 0 step 1300 loss 0.10805
10/09/2022 07:14:23 - INFO - __main__ -   epoch 0 step 1400 loss 0.11967
10/09/2022 07:14:56 - INFO - __main__ -   epoch 0 step 1500 loss 0.12017
10/09/2022 07:15:29 - INFO - __main__ -   epoch 0 step 1600 loss 0.11441
10/09/2022 07:16:02 - INFO - __main__ -   epoch 0 step 1700 loss 0.11516
10/09/2022 07:16:35 - INFO - __main__ -   epoch 0 step 1800 loss 0.11152
10/09/2022 07:17:08 - INFO - __main__ -   epoch 0 step 1900 loss 0.11944
10/09/2022 07:18:10 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:18:10 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:18:10 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:18:10 - INFO - __main__ -     Batch size = 128
10/09/2022 07:20:01 - INFO - __main__ -     R@1 = 0.608
10/09/2022 07:20:01 - INFO - __main__ -     R@5 = 0.827
10/09/2022 07:20:01 - INFO - __main__ -     R@10 = 0.88
10/09/2022 07:20:01 - INFO - __main__ -     eval_mrr = 0.706
10/09/2022 07:20:01 - INFO - __main__ -     ********************
10/09/2022 07:20:01 - INFO - __main__ -     Best mrr:0.706
10/09/2022 07:20:01 - INFO - __main__ -     ********************
10/09/2022 07:20:11 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/checkpoint-best-mrr/model.bin
10/09/2022 07:20:45 - INFO - __main__ -   epoch 1 step 100 loss 0.09982
10/09/2022 07:21:18 - INFO - __main__ -   epoch 1 step 200 loss 0.09408
10/09/2022 07:21:51 - INFO - __main__ -   epoch 1 step 300 loss 0.08966
10/09/2022 07:22:24 - INFO - __main__ -   epoch 1 step 400 loss 0.09166
10/09/2022 07:22:57 - INFO - __main__ -   epoch 1 step 500 loss 0.09401
10/09/2022 07:23:30 - INFO - __main__ -   epoch 1 step 600 loss 0.09486
10/09/2022 07:24:03 - INFO - __main__ -   epoch 1 step 700 loss 0.08796
10/09/2022 07:24:36 - INFO - __main__ -   epoch 1 step 800 loss 0.0996
10/09/2022 07:25:10 - INFO - __main__ -   epoch 1 step 900 loss 0.09781
10/09/2022 07:25:43 - INFO - __main__ -   epoch 1 step 1000 loss 0.09458
10/09/2022 07:26:16 - INFO - __main__ -   epoch 1 step 1100 loss 0.09633
10/09/2022 07:26:49 - INFO - __main__ -   epoch 1 step 1200 loss 0.08985
10/09/2022 07:27:22 - INFO - __main__ -   epoch 1 step 1300 loss 0.09206
10/09/2022 07:27:56 - INFO - __main__ -   epoch 1 step 1400 loss 0.09087
10/09/2022 07:28:29 - INFO - __main__ -   epoch 1 step 1500 loss 0.08749
10/09/2022 07:29:02 - INFO - __main__ -   epoch 1 step 1600 loss 0.08875
10/09/2022 07:29:35 - INFO - __main__ -   epoch 1 step 1700 loss 0.09197
10/09/2022 07:30:08 - INFO - __main__ -   epoch 1 step 1800 loss 0.09163
10/09/2022 07:30:41 - INFO - __main__ -   epoch 1 step 1900 loss 0.08863
10/09/2022 07:31:37 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:31:37 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:31:37 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:31:37 - INFO - __main__ -     Batch size = 128
10/09/2022 07:33:28 - INFO - __main__ -     R@1 = 0.612
10/09/2022 07:33:28 - INFO - __main__ -     R@5 = 0.833
10/09/2022 07:33:28 - INFO - __main__ -     R@10 = 0.884
10/09/2022 07:33:28 - INFO - __main__ -     eval_mrr = 0.712
10/09/2022 07:33:28 - INFO - __main__ -     ********************
10/09/2022 07:33:28 - INFO - __main__ -     Best mrr:0.712
10/09/2022 07:33:28 - INFO - __main__ -     ********************
10/09/2022 07:33:38 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/checkpoint-best-mrr/model.bin
10/09/2022 07:34:12 - INFO - __main__ -   epoch 2 step 100 loss 0.07796
10/09/2022 07:34:45 - INFO - __main__ -   epoch 2 step 200 loss 0.0702
10/09/2022 07:35:18 - INFO - __main__ -   epoch 2 step 300 loss 0.07244
10/09/2022 07:35:51 - INFO - __main__ -   epoch 2 step 400 loss 0.07155
10/09/2022 07:36:24 - INFO - __main__ -   epoch 2 step 500 loss 0.07641
10/09/2022 07:36:57 - INFO - __main__ -   epoch 2 step 600 loss 0.07572
10/09/2022 07:37:30 - INFO - __main__ -   epoch 2 step 700 loss 0.07327
10/09/2022 07:38:03 - INFO - __main__ -   epoch 2 step 800 loss 0.07056
10/09/2022 07:38:37 - INFO - __main__ -   epoch 2 step 900 loss 0.08081
10/09/2022 07:39:10 - INFO - __main__ -   epoch 2 step 1000 loss 0.07545
10/09/2022 07:39:43 - INFO - __main__ -   epoch 2 step 1100 loss 0.07843
10/09/2022 07:40:16 - INFO - __main__ -   epoch 2 step 1200 loss 0.07612
10/09/2022 07:40:49 - INFO - __main__ -   epoch 2 step 1300 loss 0.07967
10/09/2022 07:41:22 - INFO - __main__ -   epoch 2 step 1400 loss 0.07918
10/09/2022 07:41:55 - INFO - __main__ -   epoch 2 step 1500 loss 0.07457
10/09/2022 07:42:29 - INFO - __main__ -   epoch 2 step 1600 loss 0.07909
10/09/2022 07:43:02 - INFO - __main__ -   epoch 2 step 1700 loss 0.07561
10/09/2022 07:43:35 - INFO - __main__ -   epoch 2 step 1800 loss 0.07623
10/09/2022 07:44:08 - INFO - __main__ -   epoch 2 step 1900 loss 0.07718
10/09/2022 07:45:04 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:45:04 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:45:04 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:45:04 - INFO - __main__ -     Batch size = 128
10/09/2022 07:46:54 - INFO - __main__ -     R@1 = 0.613
10/09/2022 07:46:54 - INFO - __main__ -     R@5 = 0.836
10/09/2022 07:46:54 - INFO - __main__ -     R@10 = 0.884
10/09/2022 07:46:54 - INFO - __main__ -     eval_mrr = 0.712
10/09/2022 07:47:28 - INFO - __main__ -   epoch 3 step 100 loss 0.06814
10/09/2022 07:48:01 - INFO - __main__ -   epoch 3 step 200 loss 0.05975
10/09/2022 07:48:34 - INFO - __main__ -   epoch 3 step 300 loss 0.06647
10/09/2022 07:49:07 - INFO - __main__ -   epoch 3 step 400 loss 0.06376
10/09/2022 07:49:40 - INFO - __main__ -   epoch 3 step 500 loss 0.06639
10/09/2022 07:50:13 - INFO - __main__ -   epoch 3 step 600 loss 0.06243
10/09/2022 07:50:46 - INFO - __main__ -   epoch 3 step 700 loss 0.06553
10/09/2022 07:51:19 - INFO - __main__ -   epoch 3 step 800 loss 0.06407
10/09/2022 07:51:52 - INFO - __main__ -   epoch 3 step 900 loss 0.06567
10/09/2022 07:52:25 - INFO - __main__ -   epoch 3 step 1000 loss 0.06422
10/09/2022 07:52:58 - INFO - __main__ -   epoch 3 step 1100 loss 0.06053
10/09/2022 07:53:31 - INFO - __main__ -   epoch 3 step 1200 loss 0.06411
10/09/2022 07:54:05 - INFO - __main__ -   epoch 3 step 1300 loss 0.06374
10/09/2022 07:54:38 - INFO - __main__ -   epoch 3 step 1400 loss 0.06286
10/09/2022 07:55:11 - INFO - __main__ -   epoch 3 step 1500 loss 0.05754
10/09/2022 07:55:44 - INFO - __main__ -   epoch 3 step 1600 loss 0.06519
10/09/2022 07:56:17 - INFO - __main__ -   epoch 3 step 1700 loss 0.06214
10/09/2022 07:56:50 - INFO - __main__ -   epoch 3 step 1800 loss 0.06266
10/09/2022 07:57:24 - INFO - __main__ -   epoch 3 step 1900 loss 0.0683
10/09/2022 07:58:20 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:58:20 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:58:20 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:58:20 - INFO - __main__ -     Batch size = 128
10/09/2022 08:00:09 - INFO - __main__ -     R@1 = 0.615
10/09/2022 08:00:09 - INFO - __main__ -     R@5 = 0.833
10/09/2022 08:00:09 - INFO - __main__ -     R@10 = 0.883
10/09/2022 08:00:09 - INFO - __main__ -     eval_mrr = 0.713
10/09/2022 08:00:09 - INFO - __main__ -     ********************
10/09/2022 08:00:09 - INFO - __main__ -     Best mrr:0.713
10/09/2022 08:00:09 - INFO - __main__ -     ********************
10/09/2022 08:00:23 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/checkpoint-best-mrr/model.bin
10/09/2022 08:00:57 - INFO - __main__ -   epoch 4 step 100 loss 0.05513
10/09/2022 08:01:30 - INFO - __main__ -   epoch 4 step 200 loss 0.05143
10/09/2022 08:02:03 - INFO - __main__ -   epoch 4 step 300 loss 0.05693
10/09/2022 08:02:36 - INFO - __main__ -   epoch 4 step 400 loss 0.05532
10/09/2022 08:03:09 - INFO - __main__ -   epoch 4 step 500 loss 0.05487
10/09/2022 08:03:42 - INFO - __main__ -   epoch 4 step 600 loss 0.05664
10/09/2022 08:04:15 - INFO - __main__ -   epoch 4 step 700 loss 0.0551
10/09/2022 08:04:49 - INFO - __main__ -   epoch 4 step 800 loss 0.05434
10/09/2022 08:05:22 - INFO - __main__ -   epoch 4 step 900 loss 0.05421
10/09/2022 08:05:55 - INFO - __main__ -   epoch 4 step 1000 loss 0.05468
10/09/2022 08:06:28 - INFO - __main__ -   epoch 4 step 1100 loss 0.05103
10/09/2022 08:07:01 - INFO - __main__ -   epoch 4 step 1200 loss 0.05522
10/09/2022 08:07:34 - INFO - __main__ -   epoch 4 step 1300 loss 0.05461
10/09/2022 08:08:07 - INFO - __main__ -   epoch 4 step 1400 loss 0.05301
10/09/2022 08:08:41 - INFO - __main__ -   epoch 4 step 1500 loss 0.05624
10/09/2022 08:09:14 - INFO - __main__ -   epoch 4 step 1600 loss 0.05518
10/09/2022 08:09:47 - INFO - __main__ -   epoch 4 step 1700 loss 0.05338
10/09/2022 08:10:20 - INFO - __main__ -   epoch 4 step 1800 loss 0.05762
10/09/2022 08:10:53 - INFO - __main__ -   epoch 4 step 1900 loss 0.0562
10/09/2022 08:11:49 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:11:49 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:11:49 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:11:49 - INFO - __main__ -     Batch size = 128
10/09/2022 08:13:39 - INFO - __main__ -     R@1 = 0.617
10/09/2022 08:13:39 - INFO - __main__ -     R@5 = 0.835
10/09/2022 08:13:39 - INFO - __main__ -     R@10 = 0.885
10/09/2022 08:13:39 - INFO - __main__ -     eval_mrr = 0.714
10/09/2022 08:13:39 - INFO - __main__ -     ********************
10/09/2022 08:13:39 - INFO - __main__ -     Best mrr:0.714
10/09/2022 08:13:39 - INFO - __main__ -     ********************
10/09/2022 08:13:56 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/checkpoint-best-mrr/model.bin
10/09/2022 08:14:30 - INFO - __main__ -   epoch 5 step 100 loss 0.04814
10/09/2022 08:15:03 - INFO - __main__ -   epoch 5 step 200 loss 0.04791
10/09/2022 08:15:36 - INFO - __main__ -   epoch 5 step 300 loss 0.04863
10/09/2022 08:16:09 - INFO - __main__ -   epoch 5 step 400 loss 0.0463
10/09/2022 08:16:42 - INFO - __main__ -   epoch 5 step 500 loss 0.04603
10/09/2022 08:17:15 - INFO - __main__ -   epoch 5 step 600 loss 0.04812
10/09/2022 08:17:48 - INFO - __main__ -   epoch 5 step 700 loss 0.04529
10/09/2022 08:18:22 - INFO - __main__ -   epoch 5 step 800 loss 0.05083
10/09/2022 08:18:55 - INFO - __main__ -   epoch 5 step 900 loss 0.04961
10/09/2022 08:19:28 - INFO - __main__ -   epoch 5 step 1000 loss 0.0473
10/09/2022 08:20:01 - INFO - __main__ -   epoch 5 step 1100 loss 0.04689
10/09/2022 08:20:34 - INFO - __main__ -   epoch 5 step 1200 loss 0.04449
10/09/2022 08:21:07 - INFO - __main__ -   epoch 5 step 1300 loss 0.04956
10/09/2022 08:21:41 - INFO - __main__ -   epoch 5 step 1400 loss 0.04721
10/09/2022 08:22:14 - INFO - __main__ -   epoch 5 step 1500 loss 0.05027
10/09/2022 08:22:47 - INFO - __main__ -   epoch 5 step 1600 loss 0.05081
10/09/2022 08:23:20 - INFO - __main__ -   epoch 5 step 1700 loss 0.04549
10/09/2022 08:23:54 - INFO - __main__ -   epoch 5 step 1800 loss 0.05218
10/09/2022 08:24:27 - INFO - __main__ -   epoch 5 step 1900 loss 0.04952
10/09/2022 08:25:20 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:25:20 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:25:20 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:25:20 - INFO - __main__ -     Batch size = 128
10/09/2022 08:27:11 - INFO - __main__ -     R@1 = 0.617
10/09/2022 08:27:11 - INFO - __main__ -     R@5 = 0.835
10/09/2022 08:27:11 - INFO - __main__ -     R@10 = 0.885
10/09/2022 08:27:11 - INFO - __main__ -     eval_mrr = 0.715
10/09/2022 08:27:11 - INFO - __main__ -     ********************
10/09/2022 08:27:11 - INFO - __main__ -     Best mrr:0.715
10/09/2022 08:27:11 - INFO - __main__ -     ********************
10/09/2022 08:27:18 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/checkpoint-best-mrr/model.bin
10/09/2022 08:27:52 - INFO - __main__ -   epoch 6 step 100 loss 0.04527
10/09/2022 08:28:27 - INFO - __main__ -   epoch 6 step 200 loss 0.04486
10/09/2022 08:29:00 - INFO - __main__ -   epoch 6 step 300 loss 0.0419
10/09/2022 08:29:33 - INFO - __main__ -   epoch 6 step 400 loss 0.04106
10/09/2022 08:30:06 - INFO - __main__ -   epoch 6 step 500 loss 0.04245
10/09/2022 08:30:39 - INFO - __main__ -   epoch 6 step 600 loss 0.04349
10/09/2022 08:31:12 - INFO - __main__ -   epoch 6 step 700 loss 0.04096
10/09/2022 08:31:45 - INFO - __main__ -   epoch 6 step 800 loss 0.04233
10/09/2022 08:32:18 - INFO - __main__ -   epoch 6 step 900 loss 0.04255
10/09/2022 08:32:52 - INFO - __main__ -   epoch 6 step 1000 loss 0.04289
10/09/2022 08:33:25 - INFO - __main__ -   epoch 6 step 1100 loss 0.04284
10/09/2022 08:33:58 - INFO - __main__ -   epoch 6 step 1200 loss 0.04236
10/09/2022 08:34:31 - INFO - __main__ -   epoch 6 step 1300 loss 0.04066
10/09/2022 08:35:04 - INFO - __main__ -   epoch 6 step 1400 loss 0.0456
10/09/2022 08:35:38 - INFO - __main__ -   epoch 6 step 1500 loss 0.04467
10/09/2022 08:36:11 - INFO - __main__ -   epoch 6 step 1600 loss 0.04283
10/09/2022 08:36:44 - INFO - __main__ -   epoch 6 step 1700 loss 0.04238
10/09/2022 08:37:17 - INFO - __main__ -   epoch 6 step 1800 loss 0.04379
10/09/2022 08:37:50 - INFO - __main__ -   epoch 6 step 1900 loss 0.0434
10/09/2022 08:38:46 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:38:46 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:38:46 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:38:46 - INFO - __main__ -     Batch size = 128
10/09/2022 08:40:36 - INFO - __main__ -     R@1 = 0.615
10/09/2022 08:40:36 - INFO - __main__ -     R@5 = 0.836
10/09/2022 08:40:36 - INFO - __main__ -     R@10 = 0.886
10/09/2022 08:40:36 - INFO - __main__ -     eval_mrr = 0.714
10/09/2022 08:41:10 - INFO - __main__ -   epoch 7 step 100 loss 0.04091
10/09/2022 08:41:43 - INFO - __main__ -   epoch 7 step 200 loss 0.04005
10/09/2022 08:42:16 - INFO - __main__ -   epoch 7 step 300 loss 0.03914
10/09/2022 08:42:49 - INFO - __main__ -   epoch 7 step 400 loss 0.04153
10/09/2022 08:43:23 - INFO - __main__ -   epoch 7 step 500 loss 0.03793
10/09/2022 08:43:56 - INFO - __main__ -   epoch 7 step 600 loss 0.04108
10/09/2022 08:44:29 - INFO - __main__ -   epoch 7 step 700 loss 0.04013
10/09/2022 08:45:02 - INFO - __main__ -   epoch 7 step 800 loss 0.03837
10/09/2022 08:45:35 - INFO - __main__ -   epoch 7 step 900 loss 0.03907
10/09/2022 08:46:08 - INFO - __main__ -   epoch 7 step 1000 loss 0.03884
10/09/2022 08:46:42 - INFO - __main__ -   epoch 7 step 1100 loss 0.04188
10/09/2022 08:47:15 - INFO - __main__ -   epoch 7 step 1200 loss 0.0397
10/09/2022 08:47:48 - INFO - __main__ -   epoch 7 step 1300 loss 0.03986
10/09/2022 08:48:21 - INFO - __main__ -   epoch 7 step 1400 loss 0.04084
10/09/2022 08:48:54 - INFO - __main__ -   epoch 7 step 1500 loss 0.03642
10/09/2022 08:49:28 - INFO - __main__ -   epoch 7 step 1600 loss 0.04033
10/09/2022 08:50:01 - INFO - __main__ -   epoch 7 step 1700 loss 0.03802
10/09/2022 08:50:34 - INFO - __main__ -   epoch 7 step 1800 loss 0.04076
10/09/2022 08:51:07 - INFO - __main__ -   epoch 7 step 1900 loss 0.03892
10/09/2022 08:52:03 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:52:03 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:52:03 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:52:03 - INFO - __main__ -     Batch size = 128
10/09/2022 08:53:53 - INFO - __main__ -     R@1 = 0.613
10/09/2022 08:53:53 - INFO - __main__ -     R@5 = 0.836
10/09/2022 08:53:53 - INFO - __main__ -     R@10 = 0.885
10/09/2022 08:53:53 - INFO - __main__ -     eval_mrr = 0.713
10/09/2022 08:54:26 - INFO - __main__ -   epoch 8 step 100 loss 0.03661
10/09/2022 08:55:00 - INFO - __main__ -   epoch 8 step 200 loss 0.03557
10/09/2022 08:55:33 - INFO - __main__ -   epoch 8 step 300 loss 0.03714
10/09/2022 08:56:06 - INFO - __main__ -   epoch 8 step 400 loss 0.03557
10/09/2022 08:56:39 - INFO - __main__ -   epoch 8 step 500 loss 0.03648
10/09/2022 08:57:12 - INFO - __main__ -   epoch 8 step 600 loss 0.0394
10/09/2022 08:57:45 - INFO - __main__ -   epoch 8 step 700 loss 0.03533
10/09/2022 08:58:19 - INFO - __main__ -   epoch 8 step 800 loss 0.03735
10/09/2022 08:58:52 - INFO - __main__ -   epoch 8 step 900 loss 0.03725
10/09/2022 08:59:25 - INFO - __main__ -   epoch 8 step 1000 loss 0.0364
10/09/2022 08:59:58 - INFO - __main__ -   epoch 8 step 1100 loss 0.03817
10/09/2022 09:00:32 - INFO - __main__ -   epoch 8 step 1200 loss 0.03931
10/09/2022 09:01:05 - INFO - __main__ -   epoch 8 step 1300 loss 0.03873
10/09/2022 09:01:38 - INFO - __main__ -   epoch 8 step 1400 loss 0.03721
10/09/2022 09:02:11 - INFO - __main__ -   epoch 8 step 1500 loss 0.03958
10/09/2022 09:02:44 - INFO - __main__ -   epoch 8 step 1600 loss 0.03485
10/09/2022 09:03:17 - INFO - __main__ -   epoch 8 step 1700 loss 0.03764
10/09/2022 09:03:51 - INFO - __main__ -   epoch 8 step 1800 loss 0.03771
10/09/2022 09:04:24 - INFO - __main__ -   epoch 8 step 1900 loss 0.03883
10/09/2022 09:05:19 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:05:19 - INFO - __main__ -     Num queries = 13914
10/09/2022 09:05:19 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:05:19 - INFO - __main__ -     Batch size = 128
10/09/2022 09:07:09 - INFO - __main__ -     R@1 = 0.615
10/09/2022 09:07:09 - INFO - __main__ -     R@5 = 0.838
10/09/2022 09:07:09 - INFO - __main__ -     R@10 = 0.887
10/09/2022 09:07:09 - INFO - __main__ -     eval_mrr = 0.714
10/09/2022 09:07:43 - INFO - __main__ -   epoch 9 step 100 loss 0.03855
10/09/2022 09:08:16 - INFO - __main__ -   epoch 9 step 200 loss 0.03629
10/09/2022 09:08:50 - INFO - __main__ -   epoch 9 step 300 loss 0.03815
10/09/2022 09:09:23 - INFO - __main__ -   epoch 9 step 400 loss 0.03629
10/09/2022 09:09:56 - INFO - __main__ -   epoch 9 step 500 loss 0.03628
10/09/2022 09:10:29 - INFO - __main__ -   epoch 9 step 600 loss 0.03456
10/09/2022 09:11:02 - INFO - __main__ -   epoch 9 step 700 loss 0.03442
10/09/2022 09:11:36 - INFO - __main__ -   epoch 9 step 800 loss 0.03717
10/09/2022 09:12:09 - INFO - __main__ -   epoch 9 step 900 loss 0.03624
10/09/2022 09:12:42 - INFO - __main__ -   epoch 9 step 1000 loss 0.03589
10/09/2022 09:13:15 - INFO - __main__ -   epoch 9 step 1100 loss 0.0343
10/09/2022 09:13:48 - INFO - __main__ -   epoch 9 step 1200 loss 0.03588
10/09/2022 09:14:22 - INFO - __main__ -   epoch 9 step 1300 loss 0.03556
10/09/2022 09:14:55 - INFO - __main__ -   epoch 9 step 1400 loss 0.03466
10/09/2022 09:15:28 - INFO - __main__ -   epoch 9 step 1500 loss 0.03592
10/09/2022 09:16:02 - INFO - __main__ -   epoch 9 step 1600 loss 0.03791
10/09/2022 09:16:35 - INFO - __main__ -   epoch 9 step 1700 loss 0.0341
10/09/2022 09:17:08 - INFO - __main__ -   epoch 9 step 1800 loss 0.03498
10/09/2022 09:17:41 - INFO - __main__ -   epoch 9 step 1900 loss 0.03437
10/09/2022 09:18:37 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:18:37 - INFO - __main__ -     Num queries = 13914
10/09/2022 09:18:37 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:18:37 - INFO - __main__ -     Batch size = 128
10/09/2022 09:20:27 - INFO - __main__ -     R@1 = 0.617
10/09/2022 09:20:27 - INFO - __main__ -     R@5 = 0.837
10/09/2022 09:20:27 - INFO - __main__ -     R@10 = 0.887
10/09/2022 09:20:27 - INFO - __main__ -     eval_mrr = 0.715
10/09/2022 09:21:02 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:21:02 - INFO - __main__ -     Num queries = 13914
10/09/2022 09:21:02 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:21:02 - INFO - __main__ -     Batch size = 128
10/09/2022 09:22:51 - INFO - __main__ -   ***** Eval results *****
10/09/2022 09:22:51 - INFO - __main__ -     R@1 = 0.617
10/09/2022 09:22:51 - INFO - __main__ -     R@10 = 0.885
10/09/2022 09:22:51 - INFO - __main__ -     R@5 = 0.835
10/09/2022 09:22:51 - INFO - __main__ -     eval_mrr = 0.715
10/09/2022 09:23:26 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:23:26 - INFO - __main__ -     Num queries = 14918
10/09/2022 09:23:26 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:23:26 - INFO - __main__ -     Batch size = 128
10/09/2022 09:25:20 - INFO - __main__ -   ***** Eval results *****
10/09/2022 09:25:20 - INFO - __main__ -     R@1 = 0.627
10/09/2022 09:25:20 - INFO - __main__ -     R@10 = 0.896
10/09/2022 09:25:20 - INFO - __main__ -     R@5 = 0.847
10/09/2022 09:25:20 - INFO - __main__ -     eval_mrr = 0.725
10/09/2022 09:25:20 - INFO - utils -   saved dataset in saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_7_layers/20221009070247/result.jsonl

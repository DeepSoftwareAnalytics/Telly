10/09/2022 07:03:16 - INFO - __main__ -   device: cuda, n_gpu: 1
10/09/2022 07:03:17 - DEBUG - filelock -   Attempting to acquire lock 139739468066048 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:03:17 - DEBUG - filelock -   Lock 139739468066048 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   4%|▍         | 36.0k/916k [00:00<00:02, 367kB/s]Downloading:  19%|█▉        | 175k/916k [00:00<00:00, 968kB/s] Downloading:  79%|███████▊  | 719k/916k [00:00<00:00, 3.00MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 3.02MB/s]
10/09/2022 07:03:18 - DEBUG - filelock -   Attempting to release lock 139739468066048 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:03:18 - DEBUG - filelock -   Lock 139739468066048 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/09/2022 07:03:18 - DEBUG - filelock -   Attempting to acquire lock 139739468065904 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:03:18 - DEBUG - filelock -   Lock 139739468065904 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:  19%|█▉        | 84.0k/434k [00:00<00:00, 840kB/s]Downloading:  78%|███████▊  | 340k/434k [00:00<00:00, 1.84MB/s]Downloading: 100%|██████████| 434k/434k [00:00<00:00, 2.13MB/s]
10/09/2022 07:03:19 - DEBUG - filelock -   Attempting to release lock 139739468065904 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:03:19 - DEBUG - filelock -   Lock 139739468065904 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/09/2022 07:03:19 - DEBUG - filelock -   Attempting to acquire lock 139739468065904 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:03:19 - DEBUG - filelock -   Lock 139739468065904 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 594kB/s]
10/09/2022 07:03:19 - DEBUG - filelock -   Attempting to release lock 139739468065904 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:03:19 - DEBUG - filelock -   Lock 139739468065904 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/09/2022 07:03:20 - DEBUG - filelock -   Attempting to acquire lock 139739467652736 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:03:20 - DEBUG - filelock -   Lock 139739467652736 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 877kB/s]
10/09/2022 07:03:20 - DEBUG - filelock -   Attempting to release lock 139739467652736 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:03:20 - DEBUG - filelock -   Lock 139739467652736 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/09/2022 07:03:21 - DEBUG - filelock -   Attempting to acquire lock 139739467652880 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:03:21 - DEBUG - filelock -   Lock 139739467652880 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 338kB/s]
10/09/2022 07:03:21 - DEBUG - filelock -   Attempting to release lock 139739467652880 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:03:21 - DEBUG - filelock -   Lock 139739467652880 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/09/2022 07:03:22 - DEBUG - filelock -   Attempting to acquire lock 139739467926976 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:03:22 - DEBUG - filelock -   Lock 139739467926976 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   1%|▏         | 6.08M/480M [00:00<00:07, 63.7MB/s]Downloading:   3%|▎         | 15.3M/480M [00:00<00:05, 83.1MB/s]Downloading:   5%|▌         | 25.7M/480M [00:00<00:05, 95.1MB/s]Downloading:   7%|▋         | 36.0M/480M [00:00<00:04, 99.9MB/s]Downloading:  10%|▉         | 46.2M/480M [00:00<00:04, 102MB/s] Downloading:  12%|█▏        | 56.4M/480M [00:00<00:04, 104MB/s]Downloading:  14%|█▍        | 66.4M/480M [00:00<00:04, 104MB/s]Downloading:  16%|█▌        | 76.6M/480M [00:00<00:04, 105MB/s]Downloading:  18%|█▊        | 86.9M/480M [00:00<00:03, 106MB/s]Downloading:  20%|██        | 97.1M/480M [00:01<00:03, 106MB/s]Downloading:  22%|██▏       | 107M/480M [00:01<00:03, 107MB/s] Downloading:  25%|██▍       | 118M/480M [00:01<00:03, 108MB/s]Downloading:  27%|██▋       | 128M/480M [00:01<00:03, 107MB/s]Downloading:  29%|██▉       | 138M/480M [00:01<00:03, 107MB/s]Downloading:  31%|███       | 149M/480M [00:01<00:03, 107MB/s]Downloading:  33%|███▎      | 159M/480M [00:01<00:03, 107MB/s]Downloading:  35%|███▌      | 169M/480M [00:01<00:03, 107MB/s]Downloading:  37%|███▋      | 179M/480M [00:01<00:02, 107MB/s]Downloading:  39%|███▉      | 190M/480M [00:01<00:02, 107MB/s]Downloading:  42%|████▏     | 200M/480M [00:02<00:02, 107MB/s]Downloading:  44%|████▎     | 210M/480M [00:02<00:02, 107MB/s]Downloading:  46%|████▌     | 220M/480M [00:02<00:02, 107MB/s]Downloading:  48%|████▊     | 230M/480M [00:02<00:02, 107MB/s]Downloading:  50%|█████     | 241M/480M [00:02<00:02, 106MB/s]Downloading:  52%|█████▏    | 251M/480M [00:02<00:02, 106MB/s]Downloading:  54%|█████▍    | 261M/480M [00:02<00:02, 106MB/s]Downloading:  56%|█████▋    | 271M/480M [00:02<00:02, 106MB/s]Downloading:  59%|█████▊    | 281M/480M [00:02<00:01, 106MB/s]Downloading:  61%|██████    | 291M/480M [00:02<00:01, 106MB/s]Downloading:  63%|██████▎   | 301M/480M [00:03<00:01, 106MB/s]Downloading:  65%|██████▍   | 311M/480M [00:03<00:01, 105MB/s]Downloading:  67%|██████▋   | 322M/480M [00:03<00:01, 106MB/s]Downloading:  69%|██████▉   | 332M/480M [00:03<00:01, 105MB/s]Downloading:  71%|███████   | 342M/480M [00:03<00:01, 105MB/s]Downloading:  73%|███████▎  | 352M/480M [00:03<00:01, 105MB/s]Downloading:  75%|███████▌  | 362M/480M [00:03<00:01, 105MB/s]Downloading:  77%|███████▋  | 372M/480M [00:03<00:01, 105MB/s]Downloading:  80%|███████▉  | 382M/480M [00:03<00:00, 105MB/s]Downloading:  82%|████████▏ | 392M/480M [00:03<00:00, 105MB/s]Downloading:  84%|████████▎ | 402M/480M [00:04<00:00, 105MB/s]Downloading:  86%|████████▌ | 412M/480M [00:04<00:00, 106MB/s]Downloading:  88%|████████▊ | 423M/480M [00:04<00:00, 106MB/s]Downloading:  90%|█████████ | 433M/480M [00:04<00:00, 106MB/s]Downloading:  92%|█████████▏| 443M/480M [00:04<00:00, 106MB/s]Downloading:  94%|█████████▍| 453M/480M [00:04<00:00, 106MB/s]Downloading:  96%|█████████▋| 463M/480M [00:04<00:00, 106MB/s]Downloading:  99%|█████████▊| 473M/480M [00:04<00:00, 105MB/s]Downloading: 100%|██████████| 480M/480M [00:04<00:00, 105MB/s]
10/09/2022 07:03:27 - DEBUG - filelock -   Attempting to release lock 139739467926976 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:03:27 - DEBUG - filelock -   Lock 139739467926976 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/09/2022 07:03:28 - INFO - __main__ -   Training/evaluation parameters Namespace(code_length=256, codebase_file='dataset/CSN/python/codebase.jsonl', config_name='', debug=False, device=device(type='cuda'), do_F2_norm=False, do_eval=True, do_test=True, do_train=True, do_zero_shot=False, eval_batch_size=128, eval_data_file='dataset/CSN/python/valid.jsonl', freeze_bottom_k_layer_index=8, learning_rate=2e-05, max_grad_norm=1.0, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, nl_length=128, num_train_epochs=10, output_dir='saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310', seed=123456, test_data_file='dataset/CSN/python/test.jsonl', tokenizer_name='', train_batch_size=128, train_data_file='dataset/CSN/python/train.jsonl', weight_decay=0.01)
10/09/2022 07:03:28 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/09/2022 07:06:57 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:57 - INFO - __main__ -   idx: 0
10/09/2022 07:06:57 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_split', '_', 'phy', 'log', 'en', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_";"', '_)', '_[', '_0', '_]', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   code_ids: 0 6 2 729 5192 181 3258 896 386 207 400 428 2019 3144 385 437 201 120 743 545 3144 385 3144 513 12945 120 1046 385 428 746 5192 400 3144 743 483 1046 626 461 2406 513 3144 513 1046 626 524 2406 746 5192 400 29760 743 626 461 2406 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:57 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Return', '_either', '_the', '_full', '_or', '_truncated', '_version', '_of', '_a', '_Q', 'II', 'ME', '_-', '_formatted', '_taxonomy', '_string', '_.', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   nl_ids: 0 6 2 1675 4759 448 3662 872 19307 2229 595 434 1152 4300 1098 581 10440 29021 724 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:57 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:57 - INFO - __main__ -   idx: 1
10/09/2022 07:06:57 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'akedirs', '_(', '_d', '_)', '_except', '_OSError', '_as', '_oe', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'makedirs', '_#', '_ENOENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_errno', '_==', '_errno', '_.', '_ENOENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '__________________________', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '__________________________', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '__________________________', '_({})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_oe', '_.', '_strerror', '_)', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   code_ids: 0 6 2 729 6229 181 1282 400 480 743 545 462 800 2215 746 1391 746 4534 400 480 743 545 1568 545 2215 746 446 23328 400 480 743 3552 22934 880 44902 545 830 1570 800 7564 918 2215 132 24429 830 41059 144 4038 5632 1012 872 3456 462 2215 746 2341 550 2341 746 41059 545 2345 385 7916 443 400 1638 3533 872 2726 11613 488 448 1391 46072 1000 800 3040 132 1359 317 4584 2713 1147 15323 434 579 3456 563 1721 130 13874 6229 317 4584 1345 1946 11613 488 448 1391 6418 3040 6315 743 483 2345 746 2021 400 480 743 669 545 2345 385 7916 443 400 1638 1088 843 10058 11749 508 1738 448 1721 3456 317 4584 46072 918 1841 144 2334 3947 743 483 2345 746 2021 400 480 2019 44902 746 20115 743 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:57 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catch', 'es', '_OSError', '_exceptions', '_and', '_returns', '_a', '_desc', 'riptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   nl_ids: 0 6 2 1749 508 2002 3984 448 8813 3456 1391 2129 800 3040 462 1769 1738 835 746 1044 1454 2092 482 22934 12300 706 2060 434 2162 44105 1841 4488 595 479 581 47183 448 843 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:57 - INFO - __main__ -   *** Example ***
10/09/2022 07:06:57 - INFO - __main__ -   idx: 2
10/09/2022 07:06:57 - INFO - __main__ -   code_tokens: ['<s>', '<encoder-only>', '</s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_isinstance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_ValueError', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_elif', '_isinstance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   code_ids: 0 6 2 729 1012 181 2133 400 4065 190 2019 2119 385 437 200 171 120 743 545 2384 385 1938 462 5408 400 4065 190 2019 1012 743 545 462 4065 190 746 8264 545 3085 6052 400 437 1834 1012 555 8264 3508 743 2384 385 4065 190 3625 5408 400 4065 190 2019 1113 743 545 2384 385 2717 400 4065 190 2019 2119 743 483 2384 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:57 - INFO - __main__ -   nl_tokens: ['<s>', '<encoder-only>', '</s>', 'Takes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
10/09/2022 07:06:57 - INFO - __main__ -   nl_ids: 0 6 2 27408 4759 434 1012 1391 872 817 2717 1012 2384 7825 25911 706 2060 817 2717 1012 2384 872 23154 817 7900 2654 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/09/2022 07:06:58 - INFO - __main__ -   ***** Running training *****
10/09/2022 07:06:58 - INFO - __main__ -     Num examples = 251820
10/09/2022 07:06:58 - INFO - __main__ -     Num Epochs = 10
10/09/2022 07:06:58 - INFO - __main__ -     Instantaneous batch size per GPU = 128
10/09/2022 07:06:58 - INFO - __main__ -     Total train batch size  = 128
10/09/2022 07:06:58 - INFO - __main__ -     Total optimization steps = 19680
10/09/2022 07:07:30 - INFO - __main__ -   epoch 0 step 100 loss 0.23993
10/09/2022 07:08:01 - INFO - __main__ -   epoch 0 step 200 loss 0.17195
10/09/2022 07:08:31 - INFO - __main__ -   epoch 0 step 300 loss 0.15965
10/09/2022 07:09:01 - INFO - __main__ -   epoch 0 step 400 loss 0.15145
10/09/2022 07:09:31 - INFO - __main__ -   epoch 0 step 500 loss 0.15636
10/09/2022 07:10:02 - INFO - __main__ -   epoch 0 step 600 loss 0.1511
10/09/2022 07:10:32 - INFO - __main__ -   epoch 0 step 700 loss 0.14388
10/09/2022 07:11:02 - INFO - __main__ -   epoch 0 step 800 loss 0.13502
10/09/2022 07:11:32 - INFO - __main__ -   epoch 0 step 900 loss 0.13279
10/09/2022 07:12:03 - INFO - __main__ -   epoch 0 step 1000 loss 0.1252
10/09/2022 07:12:33 - INFO - __main__ -   epoch 0 step 1100 loss 0.1211
10/09/2022 07:13:03 - INFO - __main__ -   epoch 0 step 1200 loss 0.13576
10/09/2022 07:13:33 - INFO - __main__ -   epoch 0 step 1300 loss 0.11737
10/09/2022 07:14:03 - INFO - __main__ -   epoch 0 step 1400 loss 0.12825
10/09/2022 07:14:34 - INFO - __main__ -   epoch 0 step 1500 loss 0.13068
10/09/2022 07:15:04 - INFO - __main__ -   epoch 0 step 1600 loss 0.12214
10/09/2022 07:15:34 - INFO - __main__ -   epoch 0 step 1700 loss 0.12368
10/09/2022 07:16:04 - INFO - __main__ -   epoch 0 step 1800 loss 0.12085
10/09/2022 07:16:35 - INFO - __main__ -   epoch 0 step 1900 loss 0.12884
10/09/2022 07:17:34 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:17:34 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:17:34 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:17:34 - INFO - __main__ -     Batch size = 128
10/09/2022 07:19:24 - INFO - __main__ -     R@1 = 0.601
10/09/2022 07:19:24 - INFO - __main__ -     R@5 = 0.82
10/09/2022 07:19:24 - INFO - __main__ -     R@10 = 0.876
10/09/2022 07:19:24 - INFO - __main__ -     eval_mrr = 0.7
10/09/2022 07:19:24 - INFO - __main__ -     ********************
10/09/2022 07:19:24 - INFO - __main__ -     Best mrr:0.7
10/09/2022 07:19:24 - INFO - __main__ -     ********************
10/09/2022 07:19:33 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 07:20:04 - INFO - __main__ -   epoch 1 step 100 loss 0.10939
10/09/2022 07:20:35 - INFO - __main__ -   epoch 1 step 200 loss 0.10525
10/09/2022 07:21:05 - INFO - __main__ -   epoch 1 step 300 loss 0.10103
10/09/2022 07:21:35 - INFO - __main__ -   epoch 1 step 400 loss 0.1026
10/09/2022 07:22:05 - INFO - __main__ -   epoch 1 step 500 loss 0.10464
10/09/2022 07:22:36 - INFO - __main__ -   epoch 1 step 600 loss 0.10645
10/09/2022 07:23:06 - INFO - __main__ -   epoch 1 step 700 loss 0.09842
10/09/2022 07:23:36 - INFO - __main__ -   epoch 1 step 800 loss 0.112
10/09/2022 07:24:07 - INFO - __main__ -   epoch 1 step 900 loss 0.10848
10/09/2022 07:24:37 - INFO - __main__ -   epoch 1 step 1000 loss 0.10435
10/09/2022 07:25:07 - INFO - __main__ -   epoch 1 step 1100 loss 0.10875
10/09/2022 07:25:37 - INFO - __main__ -   epoch 1 step 1200 loss 0.09997
10/09/2022 07:26:08 - INFO - __main__ -   epoch 1 step 1300 loss 0.10267
10/09/2022 07:26:38 - INFO - __main__ -   epoch 1 step 1400 loss 0.10081
10/09/2022 07:27:08 - INFO - __main__ -   epoch 1 step 1500 loss 0.09795
10/09/2022 07:27:38 - INFO - __main__ -   epoch 1 step 1600 loss 0.09927
10/09/2022 07:28:09 - INFO - __main__ -   epoch 1 step 1700 loss 0.1013
10/09/2022 07:28:39 - INFO - __main__ -   epoch 1 step 1800 loss 0.10112
10/09/2022 07:29:09 - INFO - __main__ -   epoch 1 step 1900 loss 0.09862
10/09/2022 07:30:03 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:30:03 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:30:03 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:30:03 - INFO - __main__ -     Batch size = 128
10/09/2022 07:31:53 - INFO - __main__ -     R@1 = 0.608
10/09/2022 07:31:53 - INFO - __main__ -     R@5 = 0.828
10/09/2022 07:31:53 - INFO - __main__ -     R@10 = 0.879
10/09/2022 07:31:53 - INFO - __main__ -     eval_mrr = 0.707
10/09/2022 07:31:53 - INFO - __main__ -     ********************
10/09/2022 07:31:53 - INFO - __main__ -     Best mrr:0.707
10/09/2022 07:31:53 - INFO - __main__ -     ********************
10/09/2022 07:32:03 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 07:32:34 - INFO - __main__ -   epoch 2 step 100 loss 0.08967
10/09/2022 07:33:04 - INFO - __main__ -   epoch 2 step 200 loss 0.08209
10/09/2022 07:33:34 - INFO - __main__ -   epoch 2 step 300 loss 0.08353
10/09/2022 07:34:05 - INFO - __main__ -   epoch 2 step 400 loss 0.08338
10/09/2022 07:34:35 - INFO - __main__ -   epoch 2 step 500 loss 0.08727
10/09/2022 07:35:05 - INFO - __main__ -   epoch 2 step 600 loss 0.08808
10/09/2022 07:35:35 - INFO - __main__ -   epoch 2 step 700 loss 0.08479
10/09/2022 07:36:06 - INFO - __main__ -   epoch 2 step 800 loss 0.08342
10/09/2022 07:36:36 - INFO - __main__ -   epoch 2 step 900 loss 0.0945
10/09/2022 07:37:06 - INFO - __main__ -   epoch 2 step 1000 loss 0.08734
10/09/2022 07:37:36 - INFO - __main__ -   epoch 2 step 1100 loss 0.09204
10/09/2022 07:38:07 - INFO - __main__ -   epoch 2 step 1200 loss 0.08794
10/09/2022 07:38:37 - INFO - __main__ -   epoch 2 step 1300 loss 0.09192
10/09/2022 07:39:07 - INFO - __main__ -   epoch 2 step 1400 loss 0.09141
10/09/2022 07:39:38 - INFO - __main__ -   epoch 2 step 1500 loss 0.0868
10/09/2022 07:40:08 - INFO - __main__ -   epoch 2 step 1600 loss 0.09054
10/09/2022 07:40:38 - INFO - __main__ -   epoch 2 step 1700 loss 0.08593
10/09/2022 07:41:08 - INFO - __main__ -   epoch 2 step 1800 loss 0.08776
10/09/2022 07:41:39 - INFO - __main__ -   epoch 2 step 1900 loss 0.08944
10/09/2022 07:42:32 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:42:32 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:42:32 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:42:32 - INFO - __main__ -     Batch size = 128
10/09/2022 07:44:22 - INFO - __main__ -     R@1 = 0.609
10/09/2022 07:44:22 - INFO - __main__ -     R@5 = 0.83
10/09/2022 07:44:22 - INFO - __main__ -     R@10 = 0.881
10/09/2022 07:44:22 - INFO - __main__ -     eval_mrr = 0.708
10/09/2022 07:44:22 - INFO - __main__ -     ********************
10/09/2022 07:44:22 - INFO - __main__ -     Best mrr:0.708
10/09/2022 07:44:22 - INFO - __main__ -     ********************
10/09/2022 07:44:31 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 07:45:02 - INFO - __main__ -   epoch 3 step 100 loss 0.07981
10/09/2022 07:45:32 - INFO - __main__ -   epoch 3 step 200 loss 0.07214
10/09/2022 07:46:02 - INFO - __main__ -   epoch 3 step 300 loss 0.07976
10/09/2022 07:46:33 - INFO - __main__ -   epoch 3 step 400 loss 0.07488
10/09/2022 07:47:03 - INFO - __main__ -   epoch 3 step 500 loss 0.07928
10/09/2022 07:47:33 - INFO - __main__ -   epoch 3 step 600 loss 0.07376
10/09/2022 07:48:03 - INFO - __main__ -   epoch 3 step 700 loss 0.07922
10/09/2022 07:48:33 - INFO - __main__ -   epoch 3 step 800 loss 0.07605
10/09/2022 07:49:04 - INFO - __main__ -   epoch 3 step 900 loss 0.0788
10/09/2022 07:49:34 - INFO - __main__ -   epoch 3 step 1000 loss 0.07766
10/09/2022 07:50:04 - INFO - __main__ -   epoch 3 step 1100 loss 0.07309
10/09/2022 07:50:34 - INFO - __main__ -   epoch 3 step 1200 loss 0.07553
10/09/2022 07:51:05 - INFO - __main__ -   epoch 3 step 1300 loss 0.07639
10/09/2022 07:51:35 - INFO - __main__ -   epoch 3 step 1400 loss 0.07565
10/09/2022 07:52:05 - INFO - __main__ -   epoch 3 step 1500 loss 0.07087
10/09/2022 07:52:35 - INFO - __main__ -   epoch 3 step 1600 loss 0.0778
10/09/2022 07:53:06 - INFO - __main__ -   epoch 3 step 1700 loss 0.07371
10/09/2022 07:53:36 - INFO - __main__ -   epoch 3 step 1800 loss 0.07542
10/09/2022 07:54:06 - INFO - __main__ -   epoch 3 step 1900 loss 0.08167
10/09/2022 07:55:00 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 07:55:00 - INFO - __main__ -     Num queries = 13914
10/09/2022 07:55:00 - INFO - __main__ -     Num codes = 43827
10/09/2022 07:55:00 - INFO - __main__ -     Batch size = 128
10/09/2022 07:56:49 - INFO - __main__ -     R@1 = 0.609
10/09/2022 07:56:49 - INFO - __main__ -     R@5 = 0.832
10/09/2022 07:56:49 - INFO - __main__ -     R@10 = 0.882
10/09/2022 07:56:49 - INFO - __main__ -     eval_mrr = 0.709
10/09/2022 07:56:49 - INFO - __main__ -     ********************
10/09/2022 07:56:49 - INFO - __main__ -     Best mrr:0.709
10/09/2022 07:56:49 - INFO - __main__ -     ********************
10/09/2022 07:57:00 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 07:57:31 - INFO - __main__ -   epoch 4 step 100 loss 0.06779
10/09/2022 07:58:01 - INFO - __main__ -   epoch 4 step 200 loss 0.06557
10/09/2022 07:58:31 - INFO - __main__ -   epoch 4 step 300 loss 0.07039
10/09/2022 07:59:01 - INFO - __main__ -   epoch 4 step 400 loss 0.06938
10/09/2022 07:59:32 - INFO - __main__ -   epoch 4 step 500 loss 0.06745
10/09/2022 08:00:02 - INFO - __main__ -   epoch 4 step 600 loss 0.07156
10/09/2022 08:00:32 - INFO - __main__ -   epoch 4 step 700 loss 0.06838
10/09/2022 08:01:02 - INFO - __main__ -   epoch 4 step 800 loss 0.06767
10/09/2022 08:01:33 - INFO - __main__ -   epoch 4 step 900 loss 0.06653
10/09/2022 08:02:03 - INFO - __main__ -   epoch 4 step 1000 loss 0.06695
10/09/2022 08:02:33 - INFO - __main__ -   epoch 4 step 1100 loss 0.06316
10/09/2022 08:03:04 - INFO - __main__ -   epoch 4 step 1200 loss 0.06912
10/09/2022 08:03:34 - INFO - __main__ -   epoch 4 step 1300 loss 0.06706
10/09/2022 08:04:04 - INFO - __main__ -   epoch 4 step 1400 loss 0.06578
10/09/2022 08:04:34 - INFO - __main__ -   epoch 4 step 1500 loss 0.06973
10/09/2022 08:05:05 - INFO - __main__ -   epoch 4 step 1600 loss 0.06834
10/09/2022 08:05:35 - INFO - __main__ -   epoch 4 step 1700 loss 0.06658
10/09/2022 08:06:05 - INFO - __main__ -   epoch 4 step 1800 loss 0.07083
10/09/2022 08:06:35 - INFO - __main__ -   epoch 4 step 1900 loss 0.06943
10/09/2022 08:07:29 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:07:29 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:07:29 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:07:29 - INFO - __main__ -     Batch size = 128
10/09/2022 08:09:19 - INFO - __main__ -     R@1 = 0.61
10/09/2022 08:09:19 - INFO - __main__ -     R@5 = 0.831
10/09/2022 08:09:19 - INFO - __main__ -     R@10 = 0.881
10/09/2022 08:09:19 - INFO - __main__ -     eval_mrr = 0.709
10/09/2022 08:09:50 - INFO - __main__ -   epoch 5 step 100 loss 0.06015
10/09/2022 08:10:20 - INFO - __main__ -   epoch 5 step 200 loss 0.06217
10/09/2022 08:10:51 - INFO - __main__ -   epoch 5 step 300 loss 0.06123
10/09/2022 08:11:21 - INFO - __main__ -   epoch 5 step 400 loss 0.05841
10/09/2022 08:11:51 - INFO - __main__ -   epoch 5 step 500 loss 0.05773
10/09/2022 08:12:22 - INFO - __main__ -   epoch 5 step 600 loss 0.06122
10/09/2022 08:12:52 - INFO - __main__ -   epoch 5 step 700 loss 0.05818
10/09/2022 08:13:22 - INFO - __main__ -   epoch 5 step 800 loss 0.06426
10/09/2022 08:13:53 - INFO - __main__ -   epoch 5 step 900 loss 0.06265
10/09/2022 08:14:23 - INFO - __main__ -   epoch 5 step 1000 loss 0.05997
10/09/2022 08:14:53 - INFO - __main__ -   epoch 5 step 1100 loss 0.06063
10/09/2022 08:15:23 - INFO - __main__ -   epoch 5 step 1200 loss 0.05638
10/09/2022 08:15:54 - INFO - __main__ -   epoch 5 step 1300 loss 0.06282
10/09/2022 08:16:24 - INFO - __main__ -   epoch 5 step 1400 loss 0.06039
10/09/2022 08:16:54 - INFO - __main__ -   epoch 5 step 1500 loss 0.06311
10/09/2022 08:17:24 - INFO - __main__ -   epoch 5 step 1600 loss 0.06459
10/09/2022 08:17:55 - INFO - __main__ -   epoch 5 step 1700 loss 0.05725
10/09/2022 08:18:25 - INFO - __main__ -   epoch 5 step 1800 loss 0.06508
10/09/2022 08:18:55 - INFO - __main__ -   epoch 5 step 1900 loss 0.0625
10/09/2022 08:19:49 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:19:49 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:19:49 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:19:49 - INFO - __main__ -     Batch size = 128
10/09/2022 08:21:39 - INFO - __main__ -     R@1 = 0.611
10/09/2022 08:21:39 - INFO - __main__ -     R@5 = 0.832
10/09/2022 08:21:39 - INFO - __main__ -     R@10 = 0.883
10/09/2022 08:21:39 - INFO - __main__ -     eval_mrr = 0.71
10/09/2022 08:21:39 - INFO - __main__ -     ********************
10/09/2022 08:21:39 - INFO - __main__ -     Best mrr:0.71
10/09/2022 08:21:39 - INFO - __main__ -     ********************
10/09/2022 08:21:53 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 08:22:24 - INFO - __main__ -   epoch 6 step 100 loss 0.05847
10/09/2022 08:22:54 - INFO - __main__ -   epoch 6 step 200 loss 0.0581
10/09/2022 08:23:24 - INFO - __main__ -   epoch 6 step 300 loss 0.05392
10/09/2022 08:23:55 - INFO - __main__ -   epoch 6 step 400 loss 0.05296
10/09/2022 08:24:25 - INFO - __main__ -   epoch 6 step 500 loss 0.05532
10/09/2022 08:24:55 - INFO - __main__ -   epoch 6 step 600 loss 0.05763
10/09/2022 08:25:25 - INFO - __main__ -   epoch 6 step 700 loss 0.05294
10/09/2022 08:25:56 - INFO - __main__ -   epoch 6 step 800 loss 0.05447
10/09/2022 08:26:26 - INFO - __main__ -   epoch 6 step 900 loss 0.05613
10/09/2022 08:26:56 - INFO - __main__ -   epoch 6 step 1000 loss 0.05639
10/09/2022 08:27:26 - INFO - __main__ -   epoch 6 step 1100 loss 0.05576
10/09/2022 08:27:57 - INFO - __main__ -   epoch 6 step 1200 loss 0.05543
10/09/2022 08:28:27 - INFO - __main__ -   epoch 6 step 1300 loss 0.05289
10/09/2022 08:28:57 - INFO - __main__ -   epoch 6 step 1400 loss 0.05886
10/09/2022 08:29:27 - INFO - __main__ -   epoch 6 step 1500 loss 0.05719
10/09/2022 08:29:58 - INFO - __main__ -   epoch 6 step 1600 loss 0.05471
10/09/2022 08:30:28 - INFO - __main__ -   epoch 6 step 1700 loss 0.05537
10/09/2022 08:30:58 - INFO - __main__ -   epoch 6 step 1800 loss 0.05712
10/09/2022 08:31:28 - INFO - __main__ -   epoch 6 step 1900 loss 0.05555
10/09/2022 08:32:22 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:32:22 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:32:22 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:32:22 - INFO - __main__ -     Batch size = 128
10/09/2022 08:34:12 - INFO - __main__ -     R@1 = 0.612
10/09/2022 08:34:12 - INFO - __main__ -     R@5 = 0.834
10/09/2022 08:34:12 - INFO - __main__ -     R@10 = 0.884
10/09/2022 08:34:12 - INFO - __main__ -     eval_mrr = 0.71
10/09/2022 08:34:43 - INFO - __main__ -   epoch 7 step 100 loss 0.05471
10/09/2022 08:35:13 - INFO - __main__ -   epoch 7 step 200 loss 0.05283
10/09/2022 08:35:43 - INFO - __main__ -   epoch 7 step 300 loss 0.05116
10/09/2022 08:36:14 - INFO - __main__ -   epoch 7 step 400 loss 0.05553
10/09/2022 08:36:44 - INFO - __main__ -   epoch 7 step 500 loss 0.05018
10/09/2022 08:37:14 - INFO - __main__ -   epoch 7 step 600 loss 0.05341
10/09/2022 08:37:44 - INFO - __main__ -   epoch 7 step 700 loss 0.05295
10/09/2022 08:38:15 - INFO - __main__ -   epoch 7 step 800 loss 0.05031
10/09/2022 08:38:45 - INFO - __main__ -   epoch 7 step 900 loss 0.05197
10/09/2022 08:39:15 - INFO - __main__ -   epoch 7 step 1000 loss 0.05067
10/09/2022 08:39:46 - INFO - __main__ -   epoch 7 step 1100 loss 0.05472
10/09/2022 08:40:16 - INFO - __main__ -   epoch 7 step 1200 loss 0.05267
10/09/2022 08:40:46 - INFO - __main__ -   epoch 7 step 1300 loss 0.05187
10/09/2022 08:41:17 - INFO - __main__ -   epoch 7 step 1400 loss 0.05312
10/09/2022 08:41:47 - INFO - __main__ -   epoch 7 step 1500 loss 0.04692
10/09/2022 08:42:17 - INFO - __main__ -   epoch 7 step 1600 loss 0.0515
10/09/2022 08:42:48 - INFO - __main__ -   epoch 7 step 1700 loss 0.05068
10/09/2022 08:43:18 - INFO - __main__ -   epoch 7 step 1800 loss 0.05487
10/09/2022 08:43:48 - INFO - __main__ -   epoch 7 step 1900 loss 0.05176
10/09/2022 08:44:39 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:44:39 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:44:39 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:44:39 - INFO - __main__ -     Batch size = 128
10/09/2022 08:46:29 - INFO - __main__ -     R@1 = 0.611
10/09/2022 08:46:29 - INFO - __main__ -     R@5 = 0.834
10/09/2022 08:46:29 - INFO - __main__ -     R@10 = 0.882
10/09/2022 08:46:29 - INFO - __main__ -     eval_mrr = 0.71
10/09/2022 08:47:00 - INFO - __main__ -   epoch 8 step 100 loss 0.048
10/09/2022 08:47:30 - INFO - __main__ -   epoch 8 step 200 loss 0.04761
10/09/2022 08:48:01 - INFO - __main__ -   epoch 8 step 300 loss 0.04861
10/09/2022 08:48:31 - INFO - __main__ -   epoch 8 step 400 loss 0.04697
10/09/2022 08:49:01 - INFO - __main__ -   epoch 8 step 500 loss 0.04865
10/09/2022 08:49:31 - INFO - __main__ -   epoch 8 step 600 loss 0.05204
10/09/2022 08:50:02 - INFO - __main__ -   epoch 8 step 700 loss 0.04745
10/09/2022 08:50:32 - INFO - __main__ -   epoch 8 step 800 loss 0.04907
10/09/2022 08:51:02 - INFO - __main__ -   epoch 8 step 900 loss 0.04985
10/09/2022 08:51:32 - INFO - __main__ -   epoch 8 step 1000 loss 0.04791
10/09/2022 08:52:03 - INFO - __main__ -   epoch 8 step 1100 loss 0.05202
10/09/2022 08:52:33 - INFO - __main__ -   epoch 8 step 1200 loss 0.05153
10/09/2022 08:53:03 - INFO - __main__ -   epoch 8 step 1300 loss 0.05158
10/09/2022 08:53:33 - INFO - __main__ -   epoch 8 step 1400 loss 0.05099
10/09/2022 08:54:04 - INFO - __main__ -   epoch 8 step 1500 loss 0.05205
10/09/2022 08:54:34 - INFO - __main__ -   epoch 8 step 1600 loss 0.0452
10/09/2022 08:55:04 - INFO - __main__ -   epoch 8 step 1700 loss 0.05015
10/09/2022 08:55:34 - INFO - __main__ -   epoch 8 step 1800 loss 0.0495
10/09/2022 08:56:05 - INFO - __main__ -   epoch 8 step 1900 loss 0.05059
10/09/2022 08:57:00 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 08:57:00 - INFO - __main__ -     Num queries = 13914
10/09/2022 08:57:00 - INFO - __main__ -     Num codes = 43827
10/09/2022 08:57:00 - INFO - __main__ -     Batch size = 128
10/09/2022 08:58:50 - INFO - __main__ -     R@1 = 0.612
10/09/2022 08:58:50 - INFO - __main__ -     R@5 = 0.834
10/09/2022 08:58:50 - INFO - __main__ -     R@10 = 0.884
10/09/2022 08:58:50 - INFO - __main__ -     eval_mrr = 0.711
10/09/2022 08:58:50 - INFO - __main__ -     ********************
10/09/2022 08:58:50 - INFO - __main__ -     Best mrr:0.711
10/09/2022 08:58:50 - INFO - __main__ -     ********************
10/09/2022 08:58:57 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 08:59:28 - INFO - __main__ -   epoch 9 step 100 loss 0.05134
10/09/2022 08:59:58 - INFO - __main__ -   epoch 9 step 200 loss 0.04881
10/09/2022 09:00:29 - INFO - __main__ -   epoch 9 step 300 loss 0.05079
10/09/2022 09:00:59 - INFO - __main__ -   epoch 9 step 400 loss 0.04723
10/09/2022 09:01:29 - INFO - __main__ -   epoch 9 step 500 loss 0.04917
10/09/2022 09:02:00 - INFO - __main__ -   epoch 9 step 600 loss 0.04575
10/09/2022 09:02:30 - INFO - __main__ -   epoch 9 step 700 loss 0.04694
10/09/2022 09:03:00 - INFO - __main__ -   epoch 9 step 800 loss 0.04879
10/09/2022 09:03:30 - INFO - __main__ -   epoch 9 step 900 loss 0.04744
10/09/2022 09:04:01 - INFO - __main__ -   epoch 9 step 1000 loss 0.04768
10/09/2022 09:04:31 - INFO - __main__ -   epoch 9 step 1100 loss 0.04618
10/09/2022 09:05:01 - INFO - __main__ -   epoch 9 step 1200 loss 0.04816
10/09/2022 09:05:32 - INFO - __main__ -   epoch 9 step 1300 loss 0.04846
10/09/2022 09:06:02 - INFO - __main__ -   epoch 9 step 1400 loss 0.04748
10/09/2022 09:06:32 - INFO - __main__ -   epoch 9 step 1500 loss 0.04709
10/09/2022 09:07:02 - INFO - __main__ -   epoch 9 step 1600 loss 0.04993
10/09/2022 09:07:33 - INFO - __main__ -   epoch 9 step 1700 loss 0.04461
10/09/2022 09:08:03 - INFO - __main__ -   epoch 9 step 1800 loss 0.04665
10/09/2022 09:08:33 - INFO - __main__ -   epoch 9 step 1900 loss 0.04665
10/09/2022 09:09:27 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:09:27 - INFO - __main__ -     Num queries = 13914
10/09/2022 09:09:27 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:09:27 - INFO - __main__ -     Batch size = 128
10/09/2022 09:11:17 - INFO - __main__ -     R@1 = 0.613
10/09/2022 09:11:17 - INFO - __main__ -     R@5 = 0.835
10/09/2022 09:11:17 - INFO - __main__ -     R@10 = 0.884
10/09/2022 09:11:17 - INFO - __main__ -     eval_mrr = 0.712
10/09/2022 09:11:17 - INFO - __main__ -     ********************
10/09/2022 09:11:17 - INFO - __main__ -     Best mrr:0.712
10/09/2022 09:11:17 - INFO - __main__ -     ********************
10/09/2022 09:11:27 - INFO - __main__ -   Saving model checkpoint to saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/checkpoint-best-mrr/model.bin
10/09/2022 09:12:01 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:12:01 - INFO - __main__ -     Num queries = 13914
10/09/2022 09:12:01 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:12:01 - INFO - __main__ -     Batch size = 128
10/09/2022 09:13:51 - INFO - __main__ -   ***** Eval results *****
10/09/2022 09:13:51 - INFO - __main__ -     R@1 = 0.613
10/09/2022 09:13:51 - INFO - __main__ -     R@10 = 0.884
10/09/2022 09:13:51 - INFO - __main__ -     R@5 = 0.835
10/09/2022 09:13:51 - INFO - __main__ -     eval_mrr = 0.712
10/09/2022 09:14:25 - INFO - __main__ -   ***** Running evaluation *****
10/09/2022 09:14:25 - INFO - __main__ -     Num queries = 14918
10/09/2022 09:14:25 - INFO - __main__ -     Num codes = 43827
10/09/2022 09:14:25 - INFO - __main__ -     Batch size = 128
10/09/2022 09:16:19 - INFO - __main__ -   ***** Eval results *****
10/09/2022 09:16:20 - INFO - __main__ -     R@1 = 0.625
10/09/2022 09:16:20 - INFO - __main__ -     R@10 = 0.894
10/09/2022 09:16:20 - INFO - __main__ -     R@5 = 0.844
10/09/2022 09:16:20 - INFO - __main__ -     eval_mrr = 0.723
10/09/2022 09:16:20 - INFO - utils -   saved dataset in saved_models/code_search/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221009070310/result.jsonl

10/19/2022 00:34:19 - INFO - __main__ -   device: cuda, n_gpu: 1
10/19/2022 00:34:21 - DEBUG - filelock -   Attempting to acquire lock 139737553913504 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:34:21 - DEBUG - filelock -   Lock 139737553913504 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   4%|▍         | 40.0k/916k [00:00<00:02, 379kB/s]Downloading:  17%|█▋        | 153k/916k [00:00<00:01, 770kB/s] Downloading:  71%|███████   | 649k/916k [00:00<00:00, 2.51MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 2.79MB/s]
10/19/2022 00:34:21 - DEBUG - filelock -   Attempting to release lock 139737553913504 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:34:21 - DEBUG - filelock -   Lock 139737553913504 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:34:21 - DEBUG - filelock -   Attempting to acquire lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:34:21 - DEBUG - filelock -   Lock 139737552641760 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:   9%|▉         | 40.0k/434k [00:00<00:01, 399kB/s]Downloading:  44%|████▍     | 192k/434k [00:00<00:00, 1.05MB/s]Downloading: 100%|██████████| 434k/434k [00:00<00:00, 1.71MB/s]
10/19/2022 00:34:22 - DEBUG - filelock -   Attempting to release lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:34:22 - DEBUG - filelock -   Lock 139737552641760 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:34:22 - DEBUG - filelock -   Attempting to acquire lock 139737552693088 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:34:22 - DEBUG - filelock -   Lock 139737552693088 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 441kB/s]
10/19/2022 00:34:23 - DEBUG - filelock -   Attempting to release lock 139737552693088 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:34:23 - DEBUG - filelock -   Lock 139737552693088 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:34:23 - DEBUG - filelock -   Attempting to acquire lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:34:23 - DEBUG - filelock -   Lock 139737552641760 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 1.06MB/s]
10/19/2022 00:34:23 - DEBUG - filelock -   Attempting to release lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:34:23 - DEBUG - filelock -   Lock 139737552641760 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:34:24 - DEBUG - filelock -   Attempting to acquire lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:34:24 - DEBUG - filelock -   Lock 139737552641760 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 455kB/s]
10/19/2022 00:34:24 - DEBUG - filelock -   Attempting to release lock 139737552641760 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:34:24 - DEBUG - filelock -   Lock 139737552641760 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:34:25 - DEBUG - filelock -   Attempting to acquire lock 139737317482608 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:34:25 - DEBUG - filelock -   Lock 139737317482608 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   0%|          | 32.0k/480M [00:00<33:40, 249kB/s]Downloading:   0%|          | 80.0k/480M [00:00<23:47, 353kB/s]Downloading:   0%|          | 223k/480M [00:00<12:02, 697kB/s] Downloading:   0%|          | 487k/480M [00:00<06:45, 1.24MB/s]Downloading:   0%|          | 0.98M/480M [00:00<03:40, 2.28MB/s]Downloading:   0%|          | 2.00M/480M [00:00<01:57, 4.28MB/s]Downloading:   1%|          | 4.04M/480M [00:00<01:00, 8.20MB/s]Downloading:   1%|▏         | 7.02M/480M [00:01<00:37, 13.1MB/s]Downloading:   2%|▏         | 9.96M/480M [00:01<00:27, 17.6MB/s]Downloading:   2%|▏         | 12.0M/480M [00:01<00:26, 18.5MB/s]Downloading:   3%|▎         | 13.9M/480M [00:01<00:25, 19.1MB/s]Downloading:   3%|▎         | 16.0M/480M [00:01<00:24, 19.7MB/s]Downloading:   4%|▍         | 18.9M/480M [00:01<00:22, 21.0MB/s]Downloading:   5%|▍         | 21.8M/480M [00:01<00:20, 23.7MB/s]Downloading:   5%|▌         | 24.1M/480M [00:01<00:20, 23.1MB/s]Downloading:   5%|▌         | 26.3M/480M [00:01<00:20, 22.7MB/s]Downloading:   6%|▌         | 28.5M/480M [00:01<00:21, 22.3MB/s]Downloading:   6%|▋         | 30.8M/480M [00:02<00:21, 22.2MB/s]Downloading:   7%|▋         | 33.6M/480M [00:02<00:19, 24.5MB/s]Downloading:   7%|▋         | 36.0M/480M [00:02<00:19, 23.6MB/s]Downloading:   8%|▊         | 38.3M/480M [00:02<00:20, 23.2MB/s]Downloading:   8%|▊         | 40.5M/480M [00:02<00:20, 22.7MB/s]Downloading:   9%|▉         | 42.7M/480M [00:02<00:20, 22.6MB/s]Downloading:   9%|▉         | 45.5M/480M [00:02<00:18, 24.6MB/s]Downloading:  10%|▉         | 47.9M/480M [00:02<00:19, 23.8MB/s]Downloading:  10%|█         | 50.2M/480M [00:02<00:19, 23.2MB/s]Downloading:  11%|█         | 52.4M/480M [00:03<00:19, 22.8MB/s]Downloading:  11%|█▏        | 54.6M/480M [00:03<00:19, 22.7MB/s]Downloading:  12%|█▏        | 57.3M/480M [00:03<00:18, 24.4MB/s]Downloading:  12%|█▏        | 59.6M/480M [00:03<00:18, 23.6MB/s]Downloading:  13%|█▎        | 61.9M/480M [00:03<00:18, 23.2MB/s]Downloading:  13%|█▎        | 64.1M/480M [00:03<00:19, 22.7MB/s]Downloading:  14%|█▍        | 66.5M/480M [00:03<00:18, 22.9MB/s]Downloading:  14%|█▍        | 69.2M/480M [00:03<00:17, 24.5MB/s]Downloading:  15%|█▍        | 71.5M/480M [00:03<00:18, 23.7MB/s]Downloading:  15%|█▌        | 73.8M/480M [00:04<00:18, 23.2MB/s]Downloading:  16%|█▌        | 76.0M/480M [00:04<00:18, 22.7MB/s]Downloading:  16%|█▋        | 78.4M/480M [00:04<00:18, 23.0MB/s]Downloading:  17%|█▋        | 81.0M/480M [00:04<00:17, 24.4MB/s]Downloading:  17%|█▋        | 83.3M/480M [00:04<00:17, 23.7MB/s]Downloading:  18%|█▊        | 85.6M/480M [00:04<00:17, 23.2MB/s]Downloading:  18%|█▊        | 87.8M/480M [00:04<00:18, 22.8MB/s]Downloading:  19%|█▉        | 90.3M/480M [00:04<00:17, 23.2MB/s]Downloading:  19%|█▉        | 92.9M/480M [00:04<00:16, 24.3MB/s]Downloading:  20%|█▉        | 95.2M/480M [00:04<00:17, 23.6MB/s]Downloading:  20%|██        | 97.5M/480M [00:05<00:17, 23.2MB/s]Downloading:  21%|██        | 99.7M/480M [00:05<00:17, 22.8MB/s]Downloading:  21%|██▏       | 102M/480M [00:05<00:17, 23.3MB/s] Downloading:  22%|██▏       | 105M/480M [00:05<00:16, 24.0MB/s]Downloading:  22%|██▏       | 107M/480M [00:05<00:16, 23.6MB/s]Downloading:  23%|██▎       | 109M/480M [00:05<00:16, 23.1MB/s]Downloading:  23%|██▎       | 111M/480M [00:05<00:17, 22.5MB/s]Downloading:  24%|██▎       | 114M/480M [00:05<00:16, 23.6MB/s]Downloading:  24%|██▍       | 117M/480M [00:05<00:15, 24.1MB/s]Downloading:  25%|██▍       | 119M/480M [00:06<00:16, 23.6MB/s]Downloading:  25%|██▌       | 121M/480M [00:06<00:16, 23.1MB/s]Downloading:  26%|██▌       | 123M/480M [00:06<00:16, 22.6MB/s]Downloading:  26%|██▌       | 126M/480M [00:06<00:15, 23.7MB/s]Downloading:  27%|██▋       | 128M/480M [00:06<00:15, 24.0MB/s]Downloading:  27%|██▋       | 131M/480M [00:06<00:15, 23.6MB/s]Downloading:  28%|██▊       | 133M/480M [00:06<00:15, 23.0MB/s]Downloading:  28%|██▊       | 135M/480M [00:06<00:16, 22.6MB/s]Downloading:  29%|██▊       | 138M/480M [00:06<00:15, 23.9MB/s]Downloading:  29%|██▉       | 140M/480M [00:06<00:14, 24.0MB/s]Downloading:  30%|██▉       | 143M/480M [00:07<00:15, 23.6MB/s]Downloading:  30%|███       | 145M/480M [00:07<00:15, 23.1MB/s]Downloading:  31%|███       | 147M/480M [00:07<00:15, 22.6MB/s]Downloading:  31%|███       | 150M/480M [00:07<00:14, 24.2MB/s]Downloading:  32%|███▏      | 152M/480M [00:07<00:14, 23.8MB/s]Downloading:  32%|███▏      | 154M/480M [00:07<00:14, 23.4MB/s]Downloading:  33%|███▎      | 156M/480M [00:07<00:14, 23.0MB/s]Downloading:  33%|███▎      | 159M/480M [00:07<00:14, 22.9MB/s]Downloading:  34%|███▎      | 161M/480M [00:07<00:13, 24.0MB/s]Downloading:  34%|███▍      | 164M/480M [00:08<00:14, 23.7MB/s]Downloading:  35%|███▍      | 166M/480M [00:08<00:14, 23.4MB/s]Downloading:  35%|███▍      | 168M/480M [00:08<00:14, 22.9MB/s]Downloading:  36%|███▌      | 171M/480M [00:08<00:13, 23.6MB/s]Downloading:  36%|███▌      | 173M/480M [00:08<00:13, 23.8MB/s]Downloading:  36%|███▋      | 175M/480M [00:08<00:13, 23.8MB/s]Downloading:  37%|███▋      | 178M/480M [00:08<00:13, 23.2MB/s]Downloading:  37%|███▋      | 180M/480M [00:08<00:13, 22.7MB/s]Downloading:  38%|███▊      | 182M/480M [00:08<00:12, 24.1MB/s]Downloading:  38%|███▊      | 185M/480M [00:08<00:13, 23.8MB/s]Downloading:  39%|███▉      | 187M/480M [00:09<00:13, 23.4MB/s]Downloading:  39%|███▉      | 189M/480M [00:09<00:13, 23.0MB/s]Downloading:  40%|███▉      | 192M/480M [00:09<00:13, 23.0MB/s]Downloading:  40%|████      | 194M/480M [00:09<00:12, 23.8MB/s]Downloading:  41%|████      | 196M/480M [00:09<00:12, 23.6MB/s]Downloading:  41%|████▏     | 199M/480M [00:09<00:12, 23.2MB/s]Downloading:  42%|████▏     | 201M/480M [00:09<00:12, 22.9MB/s]Downloading:  42%|████▏     | 203M/480M [00:09<00:12, 24.0MB/s]Downloading:  43%|████▎     | 206M/480M [00:09<00:12, 23.8MB/s]Downloading:  43%|████▎     | 208M/480M [00:10<00:12, 23.4MB/s]Downloading:  44%|████▎     | 210M/480M [00:10<00:12, 22.9MB/s]Downloading:  44%|████▍     | 212M/480M [00:10<00:12, 23.1MB/s]Downloading:  45%|████▍     | 215M/480M [00:10<00:11, 24.0MB/s]Downloading:  45%|████▌     | 217M/480M [00:10<00:11, 23.7MB/s]Downloading:  46%|████▌     | 219M/480M [00:10<00:11, 23.0MB/s]Downloading:  46%|████▌     | 222M/480M [00:10<00:11, 22.8MB/s]Downloading:  47%|████▋     | 224M/480M [00:10<00:11, 24.1MB/s]Downloading:  47%|████▋     | 227M/480M [00:10<00:11, 23.8MB/s]Downloading:  48%|████▊     | 229M/480M [00:10<00:11, 23.2MB/s]Downloading:  48%|████▊     | 231M/480M [00:11<00:11, 23.0MB/s]Downloading:  49%|████▊     | 233M/480M [00:11<00:11, 23.1MB/s]Downloading:  49%|████▉     | 236M/480M [00:11<00:10, 24.2MB/s]Downloading:  50%|████▉     | 238M/480M [00:11<00:10, 23.6MB/s]Downloading:  50%|█████     | 240M/480M [00:11<00:10, 23.0MB/s]Downloading:  50%|█████     | 243M/480M [00:11<00:10, 22.9MB/s]Downloading:  51%|█████     | 245M/480M [00:11<00:10, 23.6MB/s]Downloading:  52%|█████▏    | 247M/480M [00:11<00:10, 24.0MB/s]Downloading:  52%|█████▏    | 250M/480M [00:11<00:10, 23.3MB/s]Downloading:  52%|█████▏    | 252M/480M [00:12<00:10, 23.0MB/s]Downloading:  53%|█████▎    | 254M/480M [00:12<00:10, 23.0MB/s]Downloading:  53%|█████▎    | 257M/480M [00:12<00:09, 24.3MB/s]Downloading:  54%|█████▍    | 259M/480M [00:12<00:09, 23.7MB/s]Downloading:  54%|█████▍    | 261M/480M [00:12<00:09, 23.2MB/s]Downloading:  55%|█████▍    | 264M/480M [00:12<00:09, 23.0MB/s]Downloading:  55%|█████▌    | 266M/480M [00:12<00:09, 23.4MB/s]Downloading:  56%|█████▌    | 268M/480M [00:12<00:09, 23.8MB/s]Downloading:  56%|█████▋    | 271M/480M [00:12<00:09, 23.4MB/s]Downloading:  57%|█████▋    | 273M/480M [00:12<00:09, 23.2MB/s]Downloading:  57%|█████▋    | 275M/480M [00:13<00:09, 23.0MB/s]Downloading:  58%|█████▊    | 278M/480M [00:13<00:08, 24.0MB/s]Downloading:  58%|█████▊    | 280M/480M [00:13<00:08, 23.6MB/s]Downloading:  59%|█████▊    | 282M/480M [00:13<00:08, 23.2MB/s]Downloading:  59%|█████▉    | 284M/480M [00:13<00:08, 23.0MB/s]Downloading:  60%|█████▉    | 287M/480M [00:13<00:08, 23.5MB/s]Downloading:  60%|██████    | 289M/480M [00:13<00:08, 23.8MB/s]Downloading:  61%|██████    | 291M/480M [00:13<00:08, 23.3MB/s]Downloading:  61%|██████    | 294M/480M [00:13<00:08, 23.0MB/s]Downloading:  62%|██████▏   | 296M/480M [00:13<00:08, 23.1MB/s]Downloading:  62%|██████▏   | 298M/480M [00:14<00:07, 24.1MB/s]Downloading:  63%|██████▎   | 301M/480M [00:14<00:07, 23.7MB/s]Downloading:  63%|██████▎   | 303M/480M [00:14<00:07, 23.3MB/s]Downloading:  64%|██████▎   | 305M/480M [00:14<00:07, 23.0MB/s]Downloading:  64%|██████▍   | 308M/480M [00:14<00:07, 23.6MB/s]Downloading:  64%|██████▍   | 310M/480M [00:14<00:07, 23.8MB/s]Downloading:  65%|██████▍   | 312M/480M [00:14<00:07, 23.3MB/s]Downloading:  65%|██████▌   | 314M/480M [00:14<00:07, 23.0MB/s]Downloading:  66%|██████▌   | 317M/480M [00:14<00:07, 23.2MB/s]Downloading:  66%|██████▋   | 319M/480M [00:14<00:07, 24.0MB/s]Downloading:  67%|██████▋   | 321M/480M [00:15<00:07, 23.6MB/s]Downloading:  67%|██████▋   | 324M/480M [00:15<00:07, 23.1MB/s]Downloading:  68%|██████▊   | 326M/480M [00:15<00:07, 23.1MB/s]Downloading:  68%|██████▊   | 328M/480M [00:15<00:06, 23.8MB/s]Downloading:  69%|██████▉   | 331M/480M [00:15<00:06, 23.6MB/s]Downloading:  69%|██████▉   | 333M/480M [00:15<00:06, 23.5MB/s]Downloading:  70%|██████▉   | 335M/480M [00:15<00:06, 23.1MB/s]Downloading:  70%|███████   | 337M/480M [00:15<00:06, 23.2MB/s]Downloading:  71%|███████   | 340M/480M [00:15<00:06, 24.0MB/s]Downloading:  71%|███████   | 342M/480M [00:16<00:06, 23.6MB/s]Downloading:  72%|███████▏  | 344M/480M [00:16<00:06, 23.2MB/s]Downloading:  72%|███████▏  | 347M/480M [00:16<00:06, 23.2MB/s]Downloading:  73%|███████▎  | 349M/480M [00:16<00:05, 24.1MB/s]Downloading:  73%|███████▎  | 351M/480M [00:16<00:05, 23.5MB/s]Downloading:  74%|███████▎  | 354M/480M [00:16<00:05, 23.2MB/s]Downloading:  74%|███████▍  | 356M/480M [00:16<00:05, 23.1MB/s]Downloading:  75%|███████▍  | 358M/480M [00:16<00:05, 23.4MB/s]Downloading:  75%|███████▌  | 361M/480M [00:16<00:05, 23.8MB/s]Downloading:  76%|███████▌  | 363M/480M [00:16<00:05, 23.5MB/s]Downloading:  76%|███████▌  | 365M/480M [00:17<00:05, 23.1MB/s]Downloading:  76%|███████▋  | 367M/480M [00:17<00:05, 23.1MB/s]Downloading:  77%|███████▋  | 370M/480M [00:17<00:04, 24.0MB/s]Downloading:  77%|███████▋  | 372M/480M [00:17<00:04, 23.8MB/s]Downloading:  78%|███████▊  | 374M/480M [00:17<00:04, 23.1MB/s]Downloading:  78%|███████▊  | 377M/480M [00:17<00:04, 23.1MB/s]Downloading:  79%|███████▉  | 379M/480M [00:17<00:04, 23.6MB/s]Downloading:  79%|███████▉  | 381M/480M [00:17<00:04, 23.7MB/s]Downloading:  80%|███████▉  | 384M/480M [00:17<00:04, 23.3MB/s]Downloading:  80%|████████  | 386M/480M [00:17<00:04, 23.2MB/s]Downloading:  81%|████████  | 388M/480M [00:18<00:04, 23.2MB/s]Downloading:  81%|████████▏ | 391M/480M [00:18<00:03, 24.0MB/s]Downloading:  82%|████████▏ | 393M/480M [00:18<00:03, 23.6MB/s]Downloading:  82%|████████▏ | 395M/480M [00:18<00:03, 23.3MB/s]Downloading:  83%|████████▎ | 397M/480M [00:18<00:03, 23.1MB/s]Downloading:  83%|████████▎ | 400M/480M [00:18<00:03, 23.9MB/s]Downloading:  84%|████████▎ | 402M/480M [00:18<00:03, 23.6MB/s]Downloading:  84%|████████▍ | 404M/480M [00:18<00:03, 23.2MB/s]Downloading:  85%|████████▍ | 407M/480M [00:18<00:03, 23.2MB/s]Downloading:  85%|████████▌ | 409M/480M [00:19<00:03, 23.3MB/s]Downloading:  86%|████████▌ | 411M/480M [00:19<00:03, 23.8MB/s]Downloading:  86%|████████▌ | 414M/480M [00:19<00:02, 23.5MB/s]Downloading:  87%|████████▋ | 416M/480M [00:19<00:02, 23.2MB/s]Downloading:  87%|████████▋ | 418M/480M [00:19<00:02, 23.1MB/s]Downloading:  88%|████████▊ | 420M/480M [00:19<00:02, 23.7MB/s]Downloading:  88%|████████▊ | 423M/480M [00:19<00:02, 23.7MB/s]Downloading:  88%|████████▊ | 425M/480M [00:19<00:02, 23.1MB/s]Downloading:  89%|████████▉ | 427M/480M [00:19<00:02, 23.3MB/s]Downloading:  89%|████████▉ | 430M/480M [00:19<00:02, 23.7MB/s]Downloading:  90%|████████▉ | 432M/480M [00:20<00:02, 23.5MB/s]Downloading:  90%|█████████ | 434M/480M [00:20<00:02, 23.3MB/s]Downloading:  91%|█████████ | 436M/480M [00:20<00:01, 23.2MB/s]Downloading:  91%|█████████▏| 439M/480M [00:20<00:01, 23.3MB/s]Downloading:  92%|█████████▏| 441M/480M [00:20<00:01, 23.9MB/s]Downloading:  92%|█████████▏| 443M/480M [00:20<00:01, 23.5MB/s]Downloading:  93%|█████████▎| 446M/480M [00:20<00:01, 23.3MB/s]Downloading:  93%|█████████▎| 448M/480M [00:20<00:01, 23.1MB/s]Downloading:  94%|█████████▎| 450M/480M [00:20<00:01, 23.7MB/s]Downloading:  94%|█████████▍| 452M/480M [00:20<00:01, 23.5MB/s]Downloading:  95%|█████████▍| 455M/480M [00:21<00:01, 23.0MB/s]Downloading:  95%|█████████▌| 457M/480M [00:21<00:01, 23.3MB/s]Downloading:  96%|█████████▌| 459M/480M [00:21<00:00, 23.8MB/s]Downloading:  96%|█████████▌| 462M/480M [00:21<00:00, 23.7MB/s]Downloading:  97%|█████████▋| 464M/480M [00:21<00:00, 23.1MB/s]Downloading:  97%|█████████▋| 466M/480M [00:21<00:00, 23.3MB/s]Downloading:  97%|█████████▋| 468M/480M [00:21<00:00, 23.2MB/s]Downloading:  98%|█████████▊| 471M/480M [00:21<00:00, 23.4MB/s]Downloading:  98%|█████████▊| 473M/480M [00:21<00:00, 23.4MB/s]Downloading:  99%|█████████▉| 475M/480M [00:21<00:00, 23.5MB/s]Downloading:  99%|█████████▉| 478M/480M [00:22<00:00, 23.3MB/s]Downloading: 100%|█████████▉| 480M/480M [00:22<00:00, 23.7MB/s]Downloading: 100%|██████████| 480M/480M [00:22<00:00, 22.7MB/s]
10/19/2022 00:34:47 - DEBUG - filelock -   Attempting to release lock 139737317482608 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:34:47 - DEBUG - filelock -   Lock 139737317482608 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:34:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, beam_size=10, debug=False, dev_filename='dataset/python/valid.jsonl', device=device(type='cuda'), do_eval=True, do_test=True, do_train=True, eval_batch_size=256, freeze_bottom_k_layer_index=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_grad_norm=1.0, max_source_length=256, max_target_length=128, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_0_layers/20221019003412', seed=123456, test_filename='dataset/python/test.jsonl', train_batch_size=32, train_filename='dataset/python/train.jsonl', weight_decay=0.0)
10/19/2022 00:34:54 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.0.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.0.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.0.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.0.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.0.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.0.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.0.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.0.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.0.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.0.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.0.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.0.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.0.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.0.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.0.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.0.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.1.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.1.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.1.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.1.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.1.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.1.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.1.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.1.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.1.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.1.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.1.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.1.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.1.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.1.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.1.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.1.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.2.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.2.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.2.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.2.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.2.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.2.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.2.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.2.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.2.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.2.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.2.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.2.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.2.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.2.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.2.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.2.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.3.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.3.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.3.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.3.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.3.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.3.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.3.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.3.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.3.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.3.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.3.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.3.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.3.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.3.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.3.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.3.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.4.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.4.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.4.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.4.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.4.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.4.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.4.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.4.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.4.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.4.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.4.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.5.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.5.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.5.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.5.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.5.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.5.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.5.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.5.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.5.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.6.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.6.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.6.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.6.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.7.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.7.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.7.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.7.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
| dense.weight                                               |   [768, 768] |  589824 |
| dense.bias                                                 |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/19/2022 00:34:54 - INFO - __main__ -   The model has 86235648 trainable parameters
10/19/2022 00:35:06 - INFO - __main__ -   *** Example ***
10/19/2022 00:35:06 - INFO - __main__ -   idx: 0
10/19/2022 00:35:06 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_split', '_', 'phy', 'log', 'en', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_";"', '_)', '_[', '_0', '_]', '</s>']
10/19/2022 00:35:06 - INFO - __main__ -   source_ids: 0 5 2 19 729 5192 181 3258 896 386 207 400 428 2019 3144 385 437 201 120 743 545 3144 385 3144 513 12945 120 1046 385 428 746 5192 400 3144 743 483 1046 626 461 2406 513 3144 513 1046 626 524 2406 746 5192 400 29760 743 626 461 2406 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:35:06 - INFO - __main__ -   target_tokens: ['<mask0>', 'Return', '_either', '_the', '_full', '_or', '_truncated', '_version', '_of', '_a', '_Q', 'II', 'ME', '_-', '_formatted', '_taxonomy', '_string', '_.', '</s>']
10/19/2022 00:35:06 - INFO - __main__ -   target_ids: 19 1675 4759 448 3662 872 19307 2229 595 434 1152 4300 1098 581 10440 29021 724 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:35:06 - INFO - __main__ -   *** Example ***
10/19/2022 00:35:06 - INFO - __main__ -   idx: 1
10/19/2022 00:35:06 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'akedirs', '_(', '_d', '_)', '_except', '_OSError', '_as', '_oe', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'makedirs', '_#', '_ENOENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_errno', '_==', '_errno', '_.', '_ENOENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({})', '_do', '_not', '_exist', '.', '_If', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', '_({})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_oe', '_.', '_strerror', '_)', '</s>']
10/19/2022 00:35:06 - INFO - __main__ -   source_ids: 0 5 2 19 729 6229 181 1282 400 480 743 545 462 800 2215 746 1391 746 4534 400 480 743 545 1568 545 2215 746 446 23328 400 480 743 3552 22934 880 44902 545 830 1570 800 7564 918 2215 132 24429 830 41059 144 4038 5632 1012 872 3456 462 2215 746 2341 550 2341 746 41059 545 2345 385 7916 443 400 1638 3533 872 2726 11613 488 448 1391 46072 1000 800 3040 132 1359 2713 1147 15323 434 579 3456 563 1721 130 13874 6229 1345 1946 11613 488 448 1391 6418 3040 6315 743 483 2345 746 2021 400 480 743 669 545 2345 385 7916 443 400 1638 1088 843 10058 11749 508 1738 448 1721 3456 46072 918 1841 144 2334 3947 743 483 2345 746 2021 400 480 2019 44902 746 20115 743 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:35:06 - INFO - __main__ -   target_tokens: ['<mask0>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catch', 'es', '_OSError', '_exceptions', '_and', '_returns', '_a', '_desc', 'riptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/19/2022 00:35:06 - INFO - __main__ -   target_ids: 19 1749 508 2002 3984 448 8813 3456 1391 2129 800 3040 462 1769 1738 835 746 1044 1454 2092 482 22934 12300 706 2060 434 2162 44105 1841 4488 595 479 581 47183 448 843 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:38:17 - INFO - __main__ -   ***** Running training *****
10/19/2022 00:38:17 - INFO - __main__ -     Num examples = 251820
10/19/2022 00:38:17 - INFO - __main__ -     Batch size = 32
10/19/2022 00:38:17 - INFO - __main__ -     Num epoch = 10
10/19/2022 00:38:35 - INFO - __main__ -   epoch 0 step 100 loss 3.2995
10/19/2022 00:38:52 - INFO - __main__ -   epoch 0 step 200 loss 3.0488
10/19/2022 00:39:08 - INFO - __main__ -   epoch 0 step 300 loss 2.8161
10/19/2022 00:39:25 - INFO - __main__ -   epoch 0 step 400 loss 2.7379
10/19/2022 00:39:42 - INFO - __main__ -   epoch 0 step 500 loss 2.6881
10/19/2022 00:39:58 - INFO - __main__ -   epoch 0 step 600 loss 2.6819
10/19/2022 00:40:15 - INFO - __main__ -   epoch 0 step 700 loss 2.6758
10/19/2022 00:40:32 - INFO - __main__ -   epoch 0 step 800 loss 2.6593
10/19/2022 00:40:48 - INFO - __main__ -   epoch 0 step 900 loss 2.6807
10/19/2022 00:41:05 - INFO - __main__ -   epoch 0 step 1000 loss 2.6466
10/19/2022 00:41:22 - INFO - __main__ -   epoch 0 step 1100 loss 2.6227
10/19/2022 00:41:39 - INFO - __main__ -   epoch 0 step 1200 loss 2.5887
10/19/2022 00:41:55 - INFO - __main__ -   epoch 0 step 1300 loss 2.6162
10/19/2022 00:42:12 - INFO - __main__ -   epoch 0 step 1400 loss 2.6267
10/19/2022 00:42:29 - INFO - __main__ -   epoch 0 step 1500 loss 2.6315
10/19/2022 00:42:46 - INFO - __main__ -   epoch 0 step 1600 loss 2.6277
10/19/2022 00:43:03 - INFO - __main__ -   epoch 0 step 1700 loss 2.5961
10/19/2022 00:43:19 - INFO - __main__ -   epoch 0 step 1800 loss 2.5756
10/19/2022 00:43:36 - INFO - __main__ -   epoch 0 step 1900 loss 2.5825
10/19/2022 00:43:53 - INFO - __main__ -   epoch 0 step 2000 loss 2.578
10/19/2022 00:44:09 - INFO - __main__ -   epoch 0 step 2100 loss 2.6097
10/19/2022 00:44:26 - INFO - __main__ -   epoch 0 step 2200 loss 2.5745
10/19/2022 00:44:43 - INFO - __main__ -   epoch 0 step 2300 loss 2.5878
10/19/2022 00:45:00 - INFO - __main__ -   epoch 0 step 2400 loss 2.584
10/19/2022 00:45:17 - INFO - __main__ -   epoch 0 step 2500 loss 2.5721
10/19/2022 00:45:34 - INFO - __main__ -   epoch 0 step 2600 loss 2.6024
10/19/2022 00:45:51 - INFO - __main__ -   epoch 0 step 2700 loss 2.5927
10/19/2022 00:46:07 - INFO - __main__ -   epoch 0 step 2800 loss 2.5883
10/19/2022 00:46:24 - INFO - __main__ -   epoch 0 step 2900 loss 2.6063
10/19/2022 00:46:41 - INFO - __main__ -   epoch 0 step 3000 loss 2.5622
10/19/2022 00:46:58 - INFO - __main__ -   epoch 0 step 3100 loss 2.6045
10/19/2022 00:47:14 - INFO - __main__ -   epoch 0 step 3200 loss 2.5737
10/19/2022 00:47:31 - INFO - __main__ -   epoch 0 step 3300 loss 2.5828
10/19/2022 00:47:48 - INFO - __main__ -   epoch 0 step 3400 loss 2.6081
10/19/2022 00:48:05 - INFO - __main__ -   epoch 0 step 3500 loss 2.555
10/19/2022 00:48:21 - INFO - __main__ -   epoch 0 step 3600 loss 2.5604
10/19/2022 00:48:38 - INFO - __main__ -   epoch 0 step 3700 loss 2.5779
10/19/2022 00:48:55 - INFO - __main__ -   epoch 0 step 3800 loss 2.5882
10/19/2022 00:49:12 - INFO - __main__ -   epoch 0 step 3900 loss 2.5692
10/19/2022 00:49:28 - INFO - __main__ -   epoch 0 step 4000 loss 2.5791
10/19/2022 00:49:45 - INFO - __main__ -   epoch 0 step 4100 loss 2.5882
10/19/2022 00:50:02 - INFO - __main__ -   epoch 0 step 4200 loss 2.568
10/19/2022 00:50:19 - INFO - __main__ -   epoch 0 step 4300 loss 2.5862
10/19/2022 00:50:35 - INFO - __main__ -   epoch 0 step 4400 loss 2.5556
10/19/2022 00:50:52 - INFO - __main__ -   epoch 0 step 4500 loss 2.5694
10/19/2022 00:51:09 - INFO - __main__ -   epoch 0 step 4600 loss 2.5914
10/19/2022 00:51:26 - INFO - __main__ -   epoch 0 step 4700 loss 2.5626
10/19/2022 00:51:42 - INFO - __main__ -   epoch 0 step 4800 loss 2.5819
10/19/2022 00:51:59 - INFO - __main__ -   epoch 0 step 4900 loss 2.5827
10/19/2022 00:52:16 - INFO - __main__ -   epoch 0 step 5000 loss 2.5745
10/19/2022 00:52:33 - INFO - __main__ -   epoch 0 step 5100 loss 2.5838
10/19/2022 00:52:49 - INFO - __main__ -   epoch 0 step 5200 loss 2.553
10/19/2022 00:53:06 - INFO - __main__ -   epoch 0 step 5300 loss 2.6115
10/19/2022 00:53:23 - INFO - __main__ -   epoch 0 step 5400 loss 2.5507
10/19/2022 00:53:40 - INFO - __main__ -   epoch 0 step 5500 loss 2.5742
10/19/2022 00:53:56 - INFO - __main__ -   epoch 0 step 5600 loss 2.5687
10/19/2022 00:54:13 - INFO - __main__ -   epoch 0 step 5700 loss 2.5773
10/19/2022 00:54:30 - INFO - __main__ -   epoch 0 step 5800 loss 2.5695
10/19/2022 00:54:47 - INFO - __main__ -   epoch 0 step 5900 loss 2.5486
10/19/2022 00:55:03 - INFO - __main__ -   epoch 0 step 6000 loss 2.5321
10/19/2022 00:55:20 - INFO - __main__ -   epoch 0 step 6100 loss 2.5795
10/19/2022 00:55:37 - INFO - __main__ -   epoch 0 step 6200 loss 2.5574
10/19/2022 00:55:54 - INFO - __main__ -   epoch 0 step 6300 loss 2.5778
10/19/2022 00:56:11 - INFO - __main__ -   epoch 0 step 6400 loss 2.5684
10/19/2022 00:56:27 - INFO - __main__ -   epoch 0 step 6500 loss 2.5887
10/19/2022 00:56:44 - INFO - __main__ -   epoch 0 step 6600 loss 2.555
10/19/2022 00:57:01 - INFO - __main__ -   epoch 0 step 6700 loss 2.5612
10/19/2022 00:57:18 - INFO - __main__ -   epoch 0 step 6800 loss 2.5923
10/19/2022 00:57:34 - INFO - __main__ -   epoch 0 step 6900 loss 2.5913
10/19/2022 00:57:51 - INFO - __main__ -   epoch 0 step 7000 loss 2.5952
10/19/2022 00:58:08 - INFO - __main__ -   epoch 0 step 7100 loss 2.5319
10/19/2022 00:58:24 - INFO - __main__ -   epoch 0 step 7200 loss 2.5311
10/19/2022 00:58:41 - INFO - __main__ -   epoch 0 step 7300 loss 2.5649
10/19/2022 00:58:58 - INFO - __main__ -   epoch 0 step 7400 loss 2.5565
10/19/2022 00:59:15 - INFO - __main__ -   epoch 0 step 7500 loss 2.5643
10/19/2022 00:59:31 - INFO - __main__ -   epoch 0 step 7600 loss 2.5705
10/19/2022 00:59:48 - INFO - __main__ -   epoch 0 step 7700 loss 2.5656
10/19/2022 01:00:05 - INFO - __main__ -   epoch 0 step 7800 loss 2.5836
10/19/2022 01:00:28 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:00:28 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:00:28 - INFO - __main__ -     Batch size = 256
10/19/2022 01:00:51 - INFO - __main__ -     eval_ppl = 15.41142
10/19/2022 01:00:51 - INFO - __main__ -     ********************
/sci_1/t-enshengshi/interpretability/sync_repo/bertviz/code-summarization/model.py:189: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
Total: 1000
10/19/2022 01:03:37 - INFO - __main__ -     bleu-4 = 18.37 
10/19/2022 01:03:37 - INFO - __main__ -     ********************
10/19/2022 01:03:37 - INFO - __main__ -     Best bleu:18.37
10/19/2022 01:03:37 - INFO - __main__ -     ********************
10/19/2022 01:03:54 - INFO - __main__ -   epoch 1 step 7900 loss 2.536
10/19/2022 01:04:10 - INFO - __main__ -   epoch 1 step 8000 loss 2.4199
10/19/2022 01:04:27 - INFO - __main__ -   epoch 1 step 8100 loss 2.4466
10/19/2022 01:04:44 - INFO - __main__ -   epoch 1 step 8200 loss 2.4538
10/19/2022 01:05:00 - INFO - __main__ -   epoch 1 step 8300 loss 2.4367
10/19/2022 01:05:17 - INFO - __main__ -   epoch 1 step 8400 loss 2.4514
10/19/2022 01:05:34 - INFO - __main__ -   epoch 1 step 8500 loss 2.4255
10/19/2022 01:05:51 - INFO - __main__ -   epoch 1 step 8600 loss 2.462
10/19/2022 01:06:07 - INFO - __main__ -   epoch 1 step 8700 loss 2.4543
10/19/2022 01:06:24 - INFO - __main__ -   epoch 1 step 8800 loss 2.4641
10/19/2022 01:06:41 - INFO - __main__ -   epoch 1 step 8900 loss 2.4905
10/19/2022 01:06:58 - INFO - __main__ -   epoch 1 step 9000 loss 2.4534
10/19/2022 01:07:15 - INFO - __main__ -   epoch 1 step 9100 loss 2.4493
10/19/2022 01:07:31 - INFO - __main__ -   epoch 1 step 9200 loss 2.4593
10/19/2022 01:07:48 - INFO - __main__ -   epoch 1 step 9300 loss 2.445
10/19/2022 01:08:05 - INFO - __main__ -   epoch 1 step 9400 loss 2.4312
10/19/2022 01:08:21 - INFO - __main__ -   epoch 1 step 9500 loss 2.421
10/19/2022 01:08:38 - INFO - __main__ -   epoch 1 step 9600 loss 2.4587
10/19/2022 01:08:55 - INFO - __main__ -   epoch 1 step 9700 loss 2.4463
10/19/2022 01:09:12 - INFO - __main__ -   epoch 1 step 9800 loss 2.4442
10/19/2022 01:09:28 - INFO - __main__ -   epoch 1 step 9900 loss 2.4756
10/19/2022 01:09:45 - INFO - __main__ -   epoch 1 step 10000 loss 2.4529
10/19/2022 01:10:02 - INFO - __main__ -   epoch 1 step 10100 loss 2.4724
10/19/2022 01:10:19 - INFO - __main__ -   epoch 1 step 10200 loss 2.4363
10/19/2022 01:10:35 - INFO - __main__ -   epoch 1 step 10300 loss 2.4815
10/19/2022 01:10:52 - INFO - __main__ -   epoch 1 step 10400 loss 2.4446
10/19/2022 01:11:09 - INFO - __main__ -   epoch 1 step 10500 loss 2.421
10/19/2022 01:11:26 - INFO - __main__ -   epoch 1 step 10600 loss 2.4523
10/19/2022 01:11:42 - INFO - __main__ -   epoch 1 step 10700 loss 2.5071
10/19/2022 01:11:59 - INFO - __main__ -   epoch 1 step 10800 loss 2.4932
10/19/2022 01:12:16 - INFO - __main__ -   epoch 1 step 10900 loss 2.4712
10/19/2022 01:12:33 - INFO - __main__ -   epoch 1 step 11000 loss 2.4377
10/19/2022 01:12:50 - INFO - __main__ -   epoch 1 step 11100 loss 2.4764
10/19/2022 01:13:06 - INFO - __main__ -   epoch 1 step 11200 loss 2.4658
10/19/2022 01:13:23 - INFO - __main__ -   epoch 1 step 11300 loss 2.4611
10/19/2022 01:13:40 - INFO - __main__ -   epoch 1 step 11400 loss 2.4271
10/19/2022 01:13:57 - INFO - __main__ -   epoch 1 step 11500 loss 2.4323
10/19/2022 01:14:14 - INFO - __main__ -   epoch 1 step 11600 loss 2.4703
10/19/2022 01:14:31 - INFO - __main__ -   epoch 1 step 11700 loss 2.446
10/19/2022 01:14:47 - INFO - __main__ -   epoch 1 step 11800 loss 2.4514
10/19/2022 01:15:04 - INFO - __main__ -   epoch 1 step 11900 loss 2.4373
10/19/2022 01:15:21 - INFO - __main__ -   epoch 1 step 12000 loss 2.4519
10/19/2022 01:15:38 - INFO - __main__ -   epoch 1 step 12100 loss 2.4404
10/19/2022 01:15:54 - INFO - __main__ -   epoch 1 step 12200 loss 2.4198
10/19/2022 01:16:11 - INFO - __main__ -   epoch 1 step 12300 loss 2.445
10/19/2022 01:16:28 - INFO - __main__ -   epoch 1 step 12400 loss 2.4706
10/19/2022 01:16:44 - INFO - __main__ -   epoch 1 step 12500 loss 2.4283
10/19/2022 01:17:01 - INFO - __main__ -   epoch 1 step 12600 loss 2.4466
10/19/2022 01:17:18 - INFO - __main__ -   epoch 1 step 12700 loss 2.4224
10/19/2022 01:17:35 - INFO - __main__ -   epoch 1 step 12800 loss 2.4192
10/19/2022 01:17:51 - INFO - __main__ -   epoch 1 step 12900 loss 2.4319
10/19/2022 01:18:08 - INFO - __main__ -   epoch 1 step 13000 loss 2.4374
10/19/2022 01:18:25 - INFO - __main__ -   epoch 1 step 13100 loss 2.4413
10/19/2022 01:18:41 - INFO - __main__ -   epoch 1 step 13200 loss 2.4611
10/19/2022 01:18:58 - INFO - __main__ -   epoch 1 step 13300 loss 2.44
10/19/2022 01:19:15 - INFO - __main__ -   epoch 1 step 13400 loss 2.4577
10/19/2022 01:19:32 - INFO - __main__ -   epoch 1 step 13500 loss 2.4294
10/19/2022 01:19:48 - INFO - __main__ -   epoch 1 step 13600 loss 2.4261
10/19/2022 01:20:05 - INFO - __main__ -   epoch 1 step 13700 loss 2.4628
10/19/2022 01:20:22 - INFO - __main__ -   epoch 1 step 13800 loss 2.4406
10/19/2022 01:20:39 - INFO - __main__ -   epoch 1 step 13900 loss 2.4308
10/19/2022 01:20:55 - INFO - __main__ -   epoch 1 step 14000 loss 2.4582
10/19/2022 01:21:12 - INFO - __main__ -   epoch 1 step 14100 loss 2.4308
10/19/2022 01:21:29 - INFO - __main__ -   epoch 1 step 14200 loss 2.4211
10/19/2022 01:21:45 - INFO - __main__ -   epoch 1 step 14300 loss 2.4289
10/19/2022 01:22:02 - INFO - __main__ -   epoch 1 step 14400 loss 2.3992
10/19/2022 01:22:19 - INFO - __main__ -   epoch 1 step 14500 loss 2.421
10/19/2022 01:22:35 - INFO - __main__ -   epoch 1 step 14600 loss 2.4496
10/19/2022 01:22:52 - INFO - __main__ -   epoch 1 step 14700 loss 2.3883
10/19/2022 01:23:09 - INFO - __main__ -   epoch 1 step 14800 loss 2.4352
10/19/2022 01:23:26 - INFO - __main__ -   epoch 1 step 14900 loss 2.4603
10/19/2022 01:23:42 - INFO - __main__ -   epoch 1 step 15000 loss 2.4045
10/19/2022 01:23:59 - INFO - __main__ -   epoch 1 step 15100 loss 2.4321
10/19/2022 01:24:16 - INFO - __main__ -   epoch 1 step 15200 loss 2.4275
10/19/2022 01:24:33 - INFO - __main__ -   epoch 1 step 15300 loss 2.4632
10/19/2022 01:24:49 - INFO - __main__ -   epoch 1 step 15400 loss 2.445
10/19/2022 01:25:06 - INFO - __main__ -   epoch 1 step 15500 loss 2.4256
10/19/2022 01:25:23 - INFO - __main__ -   epoch 1 step 15600 loss 2.4402
10/19/2022 01:25:39 - INFO - __main__ -   epoch 1 step 15700 loss 2.4333
10/19/2022 01:25:46 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:25:46 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:25:46 - INFO - __main__ -     Batch size = 256
10/19/2022 01:26:09 - INFO - __main__ -     eval_ppl = 15.26694
10/19/2022 01:26:09 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 01:28:50 - INFO - __main__ -     bleu-4 = 17.84 
10/19/2022 01:28:50 - INFO - __main__ -     ********************
10/19/2022 01:29:00 - INFO - __main__ -   epoch 2 step 15800 loss 2.2864
10/19/2022 01:29:16 - INFO - __main__ -   epoch 2 step 15900 loss 2.2235
10/19/2022 01:29:33 - INFO - __main__ -   epoch 2 step 16000 loss 2.1784
10/19/2022 01:29:50 - INFO - __main__ -   epoch 2 step 16100 loss 2.1951
10/19/2022 01:30:07 - INFO - __main__ -   epoch 2 step 16200 loss 2.2185
10/19/2022 01:30:23 - INFO - __main__ -   epoch 2 step 16300 loss 2.2255
10/19/2022 01:30:40 - INFO - __main__ -   epoch 2 step 16400 loss 2.2147
10/19/2022 01:30:57 - INFO - __main__ -   epoch 2 step 16500 loss 2.2126
10/19/2022 01:31:14 - INFO - __main__ -   epoch 2 step 16600 loss 2.2122
10/19/2022 01:31:30 - INFO - __main__ -   epoch 2 step 16700 loss 2.2586
10/19/2022 01:31:47 - INFO - __main__ -   epoch 2 step 16800 loss 2.2287
10/19/2022 01:32:04 - INFO - __main__ -   epoch 2 step 16900 loss 2.2058
10/19/2022 01:32:20 - INFO - __main__ -   epoch 2 step 17000 loss 2.2279
10/19/2022 01:32:37 - INFO - __main__ -   epoch 2 step 17100 loss 2.1999
10/19/2022 01:32:54 - INFO - __main__ -   epoch 2 step 17200 loss 2.2286
10/19/2022 01:33:10 - INFO - __main__ -   epoch 2 step 17300 loss 2.2105
10/19/2022 01:33:27 - INFO - __main__ -   epoch 2 step 17400 loss 2.221
10/19/2022 01:33:44 - INFO - __main__ -   epoch 2 step 17500 loss 2.2125
10/19/2022 01:34:01 - INFO - __main__ -   epoch 2 step 17600 loss 2.1832
10/19/2022 01:34:17 - INFO - __main__ -   epoch 2 step 17700 loss 2.1893
10/19/2022 01:34:34 - INFO - __main__ -   epoch 2 step 17800 loss 2.2413
10/19/2022 01:34:51 - INFO - __main__ -   epoch 2 step 17900 loss 2.2448
10/19/2022 01:35:08 - INFO - __main__ -   epoch 2 step 18000 loss 2.2471
10/19/2022 01:35:24 - INFO - __main__ -   epoch 2 step 18100 loss 2.1698
10/19/2022 01:35:41 - INFO - __main__ -   epoch 2 step 18200 loss 2.2131
10/19/2022 01:35:58 - INFO - __main__ -   epoch 2 step 18300 loss 2.2336
10/19/2022 01:36:14 - INFO - __main__ -   epoch 2 step 18400 loss 2.2205
10/19/2022 01:36:31 - INFO - __main__ -   epoch 2 step 18500 loss 2.2438
10/19/2022 01:36:48 - INFO - __main__ -   epoch 2 step 18600 loss 2.2319
10/19/2022 01:37:05 - INFO - __main__ -   epoch 2 step 18700 loss 2.2232
10/19/2022 01:37:21 - INFO - __main__ -   epoch 2 step 18800 loss 2.2437
10/19/2022 01:37:38 - INFO - __main__ -   epoch 2 step 18900 loss 2.2335
10/19/2022 01:37:55 - INFO - __main__ -   epoch 2 step 19000 loss 2.2328
10/19/2022 01:38:12 - INFO - __main__ -   epoch 2 step 19100 loss 2.2001
10/19/2022 01:38:28 - INFO - __main__ -   epoch 2 step 19200 loss 2.2317
10/19/2022 01:38:45 - INFO - __main__ -   epoch 2 step 19300 loss 2.2065
10/19/2022 01:39:02 - INFO - __main__ -   epoch 2 step 19400 loss 2.2153
10/19/2022 01:39:18 - INFO - __main__ -   epoch 2 step 19500 loss 2.2425
10/19/2022 01:39:35 - INFO - __main__ -   epoch 2 step 19600 loss 2.2437
10/19/2022 01:39:52 - INFO - __main__ -   epoch 2 step 19700 loss 2.2312
10/19/2022 01:40:09 - INFO - __main__ -   epoch 2 step 19800 loss 2.2266
10/19/2022 01:40:25 - INFO - __main__ -   epoch 2 step 19900 loss 2.2156
10/19/2022 01:40:42 - INFO - __main__ -   epoch 2 step 20000 loss 2.2306
10/19/2022 01:40:59 - INFO - __main__ -   epoch 2 step 20100 loss 2.2529
10/19/2022 01:41:16 - INFO - __main__ -   epoch 2 step 20200 loss 2.2356
10/19/2022 01:41:32 - INFO - __main__ -   epoch 2 step 20300 loss 2.2335
10/19/2022 01:41:49 - INFO - __main__ -   epoch 2 step 20400 loss 2.2266
10/19/2022 01:42:06 - INFO - __main__ -   epoch 2 step 20500 loss 2.2261
10/19/2022 01:42:23 - INFO - __main__ -   epoch 2 step 20600 loss 2.2457
10/19/2022 01:42:39 - INFO - __main__ -   epoch 2 step 20700 loss 2.2403
10/19/2022 01:42:56 - INFO - __main__ -   epoch 2 step 20800 loss 2.252
10/19/2022 01:43:13 - INFO - __main__ -   epoch 2 step 20900 loss 2.2329
10/19/2022 01:43:29 - INFO - __main__ -   epoch 2 step 21000 loss 2.2539
10/19/2022 01:43:46 - INFO - __main__ -   epoch 2 step 21100 loss 2.2065
10/19/2022 01:44:03 - INFO - __main__ -   epoch 2 step 21200 loss 2.2525
10/19/2022 01:44:19 - INFO - __main__ -   epoch 2 step 21300 loss 2.23
10/19/2022 01:44:36 - INFO - __main__ -   epoch 2 step 21400 loss 2.2198
10/19/2022 01:44:53 - INFO - __main__ -   epoch 2 step 21500 loss 2.2148
10/19/2022 01:45:10 - INFO - __main__ -   epoch 2 step 21600 loss 2.2139
10/19/2022 01:45:26 - INFO - __main__ -   epoch 2 step 21700 loss 2.2221
10/19/2022 01:45:43 - INFO - __main__ -   epoch 2 step 21800 loss 2.2613
10/19/2022 01:46:00 - INFO - __main__ -   epoch 2 step 21900 loss 2.2437
10/19/2022 01:46:16 - INFO - __main__ -   epoch 2 step 22000 loss 2.2432
10/19/2022 01:46:33 - INFO - __main__ -   epoch 2 step 22100 loss 2.2593
10/19/2022 01:46:50 - INFO - __main__ -   epoch 2 step 22200 loss 2.2326
10/19/2022 01:47:07 - INFO - __main__ -   epoch 2 step 22300 loss 2.2618
10/19/2022 01:47:23 - INFO - __main__ -   epoch 2 step 22400 loss 2.2614
10/19/2022 01:47:40 - INFO - __main__ -   epoch 2 step 22500 loss 2.2326
10/19/2022 01:47:57 - INFO - __main__ -   epoch 2 step 22600 loss 2.2803
10/19/2022 01:48:14 - INFO - __main__ -   epoch 2 step 22700 loss 2.2486
10/19/2022 01:48:30 - INFO - __main__ -   epoch 2 step 22800 loss 2.2232
10/19/2022 01:48:47 - INFO - __main__ -   epoch 2 step 22900 loss 2.2181
10/19/2022 01:49:04 - INFO - __main__ -   epoch 2 step 23000 loss 2.2373
10/19/2022 01:49:20 - INFO - __main__ -   epoch 2 step 23100 loss 2.2356
10/19/2022 01:49:37 - INFO - __main__ -   epoch 2 step 23200 loss 2.2627
10/19/2022 01:49:54 - INFO - __main__ -   epoch 2 step 23300 loss 2.2785
10/19/2022 01:50:11 - INFO - __main__ -   epoch 2 step 23400 loss 2.2372
10/19/2022 01:50:27 - INFO - __main__ -   epoch 2 step 23500 loss 2.2039
10/19/2022 01:50:44 - INFO - __main__ -   epoch 2 step 23600 loss 2.2602
10/19/2022 01:50:45 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:50:45 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:50:45 - INFO - __main__ -     Batch size = 256
10/19/2022 01:51:09 - INFO - __main__ -     eval_ppl = 15.99839
10/19/2022 01:51:09 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 01:53:51 - INFO - __main__ -     bleu-4 = 17.92 
10/19/2022 01:53:51 - INFO - __main__ -     ********************
  0%|          | 0/59 [00:00<?, ?it/s]  2%|▏         | 1/59 [00:36<35:34, 36.79s/it]  3%|▎         | 2/59 [01:13<34:41, 36.51s/it]  5%|▌         | 3/59 [01:58<37:40, 40.37s/it]  7%|▋         | 4/59 [02:47<40:18, 43.96s/it]  8%|▊         | 5/59 [03:30<39:21, 43.73s/it] 10%|█         | 6/59 [04:14<38:32, 43.64s/it] 12%|█▏        | 7/59 [04:53<36:38, 42.28s/it] 14%|█▎        | 8/59 [05:33<35:07, 41.32s/it] 15%|█▌        | 9/59 [06:18<35:23, 42.46s/it] 17%|█▋        | 10/59 [07:02<35:08, 43.04s/it] 19%|█▊        | 11/59 [07:50<35:40, 44.60s/it] 20%|██        | 12/59 [08:31<34:06, 43.55s/it] 22%|██▏       | 13/59 [09:12<32:38, 42.58s/it] 24%|██▎       | 14/59 [09:51<31:13, 41.63s/it] 25%|██▌       | 15/59 [10:37<31:27, 42.89s/it] 27%|██▋       | 16/59 [11:18<30:16, 42.25s/it] 29%|██▉       | 17/59 [12:00<29:37, 42.33s/it] 31%|███       | 18/59 [12:42<28:55, 42.33s/it] 32%|███▏      | 19/59 [13:29<29:02, 43.55s/it] 34%|███▍      | 20/59 [14:09<27:43, 42.64s/it] 36%|███▌      | 21/59 [14:49<26:28, 41.81s/it] 37%|███▋      | 22/59 [15:33<26:09, 42.42s/it] 39%|███▉      | 23/59 [16:10<24:29, 40.81s/it] 41%|████      | 24/59 [16:49<23:30, 40.29s/it] 42%|████▏     | 25/59 [17:37<24:04, 42.49s/it] 44%|████▍     | 26/59 [18:23<23:56, 43.53s/it] 46%|████▌     | 27/59 [19:00<22:14, 41.70s/it] 47%|████▋     | 28/59 [19:46<22:10, 42.92s/it] 49%|████▉     | 29/59 [20:26<21:03, 42.11s/it] 51%|█████     | 30/59 [21:09<20:26, 42.29s/it] 53%|█████▎    | 31/59 [21:54<20:08, 43.15s/it] 54%|█████▍    | 32/59 [22:32<18:46, 41.73s/it] 56%|█████▌    | 33/59 [23:13<17:52, 41.25s/it] 58%|█████▊    | 34/59 [23:51<16:54, 40.56s/it] 59%|█████▉    | 35/59 [24:33<16:18, 40.75s/it] 61%|██████    | 36/59 [25:16<15:58, 41.67s/it] 63%|██████▎   | 37/59 [25:54<14:48, 40.39s/it] 64%|██████▍   | 38/59 [26:33<14:01, 40.05s/it] 66%|██████▌   | 39/59 [27:12<13:14, 39.74s/it] 68%|██████▊   | 40/59 [27:56<12:56, 40.85s/it] 69%|██████▉   | 41/59 [28:35<12:08, 40.48s/it] 71%|███████   | 42/59 [29:15<11:23, 40.18s/it] 73%|███████▎  | 43/59 [29:58<10:57, 41.10s/it] 75%|███████▍  | 44/59 [30:37<10:06, 40.42s/it] 76%|███████▋  | 45/59 [31:19<09:32, 40.88s/it] 78%|███████▊  | 46/59 [31:57<08:40, 40.01s/it] 80%|███████▉  | 47/59 [32:36<07:56, 39.73s/it] 81%|████████▏ | 48/59 [33:12<07:05, 38.71s/it] 83%|████████▎ | 49/59 [33:54<06:35, 39.56s/it] 85%|████████▍ | 50/59 [34:35<05:59, 39.95s/it] 86%|████████▋ | 51/59 [35:14<05:17, 39.75s/it] 88%|████████▊ | 52/59 [35:53<04:36, 39.55s/it] 90%|████████▉ | 53/59 [36:36<04:02, 40.49s/it] 92%|█████████▏| 54/59 [37:18<03:25, 41.18s/it] 93%|█████████▎| 55/59 [37:58<02:42, 40.69s/it] 95%|█████████▍| 56/59 [38:35<01:59, 39.72s/it] 97%|█████████▋| 57/59 [39:13<01:18, 39.19s/it] 98%|█████████▊| 58/59 [39:54<00:39, 39.76s/it]100%|██████████| 59/59 [40:05<00:00, 31.09s/it]100%|██████████| 59/59 [40:05<00:00, 40.78s/it]
Total: 14918
10/19/2022 02:34:11 - INFO - __main__ -     bleu-4 = 19.19 
10/19/2022 02:34:11 - INFO - __main__ -     ********************
10/19/2022 02:34:12 - INFO - utils -   saved dataset in saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_0_layers/20221019003412/result.jsonl

10/19/2022 00:46:02 - INFO - __main__ -   device: cuda, n_gpu: 1
10/19/2022 00:46:03 - DEBUG - filelock -   Attempting to acquire lock 140261334844944 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:46:03 - DEBUG - filelock -   Lock 140261334844944 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   9%|▉         | 84.0k/916k [00:00<00:01, 777kB/s]Downloading:  38%|███▊      | 352k/916k [00:00<00:00, 1.77MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 3.33MB/s]
10/19/2022 00:46:04 - DEBUG - filelock -   Attempting to release lock 140261334844944 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:46:04 - DEBUG - filelock -   Lock 140261334844944 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 00:46:04 - DEBUG - filelock -   Attempting to acquire lock 140261333581632 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:46:04 - DEBUG - filelock -   Lock 140261333581632 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:   9%|▉         | 40.0k/434k [00:00<00:01, 370kB/s]Downloading:  40%|███▉      | 172k/434k [00:00<00:00, 866kB/s] Downloading: 100%|██████████| 434k/434k [00:00<00:00, 1.58MB/s]
10/19/2022 00:46:05 - DEBUG - filelock -   Attempting to release lock 140261333581632 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:46:05 - DEBUG - filelock -   Lock 140261333581632 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 00:46:05 - DEBUG - filelock -   Attempting to acquire lock 140261333581248 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:46:05 - DEBUG - filelock -   Lock 140261333581248 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 705kB/s]
10/19/2022 00:46:05 - DEBUG - filelock -   Attempting to release lock 140261333581248 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:46:05 - DEBUG - filelock -   Lock 140261333581248 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 00:46:06 - DEBUG - filelock -   Attempting to acquire lock 140261334844896 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:46:06 - DEBUG - filelock -   Lock 140261334844896 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 771kB/s]
10/19/2022 00:46:06 - DEBUG - filelock -   Attempting to release lock 140261334844896 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:46:06 - DEBUG - filelock -   Lock 140261334844896 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 00:46:07 - DEBUG - filelock -   Attempting to acquire lock 140261098423104 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:46:07 - DEBUG - filelock -   Lock 140261098423104 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 675kB/s]
10/19/2022 00:46:07 - DEBUG - filelock -   Attempting to release lock 140261098423104 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:46:07 - DEBUG - filelock -   Lock 140261098423104 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 00:46:07 - DEBUG - filelock -   Attempting to acquire lock 140261098423008 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:46:07 - DEBUG - filelock -   Lock 140261098423008 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   1%|          | 5.79M/480M [00:00<00:08, 60.8MB/s]Downloading:   3%|▎         | 13.2M/480M [00:00<00:06, 70.6MB/s]Downloading:   4%|▍         | 19.9M/480M [00:00<00:07, 68.1MB/s]Downloading:   6%|▌         | 28.1M/480M [00:00<00:06, 74.8MB/s]Downloading:   8%|▊         | 37.9M/480M [00:00<00:05, 85.0MB/s]Downloading:  10%|█         | 48.7M/480M [00:00<00:04, 94.5MB/s]Downloading:  12%|█▏        | 59.3M/480M [00:00<00:04, 100MB/s] Downloading:  15%|█▍        | 69.7M/480M [00:00<00:04, 103MB/s]Downloading:  17%|█▋        | 80.4M/480M [00:00<00:03, 106MB/s]Downloading:  19%|█▉        | 91.0M/480M [00:01<00:03, 108MB/s]Downloading:  21%|██        | 102M/480M [00:01<00:03, 109MB/s] Downloading:  23%|██▎       | 112M/480M [00:01<00:03, 109MB/s]Downloading:  26%|██▌       | 123M/480M [00:01<00:03, 110MB/s]Downloading:  28%|██▊       | 134M/480M [00:01<00:03, 111MB/s]Downloading:  30%|██▉       | 144M/480M [00:01<00:03, 111MB/s]Downloading:  32%|███▏      | 155M/480M [00:01<00:03, 112MB/s]Downloading:  35%|███▍      | 166M/480M [00:01<00:02, 113MB/s]Downloading:  37%|███▋      | 177M/480M [00:01<00:02, 113MB/s]Downloading:  39%|███▉      | 188M/480M [00:01<00:02, 112MB/s]Downloading:  41%|████▏     | 198M/480M [00:02<00:02, 111MB/s]Downloading:  43%|████▎     | 209M/480M [00:02<00:02, 111MB/s]Downloading:  46%|████▌     | 220M/480M [00:02<00:02, 111MB/s]Downloading:  48%|████▊     | 230M/480M [00:02<00:02, 111MB/s]Downloading:  50%|█████     | 241M/480M [00:02<00:02, 111MB/s]Downloading:  52%|█████▏    | 251M/480M [00:02<00:02, 111MB/s]Downloading:  55%|█████▍    | 262M/480M [00:02<00:02, 112MB/s]Downloading:  57%|█████▋    | 273M/480M [00:02<00:01, 113MB/s]Downloading:  59%|█████▉    | 284M/480M [00:02<00:01, 112MB/s]Downloading:  61%|██████▏   | 295M/480M [00:02<00:01, 112MB/s]Downloading:  64%|██████▎   | 306M/480M [00:03<00:01, 112MB/s]Downloading:  66%|██████▌   | 316M/480M [00:03<00:01, 112MB/s]Downloading:  68%|██████▊   | 327M/480M [00:03<00:01, 111MB/s]Downloading:  70%|███████   | 338M/480M [00:03<00:01, 112MB/s]Downloading:  72%|███████▏  | 348M/480M [00:03<00:01, 112MB/s]Downloading:  75%|███████▍  | 359M/480M [00:03<00:01, 112MB/s]Downloading:  77%|███████▋  | 370M/480M [00:03<00:01, 113MB/s]Downloading:  79%|███████▉  | 381M/480M [00:03<00:00, 113MB/s]Downloading:  82%|████████▏ | 392M/480M [00:03<00:00, 113MB/s]Downloading:  84%|████████▍ | 402M/480M [00:03<00:00, 113MB/s]Downloading:  86%|████████▌ | 413M/480M [00:04<00:00, 112MB/s]Downloading:  88%|████████▊ | 424M/480M [00:04<00:00, 112MB/s]Downloading:  90%|█████████ | 435M/480M [00:04<00:00, 112MB/s]Downloading:  93%|█████████▎| 445M/480M [00:04<00:00, 112MB/s]Downloading:  95%|█████████▍| 456M/480M [00:04<00:00, 112MB/s]Downloading:  97%|█████████▋| 466M/480M [00:04<00:00, 112MB/s]Downloading:  99%|█████████▉| 477M/480M [00:04<00:00, 113MB/s]Downloading: 100%|██████████| 480M/480M [00:04<00:00, 108MB/s]
10/19/2022 00:46:12 - DEBUG - filelock -   Attempting to release lock 140261098423008 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:46:12 - DEBUG - filelock -   Lock 140261098423008 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 00:46:20 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, beam_size=10, debug=False, dev_filename='dataset/python/valid.jsonl', device=device(type='cuda'), do_eval=True, do_test=True, do_train=True, eval_batch_size=256, freeze_bottom_k_layer_index=8, gradient_accumulation_steps=1, learning_rate=5e-05, max_grad_norm=1.0, max_source_length=256, max_target_length=128, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221019004555', seed=123456, test_filename='dataset/python/test.jsonl', train_batch_size=32, train_filename='dataset/python/train.jsonl', weight_decay=0.0)
10/19/2022 00:46:20 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
| dense.weight                                               |   [768, 768] |  589824 |
| dense.bias                                                 |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/19/2022 00:46:20 - INFO - __main__ -   The model has 29532672 trainable parameters
10/19/2022 00:46:31 - INFO - __main__ -   *** Example ***
10/19/2022 00:46:31 - INFO - __main__ -   idx: 0
10/19/2022 00:46:31 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_split', '_', 'phy', 'log', 'en', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_";"', '_)', '_[', '_0', '_]', '</s>']
10/19/2022 00:46:31 - INFO - __main__ -   source_ids: 0 5 2 19 729 5192 181 3258 896 386 207 400 428 2019 3144 385 437 201 120 743 545 3144 385 3144 513 12945 120 1046 385 428 746 5192 400 3144 743 483 1046 626 461 2406 513 3144 513 1046 626 524 2406 746 5192 400 29760 743 626 461 2406 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:46:31 - INFO - __main__ -   target_tokens: ['<mask0>', 'Return', '_either', '_the', '_full', '_or', '_truncated', '_version', '_of', '_a', '_Q', 'II', 'ME', '_-', '_formatted', '_taxonomy', '_string', '_.', '</s>']
10/19/2022 00:46:31 - INFO - __main__ -   target_ids: 19 1675 4759 448 3662 872 19307 2229 595 434 1152 4300 1098 581 10440 29021 724 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:46:31 - INFO - __main__ -   *** Example ***
10/19/2022 00:46:31 - INFO - __main__ -   idx: 1
10/19/2022 00:46:31 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'akedirs', '_(', '_d', '_)', '_except', '_OSError', '_as', '_oe', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'makedirs', '_#', '_ENOENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_errno', '_==', '_errno', '_.', '_ENOENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({})', '_do', '_not', '_exist', '.', '_If', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', '_({})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_oe', '_.', '_strerror', '_)', '</s>']
10/19/2022 00:46:31 - INFO - __main__ -   source_ids: 0 5 2 19 729 6229 181 1282 400 480 743 545 462 800 2215 746 1391 746 4534 400 480 743 545 1568 545 2215 746 446 23328 400 480 743 3552 22934 880 44902 545 830 1570 800 7564 918 2215 132 24429 830 41059 144 4038 5632 1012 872 3456 462 2215 746 2341 550 2341 746 41059 545 2345 385 7916 443 400 1638 3533 872 2726 11613 488 448 1391 46072 1000 800 3040 132 1359 2713 1147 15323 434 579 3456 563 1721 130 13874 6229 1345 1946 11613 488 448 1391 6418 3040 6315 743 483 2345 746 2021 400 480 743 669 545 2345 385 7916 443 400 1638 1088 843 10058 11749 508 1738 448 1721 3456 46072 918 1841 144 2334 3947 743 483 2345 746 2021 400 480 2019 44902 746 20115 743 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:46:31 - INFO - __main__ -   target_tokens: ['<mask0>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catch', 'es', '_OSError', '_exceptions', '_and', '_returns', '_a', '_desc', 'riptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/19/2022 00:46:31 - INFO - __main__ -   target_ids: 19 1749 508 2002 3984 448 8813 3456 1391 2129 800 3040 462 1769 1738 835 746 1044 1454 2092 482 22934 12300 706 2060 434 2162 44105 1841 4488 595 479 581 47183 448 843 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 00:49:41 - INFO - __main__ -   ***** Running training *****
10/19/2022 00:49:41 - INFO - __main__ -     Num examples = 251820
10/19/2022 00:49:41 - INFO - __main__ -     Batch size = 32
10/19/2022 00:49:41 - INFO - __main__ -     Num epoch = 10
10/19/2022 00:49:52 - INFO - __main__ -   epoch 0 step 100 loss 3.3201
10/19/2022 00:50:01 - INFO - __main__ -   epoch 0 step 200 loss 3.1361
10/19/2022 00:50:11 - INFO - __main__ -   epoch 0 step 300 loss 2.918
10/19/2022 00:50:21 - INFO - __main__ -   epoch 0 step 400 loss 2.7767
10/19/2022 00:50:30 - INFO - __main__ -   epoch 0 step 500 loss 2.7175
10/19/2022 00:50:40 - INFO - __main__ -   epoch 0 step 600 loss 2.7137
10/19/2022 00:50:50 - INFO - __main__ -   epoch 0 step 700 loss 2.7039
10/19/2022 00:51:00 - INFO - __main__ -   epoch 0 step 800 loss 2.6908
10/19/2022 00:51:09 - INFO - __main__ -   epoch 0 step 900 loss 2.714
10/19/2022 00:51:19 - INFO - __main__ -   epoch 0 step 1000 loss 2.6794
10/19/2022 00:51:29 - INFO - __main__ -   epoch 0 step 1100 loss 2.6561
10/19/2022 00:51:38 - INFO - __main__ -   epoch 0 step 1200 loss 2.6212
10/19/2022 00:51:48 - INFO - __main__ -   epoch 0 step 1300 loss 2.6489
10/19/2022 00:51:58 - INFO - __main__ -   epoch 0 step 1400 loss 2.6604
10/19/2022 00:52:08 - INFO - __main__ -   epoch 0 step 1500 loss 2.6669
10/19/2022 00:52:17 - INFO - __main__ -   epoch 0 step 1600 loss 2.6581
10/19/2022 00:52:27 - INFO - __main__ -   epoch 0 step 1700 loss 2.6233
10/19/2022 00:52:37 - INFO - __main__ -   epoch 0 step 1800 loss 2.607
10/19/2022 00:52:46 - INFO - __main__ -   epoch 0 step 1900 loss 2.6123
10/19/2022 00:52:56 - INFO - __main__ -   epoch 0 step 2000 loss 2.6036
10/19/2022 00:53:06 - INFO - __main__ -   epoch 0 step 2100 loss 2.6367
10/19/2022 00:53:16 - INFO - __main__ -   epoch 0 step 2200 loss 2.6027
10/19/2022 00:53:25 - INFO - __main__ -   epoch 0 step 2300 loss 2.6131
10/19/2022 00:53:35 - INFO - __main__ -   epoch 0 step 2400 loss 2.6123
10/19/2022 00:53:45 - INFO - __main__ -   epoch 0 step 2500 loss 2.5975
10/19/2022 00:53:55 - INFO - __main__ -   epoch 0 step 2600 loss 2.6308
10/19/2022 00:54:04 - INFO - __main__ -   epoch 0 step 2700 loss 2.6196
10/19/2022 00:54:14 - INFO - __main__ -   epoch 0 step 2800 loss 2.6126
10/19/2022 00:54:24 - INFO - __main__ -   epoch 0 step 2900 loss 2.6296
10/19/2022 00:54:34 - INFO - __main__ -   epoch 0 step 3000 loss 2.587
10/19/2022 00:54:43 - INFO - __main__ -   epoch 0 step 3100 loss 2.6271
10/19/2022 00:54:53 - INFO - __main__ -   epoch 0 step 3200 loss 2.5951
10/19/2022 00:55:03 - INFO - __main__ -   epoch 0 step 3300 loss 2.6079
10/19/2022 00:55:12 - INFO - __main__ -   epoch 0 step 3400 loss 2.6305
10/19/2022 00:55:22 - INFO - __main__ -   epoch 0 step 3500 loss 2.5753
10/19/2022 00:55:32 - INFO - __main__ -   epoch 0 step 3600 loss 2.5844
10/19/2022 00:55:42 - INFO - __main__ -   epoch 0 step 3700 loss 2.599
10/19/2022 00:55:51 - INFO - __main__ -   epoch 0 step 3800 loss 2.6084
10/19/2022 00:56:01 - INFO - __main__ -   epoch 0 step 3900 loss 2.5888
10/19/2022 00:56:11 - INFO - __main__ -   epoch 0 step 4000 loss 2.6015
10/19/2022 00:56:21 - INFO - __main__ -   epoch 0 step 4100 loss 2.6057
10/19/2022 00:56:30 - INFO - __main__ -   epoch 0 step 4200 loss 2.5895
10/19/2022 00:56:40 - INFO - __main__ -   epoch 0 step 4300 loss 2.6045
10/19/2022 00:56:50 - INFO - __main__ -   epoch 0 step 4400 loss 2.577
10/19/2022 00:56:59 - INFO - __main__ -   epoch 0 step 4500 loss 2.5848
10/19/2022 00:57:09 - INFO - __main__ -   epoch 0 step 4600 loss 2.6078
10/19/2022 00:57:19 - INFO - __main__ -   epoch 0 step 4700 loss 2.578
10/19/2022 00:57:29 - INFO - __main__ -   epoch 0 step 4800 loss 2.6006
10/19/2022 00:57:38 - INFO - __main__ -   epoch 0 step 4900 loss 2.5982
10/19/2022 00:57:48 - INFO - __main__ -   epoch 0 step 5000 loss 2.587
10/19/2022 00:57:58 - INFO - __main__ -   epoch 0 step 5100 loss 2.6009
10/19/2022 00:58:08 - INFO - __main__ -   epoch 0 step 5200 loss 2.5664
10/19/2022 00:58:17 - INFO - __main__ -   epoch 0 step 5300 loss 2.6266
10/19/2022 00:58:27 - INFO - __main__ -   epoch 0 step 5400 loss 2.5618
10/19/2022 00:58:37 - INFO - __main__ -   epoch 0 step 5500 loss 2.5861
10/19/2022 00:58:47 - INFO - __main__ -   epoch 0 step 5600 loss 2.5777
10/19/2022 00:58:56 - INFO - __main__ -   epoch 0 step 5700 loss 2.5921
10/19/2022 00:59:06 - INFO - __main__ -   epoch 0 step 5800 loss 2.5803
10/19/2022 00:59:16 - INFO - __main__ -   epoch 0 step 5900 loss 2.5599
10/19/2022 00:59:26 - INFO - __main__ -   epoch 0 step 6000 loss 2.5484
10/19/2022 00:59:35 - INFO - __main__ -   epoch 0 step 6100 loss 2.5924
10/19/2022 00:59:45 - INFO - __main__ -   epoch 0 step 6200 loss 2.5646
10/19/2022 00:59:55 - INFO - __main__ -   epoch 0 step 6300 loss 2.5881
10/19/2022 01:00:04 - INFO - __main__ -   epoch 0 step 6400 loss 2.5765
10/19/2022 01:00:14 - INFO - __main__ -   epoch 0 step 6500 loss 2.5991
10/19/2022 01:00:24 - INFO - __main__ -   epoch 0 step 6600 loss 2.5689
10/19/2022 01:00:34 - INFO - __main__ -   epoch 0 step 6700 loss 2.5716
10/19/2022 01:00:43 - INFO - __main__ -   epoch 0 step 6800 loss 2.6041
10/19/2022 01:00:53 - INFO - __main__ -   epoch 0 step 6900 loss 2.599
10/19/2022 01:01:03 - INFO - __main__ -   epoch 0 step 7000 loss 2.5998
10/19/2022 01:01:12 - INFO - __main__ -   epoch 0 step 7100 loss 2.538
10/19/2022 01:01:22 - INFO - __main__ -   epoch 0 step 7200 loss 2.5366
10/19/2022 01:01:32 - INFO - __main__ -   epoch 0 step 7300 loss 2.5681
10/19/2022 01:01:42 - INFO - __main__ -   epoch 0 step 7400 loss 2.5645
10/19/2022 01:01:52 - INFO - __main__ -   epoch 0 step 7500 loss 2.5667
10/19/2022 01:02:01 - INFO - __main__ -   epoch 0 step 7600 loss 2.573
10/19/2022 01:02:11 - INFO - __main__ -   epoch 0 step 7700 loss 2.5691
10/19/2022 01:02:21 - INFO - __main__ -   epoch 0 step 7800 loss 2.5875
10/19/2022 01:02:39 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:02:39 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:02:39 - INFO - __main__ -     Batch size = 256
10/19/2022 01:03:02 - INFO - __main__ -     eval_ppl = 15.19621
10/19/2022 01:03:02 - INFO - __main__ -     ********************
/sci_1/t-enshengshi/interpretability/sync_repo/bertviz/code-summarization/model.py:189: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
Total: 1000
10/19/2022 01:05:44 - INFO - __main__ -     bleu-4 = 18.2 
10/19/2022 01:05:44 - INFO - __main__ -     ********************
10/19/2022 01:05:44 - INFO - __main__ -     Best bleu:18.2
10/19/2022 01:05:44 - INFO - __main__ -     ********************
10/19/2022 01:06:02 - INFO - __main__ -   epoch 1 step 7900 loss 2.5545
10/19/2022 01:06:12 - INFO - __main__ -   epoch 1 step 8000 loss 2.4839
10/19/2022 01:06:21 - INFO - __main__ -   epoch 1 step 8100 loss 2.509
10/19/2022 01:06:31 - INFO - __main__ -   epoch 1 step 8200 loss 2.5141
10/19/2022 01:06:41 - INFO - __main__ -   epoch 1 step 8300 loss 2.4965
10/19/2022 01:06:50 - INFO - __main__ -   epoch 1 step 8400 loss 2.5061
10/19/2022 01:07:00 - INFO - __main__ -   epoch 1 step 8500 loss 2.4865
10/19/2022 01:07:10 - INFO - __main__ -   epoch 1 step 8600 loss 2.5224
10/19/2022 01:07:20 - INFO - __main__ -   epoch 1 step 8700 loss 2.5087
10/19/2022 01:07:29 - INFO - __main__ -   epoch 1 step 8800 loss 2.5169
10/19/2022 01:07:39 - INFO - __main__ -   epoch 1 step 8900 loss 2.5446
10/19/2022 01:07:49 - INFO - __main__ -   epoch 1 step 9000 loss 2.5097
10/19/2022 01:07:58 - INFO - __main__ -   epoch 1 step 9100 loss 2.5003
10/19/2022 01:08:08 - INFO - __main__ -   epoch 1 step 9200 loss 2.5183
10/19/2022 01:08:18 - INFO - __main__ -   epoch 1 step 9300 loss 2.4984
10/19/2022 01:08:28 - INFO - __main__ -   epoch 1 step 9400 loss 2.4834
10/19/2022 01:08:37 - INFO - __main__ -   epoch 1 step 9500 loss 2.4734
10/19/2022 01:08:47 - INFO - __main__ -   epoch 1 step 9600 loss 2.5153
10/19/2022 01:08:57 - INFO - __main__ -   epoch 1 step 9700 loss 2.5024
10/19/2022 01:09:07 - INFO - __main__ -   epoch 1 step 9800 loss 2.4985
10/19/2022 01:09:16 - INFO - __main__ -   epoch 1 step 9900 loss 2.5294
10/19/2022 01:09:26 - INFO - __main__ -   epoch 1 step 10000 loss 2.5001
10/19/2022 01:09:36 - INFO - __main__ -   epoch 1 step 10100 loss 2.525
10/19/2022 01:09:46 - INFO - __main__ -   epoch 1 step 10200 loss 2.4871
10/19/2022 01:09:55 - INFO - __main__ -   epoch 1 step 10300 loss 2.5311
10/19/2022 01:10:05 - INFO - __main__ -   epoch 1 step 10400 loss 2.4934
10/19/2022 01:10:15 - INFO - __main__ -   epoch 1 step 10500 loss 2.4683
10/19/2022 01:10:25 - INFO - __main__ -   epoch 1 step 10600 loss 2.5042
10/19/2022 01:10:34 - INFO - __main__ -   epoch 1 step 10700 loss 2.5628
10/19/2022 01:10:44 - INFO - __main__ -   epoch 1 step 10800 loss 2.5465
10/19/2022 01:10:54 - INFO - __main__ -   epoch 1 step 10900 loss 2.5233
10/19/2022 01:11:04 - INFO - __main__ -   epoch 1 step 11000 loss 2.4894
10/19/2022 01:11:13 - INFO - __main__ -   epoch 1 step 11100 loss 2.5294
10/19/2022 01:11:23 - INFO - __main__ -   epoch 1 step 11200 loss 2.5156
10/19/2022 01:11:33 - INFO - __main__ -   epoch 1 step 11300 loss 2.5143
10/19/2022 01:11:43 - INFO - __main__ -   epoch 1 step 11400 loss 2.4804
10/19/2022 01:11:53 - INFO - __main__ -   epoch 1 step 11500 loss 2.4843
10/19/2022 01:12:02 - INFO - __main__ -   epoch 1 step 11600 loss 2.5229
10/19/2022 01:12:12 - INFO - __main__ -   epoch 1 step 11700 loss 2.4986
10/19/2022 01:12:22 - INFO - __main__ -   epoch 1 step 11800 loss 2.5058
10/19/2022 01:12:31 - INFO - __main__ -   epoch 1 step 11900 loss 2.4834
10/19/2022 01:12:41 - INFO - __main__ -   epoch 1 step 12000 loss 2.4974
10/19/2022 01:12:51 - INFO - __main__ -   epoch 1 step 12100 loss 2.4852
10/19/2022 01:13:01 - INFO - __main__ -   epoch 1 step 12200 loss 2.47
10/19/2022 01:13:11 - INFO - __main__ -   epoch 1 step 12300 loss 2.4924
10/19/2022 01:13:20 - INFO - __main__ -   epoch 1 step 12400 loss 2.5217
10/19/2022 01:13:30 - INFO - __main__ -   epoch 1 step 12500 loss 2.4814
10/19/2022 01:13:40 - INFO - __main__ -   epoch 1 step 12600 loss 2.4968
10/19/2022 01:13:50 - INFO - __main__ -   epoch 1 step 12700 loss 2.474
10/19/2022 01:13:59 - INFO - __main__ -   epoch 1 step 12800 loss 2.4643
10/19/2022 01:14:09 - INFO - __main__ -   epoch 1 step 12900 loss 2.4778
10/19/2022 01:14:19 - INFO - __main__ -   epoch 1 step 13000 loss 2.4875
10/19/2022 01:14:29 - INFO - __main__ -   epoch 1 step 13100 loss 2.4892
10/19/2022 01:14:38 - INFO - __main__ -   epoch 1 step 13200 loss 2.5134
10/19/2022 01:14:48 - INFO - __main__ -   epoch 1 step 13300 loss 2.4882
10/19/2022 01:14:58 - INFO - __main__ -   epoch 1 step 13400 loss 2.5064
10/19/2022 01:15:08 - INFO - __main__ -   epoch 1 step 13500 loss 2.4828
10/19/2022 01:15:17 - INFO - __main__ -   epoch 1 step 13600 loss 2.4785
10/19/2022 01:15:27 - INFO - __main__ -   epoch 1 step 13700 loss 2.5048
10/19/2022 01:15:37 - INFO - __main__ -   epoch 1 step 13800 loss 2.4866
10/19/2022 01:15:47 - INFO - __main__ -   epoch 1 step 13900 loss 2.4751
10/19/2022 01:15:56 - INFO - __main__ -   epoch 1 step 14000 loss 2.5002
10/19/2022 01:16:06 - INFO - __main__ -   epoch 1 step 14100 loss 2.4795
10/19/2022 01:16:16 - INFO - __main__ -   epoch 1 step 14200 loss 2.471
10/19/2022 01:16:26 - INFO - __main__ -   epoch 1 step 14300 loss 2.4784
10/19/2022 01:16:35 - INFO - __main__ -   epoch 1 step 14400 loss 2.4542
10/19/2022 01:16:45 - INFO - __main__ -   epoch 1 step 14500 loss 2.4744
10/19/2022 01:16:55 - INFO - __main__ -   epoch 1 step 14600 loss 2.4989
10/19/2022 01:17:05 - INFO - __main__ -   epoch 1 step 14700 loss 2.4391
10/19/2022 01:17:14 - INFO - __main__ -   epoch 1 step 14800 loss 2.4843
10/19/2022 01:17:24 - INFO - __main__ -   epoch 1 step 14900 loss 2.5109
10/19/2022 01:17:34 - INFO - __main__ -   epoch 1 step 15000 loss 2.4538
10/19/2022 01:17:44 - INFO - __main__ -   epoch 1 step 15100 loss 2.4666
10/19/2022 01:17:53 - INFO - __main__ -   epoch 1 step 15200 loss 2.4748
10/19/2022 01:18:03 - INFO - __main__ -   epoch 1 step 15300 loss 2.5103
10/19/2022 01:18:13 - INFO - __main__ -   epoch 1 step 15400 loss 2.4958
10/19/2022 01:18:23 - INFO - __main__ -   epoch 1 step 15500 loss 2.4698
10/19/2022 01:18:32 - INFO - __main__ -   epoch 1 step 15600 loss 2.4912
10/19/2022 01:18:42 - INFO - __main__ -   epoch 1 step 15700 loss 2.4835
10/19/2022 01:18:46 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:18:46 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:18:46 - INFO - __main__ -     Batch size = 256
10/19/2022 01:19:09 - INFO - __main__ -     eval_ppl = 15.10961
10/19/2022 01:19:09 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 01:21:37 - INFO - __main__ -     bleu-4 = 18.15 
10/19/2022 01:21:37 - INFO - __main__ -     ********************
10/19/2022 01:21:43 - INFO - __main__ -   epoch 2 step 15800 loss 2.3937
10/19/2022 01:21:53 - INFO - __main__ -   epoch 2 step 15900 loss 2.374
10/19/2022 01:22:03 - INFO - __main__ -   epoch 2 step 16000 loss 2.3314
10/19/2022 01:22:12 - INFO - __main__ -   epoch 2 step 16100 loss 2.3441
10/19/2022 01:22:22 - INFO - __main__ -   epoch 2 step 16200 loss 2.3624
10/19/2022 01:22:32 - INFO - __main__ -   epoch 2 step 16300 loss 2.371
10/19/2022 01:22:42 - INFO - __main__ -   epoch 2 step 16400 loss 2.3528
10/19/2022 01:22:51 - INFO - __main__ -   epoch 2 step 16500 loss 2.3537
10/19/2022 01:23:01 - INFO - __main__ -   epoch 2 step 16600 loss 2.3535
10/19/2022 01:23:11 - INFO - __main__ -   epoch 2 step 16700 loss 2.4005
10/19/2022 01:23:21 - INFO - __main__ -   epoch 2 step 16800 loss 2.3561
10/19/2022 01:23:30 - INFO - __main__ -   epoch 2 step 16900 loss 2.3381
10/19/2022 01:23:40 - INFO - __main__ -   epoch 2 step 17000 loss 2.3632
10/19/2022 01:23:50 - INFO - __main__ -   epoch 2 step 17100 loss 2.3367
10/19/2022 01:23:59 - INFO - __main__ -   epoch 2 step 17200 loss 2.3713
10/19/2022 01:24:09 - INFO - __main__ -   epoch 2 step 17300 loss 2.3495
10/19/2022 01:24:19 - INFO - __main__ -   epoch 2 step 17400 loss 2.3664
10/19/2022 01:24:29 - INFO - __main__ -   epoch 2 step 17500 loss 2.3564
10/19/2022 01:24:39 - INFO - __main__ -   epoch 2 step 17600 loss 2.3268
10/19/2022 01:24:48 - INFO - __main__ -   epoch 2 step 17700 loss 2.3326
10/19/2022 01:24:58 - INFO - __main__ -   epoch 2 step 17800 loss 2.3827
10/19/2022 01:25:08 - INFO - __main__ -   epoch 2 step 17900 loss 2.3888
10/19/2022 01:25:18 - INFO - __main__ -   epoch 2 step 18000 loss 2.384
10/19/2022 01:25:27 - INFO - __main__ -   epoch 2 step 18100 loss 2.3058
10/19/2022 01:25:37 - INFO - __main__ -   epoch 2 step 18200 loss 2.3549
10/19/2022 01:25:47 - INFO - __main__ -   epoch 2 step 18300 loss 2.3732
10/19/2022 01:25:56 - INFO - __main__ -   epoch 2 step 18400 loss 2.3613
10/19/2022 01:26:06 - INFO - __main__ -   epoch 2 step 18500 loss 2.381
10/19/2022 01:26:16 - INFO - __main__ -   epoch 2 step 18600 loss 2.3666
10/19/2022 01:26:26 - INFO - __main__ -   epoch 2 step 18700 loss 2.3612
10/19/2022 01:26:35 - INFO - __main__ -   epoch 2 step 18800 loss 2.383
10/19/2022 01:26:45 - INFO - __main__ -   epoch 2 step 18900 loss 2.3756
10/19/2022 01:26:55 - INFO - __main__ -   epoch 2 step 19000 loss 2.3719
10/19/2022 01:27:05 - INFO - __main__ -   epoch 2 step 19100 loss 2.3345
10/19/2022 01:27:14 - INFO - __main__ -   epoch 2 step 19200 loss 2.3663
10/19/2022 01:27:24 - INFO - __main__ -   epoch 2 step 19300 loss 2.3446
10/19/2022 01:27:34 - INFO - __main__ -   epoch 2 step 19400 loss 2.351
10/19/2022 01:27:44 - INFO - __main__ -   epoch 2 step 19500 loss 2.3796
10/19/2022 01:27:53 - INFO - __main__ -   epoch 2 step 19600 loss 2.3753
10/19/2022 01:28:03 - INFO - __main__ -   epoch 2 step 19700 loss 2.373
10/19/2022 01:28:13 - INFO - __main__ -   epoch 2 step 19800 loss 2.3592
10/19/2022 01:28:23 - INFO - __main__ -   epoch 2 step 19900 loss 2.3468
10/19/2022 01:28:32 - INFO - __main__ -   epoch 2 step 20000 loss 2.3641
10/19/2022 01:28:42 - INFO - __main__ -   epoch 2 step 20100 loss 2.3843
10/19/2022 01:28:52 - INFO - __main__ -   epoch 2 step 20200 loss 2.3682
10/19/2022 01:29:02 - INFO - __main__ -   epoch 2 step 20300 loss 2.3681
10/19/2022 01:29:11 - INFO - __main__ -   epoch 2 step 20400 loss 2.3648
10/19/2022 01:29:21 - INFO - __main__ -   epoch 2 step 20500 loss 2.3669
10/19/2022 01:29:31 - INFO - __main__ -   epoch 2 step 20600 loss 2.3801
10/19/2022 01:29:41 - INFO - __main__ -   epoch 2 step 20700 loss 2.3813
10/19/2022 01:29:50 - INFO - __main__ -   epoch 2 step 20800 loss 2.385
10/19/2022 01:30:00 - INFO - __main__ -   epoch 2 step 20900 loss 2.3588
10/19/2022 01:30:10 - INFO - __main__ -   epoch 2 step 21000 loss 2.3879
10/19/2022 01:30:20 - INFO - __main__ -   epoch 2 step 21100 loss 2.3463
10/19/2022 01:30:29 - INFO - __main__ -   epoch 2 step 21200 loss 2.3866
10/19/2022 01:30:39 - INFO - __main__ -   epoch 2 step 21300 loss 2.3569
10/19/2022 01:30:49 - INFO - __main__ -   epoch 2 step 21400 loss 2.3515
10/19/2022 01:30:59 - INFO - __main__ -   epoch 2 step 21500 loss 2.3549
10/19/2022 01:31:08 - INFO - __main__ -   epoch 2 step 21600 loss 2.3467
10/19/2022 01:31:18 - INFO - __main__ -   epoch 2 step 21700 loss 2.3553
10/19/2022 01:31:28 - INFO - __main__ -   epoch 2 step 21800 loss 2.3882
10/19/2022 01:31:38 - INFO - __main__ -   epoch 2 step 21900 loss 2.3684
10/19/2022 01:31:48 - INFO - __main__ -   epoch 2 step 22000 loss 2.3712
10/19/2022 01:31:57 - INFO - __main__ -   epoch 2 step 22100 loss 2.3841
10/19/2022 01:32:07 - INFO - __main__ -   epoch 2 step 22200 loss 2.3656
10/19/2022 01:32:17 - INFO - __main__ -   epoch 2 step 22300 loss 2.3949
10/19/2022 01:32:27 - INFO - __main__ -   epoch 2 step 22400 loss 2.3868
10/19/2022 01:32:36 - INFO - __main__ -   epoch 2 step 22500 loss 2.366
10/19/2022 01:32:46 - INFO - __main__ -   epoch 2 step 22600 loss 2.4116
10/19/2022 01:32:56 - INFO - __main__ -   epoch 2 step 22700 loss 2.376
10/19/2022 01:33:06 - INFO - __main__ -   epoch 2 step 22800 loss 2.3498
10/19/2022 01:33:15 - INFO - __main__ -   epoch 2 step 22900 loss 2.3499
10/19/2022 01:33:25 - INFO - __main__ -   epoch 2 step 23000 loss 2.3618
10/19/2022 01:33:35 - INFO - __main__ -   epoch 2 step 23100 loss 2.3686
10/19/2022 01:33:45 - INFO - __main__ -   epoch 2 step 23200 loss 2.3947
10/19/2022 01:33:54 - INFO - __main__ -   epoch 2 step 23300 loss 2.4068
10/19/2022 01:34:04 - INFO - __main__ -   epoch 2 step 23400 loss 2.3621
10/19/2022 01:34:14 - INFO - __main__ -   epoch 2 step 23500 loss 2.3365
10/19/2022 01:34:24 - INFO - __main__ -   epoch 2 step 23600 loss 2.3903
10/19/2022 01:34:24 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:34:24 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:34:24 - INFO - __main__ -     Batch size = 256
10/19/2022 01:34:48 - INFO - __main__ -     eval_ppl = 15.3351
10/19/2022 01:34:48 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 01:37:17 - INFO - __main__ -     bleu-4 = 18.28 
10/19/2022 01:37:17 - INFO - __main__ -     ********************
10/19/2022 01:37:17 - INFO - __main__ -     Best bleu:18.28
10/19/2022 01:37:17 - INFO - __main__ -     ********************
10/19/2022 01:37:36 - INFO - __main__ -   epoch 3 step 23700 loss 2.2805
10/19/2022 01:37:45 - INFO - __main__ -   epoch 3 step 23800 loss 2.2346
10/19/2022 01:37:55 - INFO - __main__ -   epoch 3 step 23900 loss 2.2151
10/19/2022 01:38:05 - INFO - __main__ -   epoch 3 step 24000 loss 2.2083
10/19/2022 01:38:14 - INFO - __main__ -   epoch 3 step 24100 loss 2.2331
10/19/2022 01:38:24 - INFO - __main__ -   epoch 3 step 24200 loss 2.226
10/19/2022 01:38:34 - INFO - __main__ -   epoch 3 step 24300 loss 2.2571
10/19/2022 01:38:44 - INFO - __main__ -   epoch 3 step 24400 loss 2.2504
10/19/2022 01:38:53 - INFO - __main__ -   epoch 3 step 24500 loss 2.2581
10/19/2022 01:39:03 - INFO - __main__ -   epoch 3 step 24600 loss 2.2209
10/19/2022 01:39:13 - INFO - __main__ -   epoch 3 step 24700 loss 2.2033
10/19/2022 01:39:22 - INFO - __main__ -   epoch 3 step 24800 loss 2.2395
10/19/2022 01:39:32 - INFO - __main__ -   epoch 3 step 24900 loss 2.2151
10/19/2022 01:39:42 - INFO - __main__ -   epoch 3 step 25000 loss 2.2539
10/19/2022 01:39:52 - INFO - __main__ -   epoch 3 step 25100 loss 2.2646
10/19/2022 01:40:01 - INFO - __main__ -   epoch 3 step 25200 loss 2.2213
10/19/2022 01:40:11 - INFO - __main__ -   epoch 3 step 25300 loss 2.2594
10/19/2022 01:40:21 - INFO - __main__ -   epoch 3 step 25400 loss 2.2665
10/19/2022 01:40:31 - INFO - __main__ -   epoch 3 step 25500 loss 2.2444
10/19/2022 01:40:40 - INFO - __main__ -   epoch 3 step 25600 loss 2.2258
10/19/2022 01:40:50 - INFO - __main__ -   epoch 3 step 25700 loss 2.2467
10/19/2022 01:41:00 - INFO - __main__ -   epoch 3 step 25800 loss 2.2288
10/19/2022 01:41:10 - INFO - __main__ -   epoch 3 step 25900 loss 2.2364
10/19/2022 01:41:19 - INFO - __main__ -   epoch 3 step 26000 loss 2.2616
10/19/2022 01:41:29 - INFO - __main__ -   epoch 3 step 26100 loss 2.2661
10/19/2022 01:41:39 - INFO - __main__ -   epoch 3 step 26200 loss 2.2664
10/19/2022 01:41:49 - INFO - __main__ -   epoch 3 step 26300 loss 2.2576
10/19/2022 01:41:58 - INFO - __main__ -   epoch 3 step 26400 loss 2.2366
10/19/2022 01:42:08 - INFO - __main__ -   epoch 3 step 26500 loss 2.2499
10/19/2022 01:42:18 - INFO - __main__ -   epoch 3 step 26600 loss 2.247
10/19/2022 01:42:28 - INFO - __main__ -   epoch 3 step 26700 loss 2.2651
10/19/2022 01:42:37 - INFO - __main__ -   epoch 3 step 26800 loss 2.2589
10/19/2022 01:42:47 - INFO - __main__ -   epoch 3 step 26900 loss 2.2559
10/19/2022 01:42:57 - INFO - __main__ -   epoch 3 step 27000 loss 2.2568
10/19/2022 01:43:07 - INFO - __main__ -   epoch 3 step 27100 loss 2.2767
10/19/2022 01:43:16 - INFO - __main__ -   epoch 3 step 27200 loss 2.2873
10/19/2022 01:43:26 - INFO - __main__ -   epoch 3 step 27300 loss 2.2763
10/19/2022 01:43:36 - INFO - __main__ -   epoch 3 step 27400 loss 2.2642
10/19/2022 01:43:46 - INFO - __main__ -   epoch 3 step 27500 loss 2.2685
10/19/2022 01:43:55 - INFO - __main__ -   epoch 3 step 27600 loss 2.2772
10/19/2022 01:44:05 - INFO - __main__ -   epoch 3 step 27700 loss 2.2542
10/19/2022 01:44:15 - INFO - __main__ -   epoch 3 step 27800 loss 2.277
10/19/2022 01:44:25 - INFO - __main__ -   epoch 3 step 27900 loss 2.2501
10/19/2022 01:44:34 - INFO - __main__ -   epoch 3 step 28000 loss 2.2462
10/19/2022 01:44:44 - INFO - __main__ -   epoch 3 step 28100 loss 2.2449
10/19/2022 01:44:54 - INFO - __main__ -   epoch 3 step 28200 loss 2.2438
10/19/2022 01:45:04 - INFO - __main__ -   epoch 3 step 28300 loss 2.286
10/19/2022 01:45:13 - INFO - __main__ -   epoch 3 step 28400 loss 2.2985
10/19/2022 01:45:23 - INFO - __main__ -   epoch 3 step 28500 loss 2.2711
10/19/2022 01:45:33 - INFO - __main__ -   epoch 3 step 28600 loss 2.2794
10/19/2022 01:45:43 - INFO - __main__ -   epoch 3 step 28700 loss 2.2885
10/19/2022 01:45:52 - INFO - __main__ -   epoch 3 step 28800 loss 2.2828
10/19/2022 01:46:02 - INFO - __main__ -   epoch 3 step 28900 loss 2.2212
10/19/2022 01:46:12 - INFO - __main__ -   epoch 3 step 29000 loss 2.3022
10/19/2022 01:46:22 - INFO - __main__ -   epoch 3 step 29100 loss 2.26
10/19/2022 01:46:31 - INFO - __main__ -   epoch 3 step 29200 loss 2.2677
10/19/2022 01:46:41 - INFO - __main__ -   epoch 3 step 29300 loss 2.2643
10/19/2022 01:46:51 - INFO - __main__ -   epoch 3 step 29400 loss 2.2764
10/19/2022 01:47:01 - INFO - __main__ -   epoch 3 step 29500 loss 2.2685
10/19/2022 01:47:10 - INFO - __main__ -   epoch 3 step 29600 loss 2.2912
10/19/2022 01:47:20 - INFO - __main__ -   epoch 3 step 29700 loss 2.2556
10/19/2022 01:47:30 - INFO - __main__ -   epoch 3 step 29800 loss 2.2604
10/19/2022 01:47:40 - INFO - __main__ -   epoch 3 step 29900 loss 2.2678
10/19/2022 01:47:49 - INFO - __main__ -   epoch 3 step 30000 loss 2.2297
10/19/2022 01:47:59 - INFO - __main__ -   epoch 3 step 30100 loss 2.2727
10/19/2022 01:48:09 - INFO - __main__ -   epoch 3 step 30200 loss 2.2778
10/19/2022 01:48:19 - INFO - __main__ -   epoch 3 step 30300 loss 2.2658
10/19/2022 01:48:29 - INFO - __main__ -   epoch 3 step 30400 loss 2.2837
10/19/2022 01:48:38 - INFO - __main__ -   epoch 3 step 30500 loss 2.2846
10/19/2022 01:48:48 - INFO - __main__ -   epoch 3 step 30600 loss 2.2352
10/19/2022 01:48:58 - INFO - __main__ -   epoch 3 step 30700 loss 2.2414
10/19/2022 01:49:07 - INFO - __main__ -   epoch 3 step 30800 loss 2.2744
10/19/2022 01:49:17 - INFO - __main__ -   epoch 3 step 30900 loss 2.2769
10/19/2022 01:49:27 - INFO - __main__ -   epoch 3 step 31000 loss 2.2689
10/19/2022 01:49:37 - INFO - __main__ -   epoch 3 step 31100 loss 2.2658
10/19/2022 01:49:46 - INFO - __main__ -   epoch 3 step 31200 loss 2.3118
10/19/2022 01:49:56 - INFO - __main__ -   epoch 3 step 31300 loss 2.2379
10/19/2022 01:50:06 - INFO - __main__ -   epoch 3 step 31400 loss 2.2454
10/19/2022 01:50:14 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 01:50:14 - INFO - __main__ -     Num examples = 13914
10/19/2022 01:50:14 - INFO - __main__ -     Batch size = 256
10/19/2022 01:50:37 - INFO - __main__ -     eval_ppl = 15.78483
10/19/2022 01:50:37 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 01:53:11 - INFO - __main__ -     bleu-4 = 17.94 
10/19/2022 01:53:11 - INFO - __main__ -     ********************
10/19/2022 01:53:13 - INFO - __main__ -   epoch 4 step 31500 loss 2.2449
10/19/2022 01:53:23 - INFO - __main__ -   epoch 4 step 31600 loss 2.1777
10/19/2022 01:53:33 - INFO - __main__ -   epoch 4 step 31700 loss 2.1477
10/19/2022 01:53:43 - INFO - __main__ -   epoch 4 step 31800 loss 2.1125
10/19/2022 01:53:52 - INFO - __main__ -   epoch 4 step 31900 loss 2.1403
10/19/2022 01:54:02 - INFO - __main__ -   epoch 4 step 32000 loss 2.1552
10/19/2022 01:54:12 - INFO - __main__ -   epoch 4 step 32100 loss 2.1615
10/19/2022 01:54:22 - INFO - __main__ -   epoch 4 step 32200 loss 2.1669
10/19/2022 01:54:31 - INFO - __main__ -   epoch 4 step 32300 loss 2.1509
10/19/2022 01:54:41 - INFO - __main__ -   epoch 4 step 32400 loss 2.1211
10/19/2022 01:54:51 - INFO - __main__ -   epoch 4 step 32500 loss 2.1734
10/19/2022 01:55:00 - INFO - __main__ -   epoch 4 step 32600 loss 2.1596
10/19/2022 01:55:10 - INFO - __main__ -   epoch 4 step 32700 loss 2.1647
10/19/2022 01:55:20 - INFO - __main__ -   epoch 4 step 32800 loss 2.1413
10/19/2022 01:55:30 - INFO - __main__ -   epoch 4 step 32900 loss 2.149
10/19/2022 01:55:39 - INFO - __main__ -   epoch 4 step 33000 loss 2.1834
10/19/2022 01:55:49 - INFO - __main__ -   epoch 4 step 33100 loss 2.1338
10/19/2022 01:55:59 - INFO - __main__ -   epoch 4 step 33200 loss 2.1469
10/19/2022 01:56:09 - INFO - __main__ -   epoch 4 step 33300 loss 2.1647
10/19/2022 01:56:18 - INFO - __main__ -   epoch 4 step 33400 loss 2.149
10/19/2022 01:56:28 - INFO - __main__ -   epoch 4 step 33500 loss 2.1525
10/19/2022 01:56:38 - INFO - __main__ -   epoch 4 step 33600 loss 2.1697
10/19/2022 01:56:48 - INFO - __main__ -   epoch 4 step 33700 loss 2.1344
10/19/2022 01:56:57 - INFO - __main__ -   epoch 4 step 33800 loss 2.1647
10/19/2022 01:57:07 - INFO - __main__ -   epoch 4 step 33900 loss 2.1637
10/19/2022 01:57:17 - INFO - __main__ -   epoch 4 step 34000 loss 2.2049
10/19/2022 01:57:27 - INFO - __main__ -   epoch 4 step 34100 loss 2.1365
10/19/2022 01:57:36 - INFO - __main__ -   epoch 4 step 34200 loss 2.1528
10/19/2022 01:57:46 - INFO - __main__ -   epoch 4 step 34300 loss 2.1739
10/19/2022 01:57:56 - INFO - __main__ -   epoch 4 step 34400 loss 2.1395
10/19/2022 01:58:06 - INFO - __main__ -   epoch 4 step 34500 loss 2.151
10/19/2022 01:58:15 - INFO - __main__ -   epoch 4 step 34600 loss 2.1386
10/19/2022 01:58:25 - INFO - __main__ -   epoch 4 step 34700 loss 2.1893
10/19/2022 01:58:35 - INFO - __main__ -   epoch 4 step 34800 loss 2.1413
10/19/2022 01:58:45 - INFO - __main__ -   epoch 4 step 34900 loss 2.1825
10/19/2022 01:58:54 - INFO - __main__ -   epoch 4 step 35000 loss 2.1812
10/19/2022 01:59:04 - INFO - __main__ -   epoch 4 step 35100 loss 2.1552
10/19/2022 01:59:14 - INFO - __main__ -   epoch 4 step 35200 loss 2.1708
10/19/2022 01:59:24 - INFO - __main__ -   epoch 4 step 35300 loss 2.1667
10/19/2022 01:59:33 - INFO - __main__ -   epoch 4 step 35400 loss 2.1883
10/19/2022 01:59:43 - INFO - __main__ -   epoch 4 step 35500 loss 2.1416
10/19/2022 01:59:53 - INFO - __main__ -   epoch 4 step 35600 loss 2.1774
10/19/2022 02:00:03 - INFO - __main__ -   epoch 4 step 35700 loss 2.1667
10/19/2022 02:00:12 - INFO - __main__ -   epoch 4 step 35800 loss 2.1797
10/19/2022 02:00:22 - INFO - __main__ -   epoch 4 step 35900 loss 2.1768
10/19/2022 02:00:32 - INFO - __main__ -   epoch 4 step 36000 loss 2.1851
10/19/2022 02:00:42 - INFO - __main__ -   epoch 4 step 36100 loss 2.1694
10/19/2022 02:00:51 - INFO - __main__ -   epoch 4 step 36200 loss 2.1953
10/19/2022 02:01:01 - INFO - __main__ -   epoch 4 step 36300 loss 2.1471
10/19/2022 02:01:11 - INFO - __main__ -   epoch 4 step 36400 loss 2.1593
10/19/2022 02:01:21 - INFO - __main__ -   epoch 4 step 36500 loss 2.1744
10/19/2022 02:01:30 - INFO - __main__ -   epoch 4 step 36600 loss 2.1525
10/19/2022 02:01:40 - INFO - __main__ -   epoch 4 step 36700 loss 2.1931
10/19/2022 02:01:50 - INFO - __main__ -   epoch 4 step 36800 loss 2.1775
10/19/2022 02:02:00 - INFO - __main__ -   epoch 4 step 36900 loss 2.1611
10/19/2022 02:02:09 - INFO - __main__ -   epoch 4 step 37000 loss 2.193
10/19/2022 02:02:19 - INFO - __main__ -   epoch 4 step 37100 loss 2.1981
10/19/2022 02:02:29 - INFO - __main__ -   epoch 4 step 37200 loss 2.1616
10/19/2022 02:02:39 - INFO - __main__ -   epoch 4 step 37300 loss 2.1518
10/19/2022 02:02:48 - INFO - __main__ -   epoch 4 step 37400 loss 2.1428
10/19/2022 02:02:58 - INFO - __main__ -   epoch 4 step 37500 loss 2.1743
10/19/2022 02:03:08 - INFO - __main__ -   epoch 4 step 37600 loss 2.1511
10/19/2022 02:03:18 - INFO - __main__ -   epoch 4 step 37700 loss 2.1686
10/19/2022 02:03:27 - INFO - __main__ -   epoch 4 step 37800 loss 2.1602
10/19/2022 02:03:37 - INFO - __main__ -   epoch 4 step 37900 loss 2.1779
10/19/2022 02:03:47 - INFO - __main__ -   epoch 4 step 38000 loss 2.1994
10/19/2022 02:03:57 - INFO - __main__ -   epoch 4 step 38100 loss 2.2101
10/19/2022 02:04:06 - INFO - __main__ -   epoch 4 step 38200 loss 2.1438
10/19/2022 02:04:16 - INFO - __main__ -   epoch 4 step 38300 loss 2.168
10/19/2022 02:04:26 - INFO - __main__ -   epoch 4 step 38400 loss 2.1806
10/19/2022 02:04:36 - INFO - __main__ -   epoch 4 step 38500 loss 2.1455
10/19/2022 02:04:45 - INFO - __main__ -   epoch 4 step 38600 loss 2.1645
10/19/2022 02:04:55 - INFO - __main__ -   epoch 4 step 38700 loss 2.167
10/19/2022 02:05:05 - INFO - __main__ -   epoch 4 step 38800 loss 2.1812
10/19/2022 02:05:14 - INFO - __main__ -   epoch 4 step 38900 loss 2.1677
10/19/2022 02:05:24 - INFO - __main__ -   epoch 4 step 39000 loss 2.1846
10/19/2022 02:05:34 - INFO - __main__ -   epoch 4 step 39100 loss 2.189
10/19/2022 02:05:44 - INFO - __main__ -   epoch 4 step 39200 loss 2.1929
10/19/2022 02:05:53 - INFO - __main__ -   epoch 4 step 39300 loss 2.1646
10/19/2022 02:05:58 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 02:05:58 - INFO - __main__ -     Num examples = 13914
10/19/2022 02:05:58 - INFO - __main__ -     Batch size = 256
10/19/2022 02:06:22 - INFO - __main__ -     eval_ppl = 16.36535
10/19/2022 02:06:22 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 02:08:55 - INFO - __main__ -     bleu-4 = 18.2 
10/19/2022 02:08:55 - INFO - __main__ -     ********************
  0%|          | 0/59 [00:00<?, ?it/s]  2%|▏         | 1/59 [00:35<34:01, 35.20s/it]  3%|▎         | 2/59 [01:09<33:11, 34.94s/it]  5%|▌         | 3/59 [01:48<34:16, 36.72s/it]  7%|▋         | 4/59 [02:31<35:46, 39.03s/it]  8%|▊         | 5/59 [03:10<35:01, 38.92s/it] 10%|█         | 6/59 [03:50<34:43, 39.31s/it] 12%|█▏        | 7/59 [04:26<33:15, 38.38s/it] 14%|█▎        | 8/59 [05:04<32:21, 38.07s/it] 15%|█▌        | 9/59 [05:46<32:56, 39.53s/it] 17%|█▋        | 10/59 [06:25<32:08, 39.36s/it] 19%|█▊        | 11/59 [07:06<31:46, 39.71s/it] 20%|██        | 12/59 [07:43<30:37, 39.10s/it] 22%|██▏       | 13/59 [08:19<29:11, 38.07s/it] 24%|██▎       | 14/59 [08:55<27:58, 37.30s/it] 25%|██▌       | 15/59 [09:36<28:11, 38.44s/it] 27%|██▋       | 16/59 [10:13<27:19, 38.13s/it] 29%|██▉       | 17/59 [10:51<26:39, 38.09s/it] 31%|███       | 18/59 [11:30<26:07, 38.24s/it] 32%|███▏      | 19/59 [12:09<25:37, 38.43s/it] 34%|███▍      | 20/59 [12:50<25:28, 39.19s/it] 36%|███▌      | 21/59 [13:27<24:33, 38.77s/it] 37%|███▋      | 22/59 [14:06<23:55, 38.80s/it] 39%|███▉      | 23/59 [14:41<22:37, 37.72s/it] 41%|████      | 24/59 [15:18<21:46, 37.32s/it] 42%|████▏     | 25/59 [16:05<22:45, 40.17s/it] 44%|████▍     | 26/59 [16:45<22:03, 40.10s/it] 46%|████▌     | 27/59 [17:19<20:25, 38.31s/it] 47%|████▋     | 28/59 [17:58<19:54, 38.52s/it] 49%|████▉     | 29/59 [18:36<19:09, 38.33s/it] 51%|█████     | 30/59 [19:13<18:26, 38.15s/it] 53%|█████▎    | 31/59 [19:54<18:07, 38.84s/it] 54%|█████▍    | 32/59 [20:32<17:19, 38.52s/it] 56%|█████▌    | 33/59 [21:08<16:27, 37.97s/it] 58%|█████▊    | 34/59 [21:46<15:45, 37.82s/it] 59%|█████▉    | 35/59 [22:23<15:04, 37.69s/it] 61%|██████    | 36/59 [23:02<14:37, 38.13s/it] 63%|██████▎   | 37/59 [23:38<13:43, 37.42s/it] 64%|██████▍   | 38/59 [24:14<12:59, 37.12s/it] 66%|██████▌   | 39/59 [24:51<12:18, 36.92s/it] 68%|██████▊   | 40/59 [25:29<11:50, 37.38s/it] 69%|██████▉   | 41/59 [26:07<11:11, 37.31s/it] 71%|███████   | 42/59 [26:44<10:33, 37.29s/it] 73%|███████▎  | 43/59 [27:22<10:00, 37.50s/it] 75%|███████▍  | 44/59 [27:58<09:14, 36.99s/it] 76%|███████▋  | 45/59 [28:37<08:46, 37.60s/it] 78%|███████▊  | 46/59 [29:12<08:01, 37.07s/it] 80%|███████▉  | 47/59 [29:48<07:19, 36.60s/it] 81%|████████▏ | 48/59 [30:22<06:33, 35.74s/it] 83%|████████▎ | 49/59 [30:59<06:01, 36.16s/it] 85%|████████▍ | 50/59 [31:36<05:28, 36.49s/it] 86%|████████▋ | 51/59 [32:12<04:51, 36.44s/it] 88%|████████▊ | 52/59 [32:49<04:14, 36.39s/it] 90%|████████▉ | 53/59 [33:30<03:47, 37.90s/it] 92%|█████████▏| 54/59 [34:06<03:06, 37.37s/it] 93%|█████████▎| 55/59 [34:43<02:28, 37.11s/it] 95%|█████████▍| 56/59 [35:18<01:49, 36.50s/it] 97%|█████████▋| 57/59 [35:53<01:12, 36.03s/it] 98%|█████████▊| 58/59 [36:30<00:36, 36.41s/it]100%|██████████| 59/59 [36:40<00:00, 28.46s/it]100%|██████████| 59/59 [36:40<00:00, 37.30s/it]
Total: 14918
10/19/2022 02:45:50 - INFO - __main__ -     bleu-4 = 19.34 
10/19/2022 02:45:50 - INFO - __main__ -     ********************
10/19/2022 02:45:50 - INFO - utils -   saved dataset in saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_8_layers/20221019004555/result.jsonl

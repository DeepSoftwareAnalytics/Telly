10/19/2022 02:10:30 - INFO - __main__ -   device: cuda, n_gpu: 1
10/19/2022 02:10:31 - DEBUG - filelock -   Attempting to acquire lock 140021085750800 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:10:31 - DEBUG - filelock -   Lock 140021085750800 acquired on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
Downloading:   0%|          | 0.00/916k [00:00<?, ?B/s]Downloading:   4%|▍         | 40.0k/916k [00:00<00:02, 375kB/s]Downloading:  19%|█▉        | 172k/916k [00:00<00:00, 869kB/s] Downloading:  82%|████████▏ | 748k/916k [00:00<00:00, 2.88MB/s]Downloading: 100%|██████████| 916k/916k [00:00<00:00, 2.79MB/s]
10/19/2022 02:10:32 - DEBUG - filelock -   Attempting to release lock 140021085750800 on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:10:32 - DEBUG - filelock -   Lock 140021085750800 released on /home/aiscuser/.cache/huggingface/transformers/6537f24197db9749ad60f891d7a50ec2de3992bee193d25b24bb244ee5ca91f9.6243fbb3cc75148b68777473341e2d0860fde2b135f39c1d7d274d8ba1763e13.lock
10/19/2022 02:10:32 - DEBUG - filelock -   Attempting to acquire lock 140021084487488 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:10:32 - DEBUG - filelock -   Lock 140021084487488 acquired on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
Downloading:   0%|          | 0.00/434k [00:00<?, ?B/s]Downloading:   8%|▊         | 36.0k/434k [00:00<00:01, 359kB/s]Downloading:  37%|███▋      | 160k/434k [00:00<00:00, 871kB/s] Downloading: 100%|██████████| 434k/434k [00:00<00:00, 1.71MB/s]
10/19/2022 02:10:32 - DEBUG - filelock -   Attempting to release lock 140021084487488 on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:10:32 - DEBUG - filelock -   Lock 140021084487488 released on /home/aiscuser/.cache/huggingface/transformers/e9a41c80e105c7ebfab8467fd5fa110db792fa435a42cf53fc84cd4dbce63203.fcaa28dbb04dd654a7ac023857de409e4815667a26706e2aa9a1bbc3ed49037a.lock
10/19/2022 02:10:33 - DEBUG - filelock -   Attempting to acquire lock 140021084487104 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:10:33 - DEBUG - filelock -   Lock 140021084487104 acquired on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]Downloading: 100%|██████████| 772/772 [00:00<00:00, 726kB/s]
10/19/2022 02:10:33 - DEBUG - filelock -   Attempting to release lock 140021084487104 on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:10:33 - DEBUG - filelock -   Lock 140021084487104 released on /home/aiscuser/.cache/huggingface/transformers/192a4a8bfa30aa3013d375ea31db6b14b0f753bf61bd99b778cb8ebaa0d6a338.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0.lock
10/19/2022 02:10:33 - DEBUG - filelock -   Attempting to acquire lock 140021085750752 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:10:33 - DEBUG - filelock -   Lock 140021085750752 acquired on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.09k/1.09k [00:00<00:00, 697kB/s]
10/19/2022 02:10:34 - DEBUG - filelock -   Attempting to release lock 140021085750752 on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:10:34 - DEBUG - filelock -   Lock 140021085750752 released on /home/aiscuser/.cache/huggingface/transformers/74b423f29ba4f21ecd941f8d4fdc1e5a1568328f2d478850463813dc4e81c58a.ad8c4e4e357cd74df740cd60a08548a831bd19834e8802cfa73d289e1818a8c4.lock
10/19/2022 02:10:34 - DEBUG - filelock -   Attempting to acquire lock 140020849328960 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:10:34 - DEBUG - filelock -   Lock 140020849328960 acquired on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
Downloading:   0%|          | 0.00/691 [00:00<?, ?B/s]Downloading: 100%|██████████| 691/691 [00:00<00:00, 890kB/s]
10/19/2022 02:10:35 - DEBUG - filelock -   Attempting to release lock 140020849328960 on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:10:35 - DEBUG - filelock -   Lock 140020849328960 released on /home/aiscuser/.cache/huggingface/transformers/f47f36c6d415b8e978f9685f6dbf2651cc9c951dea26b74fcf8bf62e44900449.b53aa458f35a3b932d45090e5916927053a2bf0e803f4eb410b7d1f922b60a05.lock
10/19/2022 02:10:35 - DEBUG - filelock -   Attempting to acquire lock 140020849328864 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:10:35 - DEBUG - filelock -   Lock 140020849328864 acquired on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
Downloading:   0%|          | 0.00/480M [00:00<?, ?B/s]Downloading:   1%|          | 4.87M/480M [00:00<00:11, 44.8MB/s]Downloading:   2%|▏         | 9.79M/480M [00:00<00:10, 48.5MB/s]Downloading:   3%|▎         | 16.1M/480M [00:00<00:08, 56.1MB/s]Downloading:   4%|▍         | 21.4M/480M [00:00<00:10, 44.2MB/s]Downloading:   5%|▌         | 25.9M/480M [00:00<00:11, 43.3MB/s]Downloading:   7%|▋         | 32.4M/480M [00:00<00:09, 50.5MB/s]Downloading:   8%|▊         | 37.5M/480M [00:00<00:09, 48.6MB/s]Downloading:   9%|▉         | 42.3M/480M [00:00<00:10, 45.0MB/s]Downloading:  10%|▉         | 46.7M/480M [00:01<00:10, 41.7MB/s]Downloading:  11%|█         | 50.8M/480M [00:01<00:12, 37.5MB/s]Downloading:  11%|█▏        | 54.5M/480M [00:01<00:12, 36.8MB/s]Downloading:  12%|█▏        | 58.4M/480M [00:01<00:11, 37.8MB/s]Downloading:  13%|█▎        | 64.7M/480M [00:01<00:09, 45.7MB/s]Downloading:  14%|█▍        | 69.2M/480M [00:01<00:09, 43.6MB/s]Downloading:  15%|█▌        | 73.5M/480M [00:01<00:10, 39.9MB/s]Downloading:  16%|█▌        | 77.6M/480M [00:01<00:10, 40.7MB/s]Downloading:  17%|█▋        | 83.2M/480M [00:02<00:09, 44.6MB/s]Downloading:  18%|█▊        | 88.4M/480M [00:02<00:08, 47.2MB/s]Downloading:  19%|█▉        | 93.7M/480M [00:02<00:08, 49.5MB/s]Downloading:  21%|██        | 99.1M/480M [00:02<00:07, 51.7MB/s]Downloading:  22%|██▏       | 106M/480M [00:02<00:06, 57.0MB/s] Downloading:  23%|██▎       | 111M/480M [00:02<00:07, 49.1MB/s]Downloading:  24%|██▍       | 116M/480M [00:02<00:08, 45.7MB/s]Downloading:  26%|██▌       | 123M/480M [00:02<00:07, 51.6MB/s]Downloading:  27%|██▋       | 128M/480M [00:02<00:07, 51.4MB/s]Downloading:  28%|██▊       | 134M/480M [00:03<00:06, 54.7MB/s]Downloading:  29%|██▉       | 139M/480M [00:03<00:08, 42.2MB/s]Downloading:  30%|██▉       | 144M/480M [00:03<00:09, 36.4MB/s]Downloading:  31%|███       | 149M/480M [00:03<00:08, 40.5MB/s]Downloading:  32%|███▏      | 154M/480M [00:03<00:08, 42.5MB/s]Downloading:  33%|███▎      | 158M/480M [00:03<00:09, 36.8MB/s]Downloading:  34%|███▎      | 162M/480M [00:03<00:10, 31.1MB/s]Downloading:  34%|███▍      | 165M/480M [00:04<00:11, 29.5MB/s]Downloading:  35%|███▌      | 168M/480M [00:04<00:11, 29.1MB/s]Downloading:  36%|███▌      | 172M/480M [00:04<00:10, 31.9MB/s]Downloading:  37%|███▋      | 177M/480M [00:04<00:08, 36.8MB/s]Downloading:  38%|███▊      | 181M/480M [00:04<00:09, 34.4MB/s]Downloading:  39%|███▊      | 186M/480M [00:04<00:08, 37.7MB/s]Downloading:  39%|███▉      | 189M/480M [00:04<00:09, 33.0MB/s]Downloading:  40%|████      | 193M/480M [00:04<00:10, 30.0MB/s]Downloading:  41%|████      | 198M/480M [00:05<00:08, 35.5MB/s]Downloading:  42%|████▏     | 204M/480M [00:05<00:06, 43.2MB/s]Downloading:  44%|████▍     | 210M/480M [00:05<00:05, 49.2MB/s]Downloading:  45%|████▍     | 215M/480M [00:05<00:05, 49.3MB/s]Downloading:  46%|████▌     | 220M/480M [00:05<00:05, 49.9MB/s]Downloading:  47%|████▋     | 225M/480M [00:05<00:05, 47.3MB/s]Downloading:  48%|████▊     | 230M/480M [00:05<00:06, 43.3MB/s]Downloading:  49%|████▊     | 234M/480M [00:05<00:05, 43.8MB/s]Downloading:  50%|████▉     | 240M/480M [00:05<00:05, 48.6MB/s]Downloading:  51%|█████     | 246M/480M [00:06<00:04, 51.8MB/s]Downloading:  52%|█████▏    | 251M/480M [00:06<00:05, 40.9MB/s]Downloading:  53%|█████▎    | 256M/480M [00:06<00:05, 43.2MB/s]Downloading:  54%|█████▍    | 260M/480M [00:06<00:05, 42.8MB/s]Downloading:  55%|█████▌    | 265M/480M [00:06<00:05, 39.6MB/s]Downloading:  56%|█████▌    | 269M/480M [00:06<00:05, 38.2MB/s]Downloading:  57%|█████▋    | 274M/480M [00:06<00:04, 43.8MB/s]Downloading:  58%|█████▊    | 279M/480M [00:06<00:04, 43.9MB/s]Downloading:  59%|█████▉    | 283M/480M [00:07<00:04, 42.8MB/s]Downloading:  60%|██████    | 288M/480M [00:07<00:04, 46.4MB/s]Downloading:  61%|██████    | 293M/480M [00:07<00:05, 37.2MB/s]Downloading:  62%|██████▏   | 297M/480M [00:07<00:05, 36.0MB/s]Downloading:  63%|██████▎   | 302M/480M [00:07<00:04, 40.5MB/s]Downloading:  64%|██████▎   | 306M/480M [00:07<00:04, 39.9MB/s]Downloading:  65%|██████▍   | 312M/480M [00:07<00:03, 46.1MB/s]Downloading:  66%|██████▌   | 317M/480M [00:07<00:04, 40.3MB/s]Downloading:  67%|██████▋   | 321M/480M [00:07<00:03, 41.9MB/s]Downloading:  68%|██████▊   | 326M/480M [00:08<00:03, 44.6MB/s]Downloading:  69%|██████▉   | 331M/480M [00:08<00:03, 42.9MB/s]Downloading:  70%|██████▉   | 335M/480M [00:08<00:03, 40.5MB/s]Downloading:  71%|███████   | 339M/480M [00:08<00:03, 40.6MB/s]Downloading:  71%|███████▏  | 343M/480M [00:08<00:03, 37.6MB/s]Downloading:  72%|███████▏  | 346M/480M [00:08<00:04, 34.0MB/s]Downloading:  73%|███████▎  | 352M/480M [00:08<00:03, 40.8MB/s]Downloading:  74%|███████▍  | 356M/480M [00:08<00:03, 40.8MB/s]Downloading:  75%|███████▌  | 361M/480M [00:09<00:02, 42.0MB/s]Downloading:  76%|███████▋  | 367M/480M [00:09<00:02, 48.1MB/s]Downloading:  77%|███████▋  | 371M/480M [00:09<00:02, 47.5MB/s]Downloading:  78%|███████▊  | 376M/480M [00:09<00:02, 46.8MB/s]Downloading:  79%|███████▉  | 382M/480M [00:09<00:02, 50.2MB/s]Downloading:  80%|████████  | 387M/480M [00:09<00:02, 48.4MB/s]Downloading:  82%|████████▏ | 392M/480M [00:09<00:01, 51.1MB/s]Downloading:  83%|████████▎ | 398M/480M [00:09<00:01, 54.1MB/s]Downloading:  84%|████████▍ | 404M/480M [00:09<00:01, 57.9MB/s]Downloading:  85%|████████▌ | 410M/480M [00:09<00:01, 51.4MB/s]Downloading:  86%|████████▋ | 415M/480M [00:10<00:01, 50.3MB/s]Downloading:  87%|████████▋ | 420M/480M [00:10<00:01, 44.3MB/s]Downloading:  88%|████████▊ | 424M/480M [00:10<00:01, 41.7MB/s]Downloading:  90%|████████▉ | 430M/480M [00:10<00:01, 46.9MB/s]Downloading:  90%|█████████ | 435M/480M [00:10<00:01, 43.9MB/s]Downloading:  92%|█████████▏| 440M/480M [00:10<00:00, 47.2MB/s]Downloading:  93%|█████████▎| 445M/480M [00:10<00:00, 49.5MB/s]Downloading:  94%|█████████▎| 450M/480M [00:11<00:00, 36.5MB/s]Downloading:  95%|█████████▍| 454M/480M [00:11<00:00, 31.2MB/s]Downloading:  95%|█████████▌| 458M/480M [00:11<00:00, 30.6MB/s]Downloading:  96%|█████████▋| 463M/480M [00:11<00:00, 36.4MB/s]Downloading:  97%|█████████▋| 467M/480M [00:11<00:00, 38.0MB/s]Downloading:  98%|█████████▊| 471M/480M [00:11<00:00, 35.3MB/s]Downloading:  99%|█████████▉| 475M/480M [00:11<00:00, 30.9MB/s]Downloading: 100%|█████████▉| 480M/480M [00:11<00:00, 35.5MB/s]Downloading: 100%|██████████| 480M/480M [00:11<00:00, 42.0MB/s]
10/19/2022 02:10:47 - DEBUG - filelock -   Attempting to release lock 140020849328864 on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:10:47 - DEBUG - filelock -   Lock 140020849328864 released on /home/aiscuser/.cache/huggingface/transformers/e472463826d959ba1a2526157c66c6678d307297de0ac70cb20d4bc20227a3ea.cd2d780fc8b692f148ec889e56ece5a353765aa429eda28d9a89b5a1aeb735db.lock
10/19/2022 02:10:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, beam_size=10, debug=False, dev_filename='dataset/python/valid.jsonl', device=device(type='cuda'), do_eval=True, do_test=True, do_train=True, eval_batch_size=256, freeze_bottom_k_layer_index=6, gradient_accumulation_steps=1, learning_rate=5e-05, max_grad_norm=1.0, max_source_length=256, max_target_length=128, model_name_or_path='microsoft/unixcoder-base', n_debug_samples=100, n_gpu=1, no_cuda=False, num_train_epochs=10, output_dir='saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_6_layers/20221019021023', seed=123456, test_filename='dataset/python/test.jsonl', train_batch_size=32, train_filename='dataset/python/train.jsonl', weight_decay=0.0)
10/19/2022 02:10:50 - INFO - __main__ -   +------------------------------------------------------------+--------------+---------+
| Layer Name                                                 | Output Shape | Param # |
+------------------------------------------------------------+--------------+---------+
| encoder.encoder.layer.6.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.6.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.6.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.6.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.6.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.6.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.6.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.6.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.6.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.7.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.7.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.7.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.7.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.7.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.7.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.7.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.7.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.8.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.8.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.8.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.8.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.8.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.8.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.8.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.8.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.query.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.query.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.key.weight          |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.key.bias            |        [768] |     768 |
| encoder.encoder.layer.9.attention.self.value.weight        |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.self.value.bias          |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.dense.weight      |   [768, 768] |  589824 |
| encoder.encoder.layer.9.attention.output.dense.bias        |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.weight  |        [768] |     768 |
| encoder.encoder.layer.9.attention.output.LayerNorm.bias    |        [768] |     768 |
| encoder.encoder.layer.9.intermediate.dense.weight          |  [3072, 768] | 2359296 |
| encoder.encoder.layer.9.intermediate.dense.bias            |       [3072] |    3072 |
| encoder.encoder.layer.9.output.dense.weight                |  [768, 3072] | 2359296 |
| encoder.encoder.layer.9.output.dense.bias                  |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.weight            |        [768] |     768 |
| encoder.encoder.layer.9.output.LayerNorm.bias              |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.10.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.10.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.10.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.10.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.10.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.10.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.10.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.10.output.LayerNorm.bias             |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.query.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.query.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.key.weight         |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.key.bias           |        [768] |     768 |
| encoder.encoder.layer.11.attention.self.value.weight       |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.self.value.bias         |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.dense.weight     |   [768, 768] |  589824 |
| encoder.encoder.layer.11.attention.output.dense.bias       |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.weight |        [768] |     768 |
| encoder.encoder.layer.11.attention.output.LayerNorm.bias   |        [768] |     768 |
| encoder.encoder.layer.11.intermediate.dense.weight         |  [3072, 768] | 2359296 |
| encoder.encoder.layer.11.intermediate.dense.bias           |       [3072] |    3072 |
| encoder.encoder.layer.11.output.dense.weight               |  [768, 3072] | 2359296 |
| encoder.encoder.layer.11.output.dense.bias                 |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.weight           |        [768] |     768 |
| encoder.encoder.layer.11.output.LayerNorm.bias             |        [768] |     768 |
| encoder.pooler.dense.weight                                |   [768, 768] |  589824 |
| encoder.pooler.dense.bias                                  |        [768] |     768 |
| dense.weight                                               |   [768, 768] |  589824 |
| dense.bias                                                 |        [768] |     768 |
+------------------------------------------------------------+--------------+---------+
10/19/2022 02:10:50 - INFO - __main__ -   The model has 43708416 trainable parameters
10/19/2022 02:11:01 - INFO - __main__ -   *** Example ***
10/19/2022 02:11:01 - INFO - __main__ -   idx: 0
10/19/2022 02:11:01 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_split', '_', 'phy', 'log', 'en', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_";"', '_)', '_[', '_0', '_]', '</s>']
10/19/2022 02:11:01 - INFO - __main__ -   source_ids: 0 5 2 19 729 5192 181 3258 896 386 207 400 428 2019 3144 385 437 201 120 743 545 3144 385 3144 513 12945 120 1046 385 428 746 5192 400 3144 743 483 1046 626 461 2406 513 3144 513 1046 626 524 2406 746 5192 400 29760 743 626 461 2406 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:11:01 - INFO - __main__ -   target_tokens: ['<mask0>', 'Return', '_either', '_the', '_full', '_or', '_truncated', '_version', '_of', '_a', '_Q', 'II', 'ME', '_-', '_formatted', '_taxonomy', '_string', '_.', '</s>']
10/19/2022 02:11:01 - INFO - __main__ -   target_ids: 19 1675 4759 448 3662 872 19307 2229 595 434 1152 4300 1098 581 10440 29021 724 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:11:01 - INFO - __main__ -   *** Example ***
10/19/2022 02:11:01 - INFO - __main__ -   idx: 1
10/19/2022 02:11:01 - INFO - __main__ -   source_tokens: ['<s>', '<encoder-decoder>', '</s>', '<mask0>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'akedirs', '_(', '_d', '_)', '_except', '_OSError', '_as', '_oe', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'makedirs', '_#', '_ENOENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_errno', '_==', '_errno', '_.', '_ENOENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({})', '_do', '_not', '_exist', '.', '_If', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', '_({})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_oe', '_.', '_strerror', '_)', '</s>']
10/19/2022 02:11:01 - INFO - __main__ -   source_ids: 0 5 2 19 729 6229 181 1282 400 480 743 545 462 800 2215 746 1391 746 4534 400 480 743 545 1568 545 2215 746 446 23328 400 480 743 3552 22934 880 44902 545 830 1570 800 7564 918 2215 132 24429 830 41059 144 4038 5632 1012 872 3456 462 2215 746 2341 550 2341 746 41059 545 2345 385 7916 443 400 1638 3533 872 2726 11613 488 448 1391 46072 1000 800 3040 132 1359 2713 1147 15323 434 579 3456 563 1721 130 13874 6229 1345 1946 11613 488 448 1391 6418 3040 6315 743 483 2345 746 2021 400 480 743 669 545 2345 385 7916 443 400 1638 1088 843 10058 11749 508 1738 448 1721 3456 46072 918 1841 144 2334 3947 743 483 2345 746 2021 400 480 2019 44902 746 20115 743 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:11:01 - INFO - __main__ -   target_tokens: ['<mask0>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catch', 'es', '_OSError', '_exceptions', '_and', '_returns', '_a', '_desc', 'riptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/19/2022 02:11:01 - INFO - __main__ -   target_ids: 19 1749 508 2002 3984 448 8813 3456 1391 2129 800 3040 462 1769 1738 835 746 1044 1454 2092 482 22934 12300 706 2060 434 2162 44105 1841 4488 595 479 581 47183 448 843 746 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/19/2022 02:14:18 - INFO - __main__ -   ***** Running training *****
10/19/2022 02:14:18 - INFO - __main__ -     Num examples = 251820
10/19/2022 02:14:18 - INFO - __main__ -     Batch size = 32
10/19/2022 02:14:18 - INFO - __main__ -     Num epoch = 10
10/19/2022 02:14:31 - INFO - __main__ -   epoch 0 step 100 loss 3.3109
10/19/2022 02:14:42 - INFO - __main__ -   epoch 0 step 200 loss 3.0951
10/19/2022 02:14:54 - INFO - __main__ -   epoch 0 step 300 loss 2.862
10/19/2022 02:15:05 - INFO - __main__ -   epoch 0 step 400 loss 2.7562
10/19/2022 02:15:17 - INFO - __main__ -   epoch 0 step 500 loss 2.7051
10/19/2022 02:15:28 - INFO - __main__ -   epoch 0 step 600 loss 2.7022
10/19/2022 02:15:40 - INFO - __main__ -   epoch 0 step 700 loss 2.6926
10/19/2022 02:15:52 - INFO - __main__ -   epoch 0 step 800 loss 2.6792
10/19/2022 02:16:03 - INFO - __main__ -   epoch 0 step 900 loss 2.7035
10/19/2022 02:16:15 - INFO - __main__ -   epoch 0 step 1000 loss 2.6682
10/19/2022 02:16:26 - INFO - __main__ -   epoch 0 step 1100 loss 2.6445
10/19/2022 02:16:38 - INFO - __main__ -   epoch 0 step 1200 loss 2.6099
10/19/2022 02:16:49 - INFO - __main__ -   epoch 0 step 1300 loss 2.6374
10/19/2022 02:17:01 - INFO - __main__ -   epoch 0 step 1400 loss 2.6485
10/19/2022 02:17:12 - INFO - __main__ -   epoch 0 step 1500 loss 2.6556
10/19/2022 02:17:24 - INFO - __main__ -   epoch 0 step 1600 loss 2.6477
10/19/2022 02:17:36 - INFO - __main__ -   epoch 0 step 1700 loss 2.6132
10/19/2022 02:17:47 - INFO - __main__ -   epoch 0 step 1800 loss 2.5956
10/19/2022 02:17:59 - INFO - __main__ -   epoch 0 step 1900 loss 2.6024
10/19/2022 02:18:10 - INFO - __main__ -   epoch 0 step 2000 loss 2.5936
10/19/2022 02:18:22 - INFO - __main__ -   epoch 0 step 2100 loss 2.6277
10/19/2022 02:18:33 - INFO - __main__ -   epoch 0 step 2200 loss 2.5928
10/19/2022 02:18:45 - INFO - __main__ -   epoch 0 step 2300 loss 2.6032
10/19/2022 02:18:57 - INFO - __main__ -   epoch 0 step 2400 loss 2.6025
10/19/2022 02:19:08 - INFO - __main__ -   epoch 0 step 2500 loss 2.5887
10/19/2022 02:19:20 - INFO - __main__ -   epoch 0 step 2600 loss 2.6202
10/19/2022 02:19:31 - INFO - __main__ -   epoch 0 step 2700 loss 2.6094
10/19/2022 02:19:43 - INFO - __main__ -   epoch 0 step 2800 loss 2.6035
10/19/2022 02:19:54 - INFO - __main__ -   epoch 0 step 2900 loss 2.6213
10/19/2022 02:20:06 - INFO - __main__ -   epoch 0 step 3000 loss 2.5769
10/19/2022 02:20:18 - INFO - __main__ -   epoch 0 step 3100 loss 2.6179
10/19/2022 02:20:29 - INFO - __main__ -   epoch 0 step 3200 loss 2.5869
10/19/2022 02:20:41 - INFO - __main__ -   epoch 0 step 3300 loss 2.5989
10/19/2022 02:20:52 - INFO - __main__ -   epoch 0 step 3400 loss 2.6218
10/19/2022 02:21:04 - INFO - __main__ -   epoch 0 step 3500 loss 2.568
10/19/2022 02:21:15 - INFO - __main__ -   epoch 0 step 3600 loss 2.5754
10/19/2022 02:21:27 - INFO - __main__ -   epoch 0 step 3700 loss 2.5916
10/19/2022 02:21:39 - INFO - __main__ -   epoch 0 step 3800 loss 2.6005
10/19/2022 02:21:50 - INFO - __main__ -   epoch 0 step 3900 loss 2.581
10/19/2022 02:22:02 - INFO - __main__ -   epoch 0 step 4000 loss 2.5926
10/19/2022 02:22:13 - INFO - __main__ -   epoch 0 step 4100 loss 2.5987
10/19/2022 02:22:25 - INFO - __main__ -   epoch 0 step 4200 loss 2.5816
10/19/2022 02:22:36 - INFO - __main__ -   epoch 0 step 4300 loss 2.5967
10/19/2022 02:22:48 - INFO - __main__ -   epoch 0 step 4400 loss 2.5677
10/19/2022 02:23:00 - INFO - __main__ -   epoch 0 step 4500 loss 2.5782
10/19/2022 02:23:11 - INFO - __main__ -   epoch 0 step 4600 loss 2.6005
10/19/2022 02:23:23 - INFO - __main__ -   epoch 0 step 4700 loss 2.5697
10/19/2022 02:23:34 - INFO - __main__ -   epoch 0 step 4800 loss 2.5928
10/19/2022 02:23:46 - INFO - __main__ -   epoch 0 step 4900 loss 2.5912
10/19/2022 02:23:57 - INFO - __main__ -   epoch 0 step 5000 loss 2.5809
10/19/2022 02:24:09 - INFO - __main__ -   epoch 0 step 5100 loss 2.5931
10/19/2022 02:24:20 - INFO - __main__ -   epoch 0 step 5200 loss 2.5606
10/19/2022 02:24:32 - INFO - __main__ -   epoch 0 step 5300 loss 2.6188
10/19/2022 02:24:43 - INFO - __main__ -   epoch 0 step 5400 loss 2.5559
10/19/2022 02:24:55 - INFO - __main__ -   epoch 0 step 5500 loss 2.5798
10/19/2022 02:25:07 - INFO - __main__ -   epoch 0 step 5600 loss 2.5735
10/19/2022 02:25:18 - INFO - __main__ -   epoch 0 step 5700 loss 2.5848
10/19/2022 02:25:30 - INFO - __main__ -   epoch 0 step 5800 loss 2.5732
10/19/2022 02:25:41 - INFO - __main__ -   epoch 0 step 5900 loss 2.5534
10/19/2022 02:25:53 - INFO - __main__ -   epoch 0 step 6000 loss 2.5417
10/19/2022 02:26:04 - INFO - __main__ -   epoch 0 step 6100 loss 2.5866
10/19/2022 02:26:16 - INFO - __main__ -   epoch 0 step 6200 loss 2.5598
10/19/2022 02:26:27 - INFO - __main__ -   epoch 0 step 6300 loss 2.5812
10/19/2022 02:26:39 - INFO - __main__ -   epoch 0 step 6400 loss 2.5706
10/19/2022 02:26:51 - INFO - __main__ -   epoch 0 step 6500 loss 2.5935
10/19/2022 02:27:02 - INFO - __main__ -   epoch 0 step 6600 loss 2.5608
10/19/2022 02:27:14 - INFO - __main__ -   epoch 0 step 6700 loss 2.5658
10/19/2022 02:27:25 - INFO - __main__ -   epoch 0 step 6800 loss 2.5971
10/19/2022 02:27:37 - INFO - __main__ -   epoch 0 step 6900 loss 2.5937
10/19/2022 02:27:48 - INFO - __main__ -   epoch 0 step 7000 loss 2.595
10/19/2022 02:28:00 - INFO - __main__ -   epoch 0 step 7100 loss 2.5335
10/19/2022 02:28:11 - INFO - __main__ -   epoch 0 step 7200 loss 2.5321
10/19/2022 02:28:23 - INFO - __main__ -   epoch 0 step 7300 loss 2.5636
10/19/2022 02:28:34 - INFO - __main__ -   epoch 0 step 7400 loss 2.5591
10/19/2022 02:28:46 - INFO - __main__ -   epoch 0 step 7500 loss 2.5625
10/19/2022 02:28:58 - INFO - __main__ -   epoch 0 step 7600 loss 2.5691
10/19/2022 02:29:09 - INFO - __main__ -   epoch 0 step 7700 loss 2.5649
10/19/2022 02:29:21 - INFO - __main__ -   epoch 0 step 7800 loss 2.582
10/19/2022 02:29:41 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 02:29:41 - INFO - __main__ -     Num examples = 13914
10/19/2022 02:29:41 - INFO - __main__ -     Batch size = 256
10/19/2022 02:30:04 - INFO - __main__ -     eval_ppl = 15.23309
10/19/2022 02:30:04 - INFO - __main__ -     ********************
/sci_1/t-enshengshi/interpretability/sync_repo/bertviz/code-summarization/model.py:189: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
Total: 1000
10/19/2022 02:32:58 - INFO - __main__ -     bleu-4 = 18.16 
10/19/2022 02:32:58 - INFO - __main__ -     ********************
10/19/2022 02:32:58 - INFO - __main__ -     Best bleu:18.16
10/19/2022 02:32:58 - INFO - __main__ -     ********************
10/19/2022 02:33:15 - INFO - __main__ -   epoch 1 step 7900 loss 2.5457
10/19/2022 02:33:26 - INFO - __main__ -   epoch 1 step 8000 loss 2.4583
10/19/2022 02:33:38 - INFO - __main__ -   epoch 1 step 8100 loss 2.4849
10/19/2022 02:33:49 - INFO - __main__ -   epoch 1 step 8200 loss 2.4898
10/19/2022 02:34:01 - INFO - __main__ -   epoch 1 step 8300 loss 2.4732
10/19/2022 02:34:13 - INFO - __main__ -   epoch 1 step 8400 loss 2.4828
10/19/2022 02:34:24 - INFO - __main__ -   epoch 1 step 8500 loss 2.464
10/19/2022 02:34:36 - INFO - __main__ -   epoch 1 step 8600 loss 2.4994
10/19/2022 02:34:47 - INFO - __main__ -   epoch 1 step 8700 loss 2.4883
10/19/2022 02:34:59 - INFO - __main__ -   epoch 1 step 8800 loss 2.4967
10/19/2022 02:35:10 - INFO - __main__ -   epoch 1 step 8900 loss 2.5222
10/19/2022 02:35:22 - INFO - __main__ -   epoch 1 step 9000 loss 2.4862
10/19/2022 02:35:34 - INFO - __main__ -   epoch 1 step 9100 loss 2.4795
10/19/2022 02:35:45 - INFO - __main__ -   epoch 1 step 9200 loss 2.4948
10/19/2022 02:35:57 - INFO - __main__ -   epoch 1 step 9300 loss 2.4766
10/19/2022 02:36:08 - INFO - __main__ -   epoch 1 step 9400 loss 2.4608
10/19/2022 02:36:20 - INFO - __main__ -   epoch 1 step 9500 loss 2.4517
10/19/2022 02:36:32 - INFO - __main__ -   epoch 1 step 9600 loss 2.4929
10/19/2022 02:36:43 - INFO - __main__ -   epoch 1 step 9700 loss 2.4794
10/19/2022 02:36:55 - INFO - __main__ -   epoch 1 step 9800 loss 2.4757
10/19/2022 02:37:06 - INFO - __main__ -   epoch 1 step 9900 loss 2.5068
10/19/2022 02:37:18 - INFO - __main__ -   epoch 1 step 10000 loss 2.48
10/19/2022 02:37:29 - INFO - __main__ -   epoch 1 step 10100 loss 2.5035
10/19/2022 02:37:41 - INFO - __main__ -   epoch 1 step 10200 loss 2.4671
10/19/2022 02:37:53 - INFO - __main__ -   epoch 1 step 10300 loss 2.5113
10/19/2022 02:38:04 - INFO - __main__ -   epoch 1 step 10400 loss 2.4737
10/19/2022 02:38:16 - INFO - __main__ -   epoch 1 step 10500 loss 2.4479
10/19/2022 02:38:27 - INFO - __main__ -   epoch 1 step 10600 loss 2.4827
10/19/2022 02:38:39 - INFO - __main__ -   epoch 1 step 10700 loss 2.5383
10/19/2022 02:38:50 - INFO - __main__ -   epoch 1 step 10800 loss 2.5249
10/19/2022 02:39:02 - INFO - __main__ -   epoch 1 step 10900 loss 2.5039
10/19/2022 02:39:14 - INFO - __main__ -   epoch 1 step 11000 loss 2.4689
10/19/2022 02:39:25 - INFO - __main__ -   epoch 1 step 11100 loss 2.5056
10/19/2022 02:39:37 - INFO - __main__ -   epoch 1 step 11200 loss 2.4961
10/19/2022 02:39:48 - INFO - __main__ -   epoch 1 step 11300 loss 2.4926
10/19/2022 02:40:00 - INFO - __main__ -   epoch 1 step 11400 loss 2.4577
10/19/2022 02:40:11 - INFO - __main__ -   epoch 1 step 11500 loss 2.4617
10/19/2022 02:40:23 - INFO - __main__ -   epoch 1 step 11600 loss 2.5014
10/19/2022 02:40:35 - INFO - __main__ -   epoch 1 step 11700 loss 2.4755
10/19/2022 02:40:46 - INFO - __main__ -   epoch 1 step 11800 loss 2.4841
10/19/2022 02:40:58 - INFO - __main__ -   epoch 1 step 11900 loss 2.4644
10/19/2022 02:41:09 - INFO - __main__ -   epoch 1 step 12000 loss 2.4801
10/19/2022 02:41:21 - INFO - __main__ -   epoch 1 step 12100 loss 2.4662
10/19/2022 02:41:32 - INFO - __main__ -   epoch 1 step 12200 loss 2.446
10/19/2022 02:41:44 - INFO - __main__ -   epoch 1 step 12300 loss 2.4725
10/19/2022 02:41:55 - INFO - __main__ -   epoch 1 step 12400 loss 2.4979
10/19/2022 02:42:07 - INFO - __main__ -   epoch 1 step 12500 loss 2.4556
10/19/2022 02:42:19 - INFO - __main__ -   epoch 1 step 12600 loss 2.4744
10/19/2022 02:42:30 - INFO - __main__ -   epoch 1 step 12700 loss 2.4515
10/19/2022 02:42:42 - INFO - __main__ -   epoch 1 step 12800 loss 2.4436
10/19/2022 02:42:53 - INFO - __main__ -   epoch 1 step 12900 loss 2.4578
10/19/2022 02:43:05 - INFO - __main__ -   epoch 1 step 13000 loss 2.4667
10/19/2022 02:43:16 - INFO - __main__ -   epoch 1 step 13100 loss 2.4668
10/19/2022 02:43:28 - INFO - __main__ -   epoch 1 step 13200 loss 2.4938
10/19/2022 02:43:39 - INFO - __main__ -   epoch 1 step 13300 loss 2.4684
10/19/2022 02:43:51 - INFO - __main__ -   epoch 1 step 13400 loss 2.4852
10/19/2022 02:44:03 - INFO - __main__ -   epoch 1 step 13500 loss 2.4582
10/19/2022 02:44:14 - INFO - __main__ -   epoch 1 step 13600 loss 2.4558
10/19/2022 02:44:26 - INFO - __main__ -   epoch 1 step 13700 loss 2.4851
10/19/2022 02:44:37 - INFO - __main__ -   epoch 1 step 13800 loss 2.4663
10/19/2022 02:44:49 - INFO - __main__ -   epoch 1 step 13900 loss 2.4552
10/19/2022 02:45:00 - INFO - __main__ -   epoch 1 step 14000 loss 2.4828
10/19/2022 02:45:12 - INFO - __main__ -   epoch 1 step 14100 loss 2.4578
10/19/2022 02:45:24 - INFO - __main__ -   epoch 1 step 14200 loss 2.4486
10/19/2022 02:45:35 - INFO - __main__ -   epoch 1 step 14300 loss 2.4562
10/19/2022 02:45:47 - INFO - __main__ -   epoch 1 step 14400 loss 2.4291
10/19/2022 02:45:58 - INFO - __main__ -   epoch 1 step 14500 loss 2.4515
10/19/2022 02:46:10 - INFO - __main__ -   epoch 1 step 14600 loss 2.4801
10/19/2022 02:46:21 - INFO - __main__ -   epoch 1 step 14700 loss 2.4165
10/19/2022 02:46:33 - INFO - __main__ -   epoch 1 step 14800 loss 2.4619
10/19/2022 02:46:45 - INFO - __main__ -   epoch 1 step 14900 loss 2.4878
10/19/2022 02:46:56 - INFO - __main__ -   epoch 1 step 15000 loss 2.4325
10/19/2022 02:47:08 - INFO - __main__ -   epoch 1 step 15100 loss 2.4427
10/19/2022 02:47:19 - INFO - __main__ -   epoch 1 step 15200 loss 2.4513
10/19/2022 02:47:31 - INFO - __main__ -   epoch 1 step 15300 loss 2.49
10/19/2022 02:47:42 - INFO - __main__ -   epoch 1 step 15400 loss 2.4748
10/19/2022 02:47:54 - INFO - __main__ -   epoch 1 step 15500 loss 2.446
10/19/2022 02:48:06 - INFO - __main__ -   epoch 1 step 15600 loss 2.468
10/19/2022 02:48:17 - INFO - __main__ -   epoch 1 step 15700 loss 2.4599
10/19/2022 02:48:22 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 02:48:22 - INFO - __main__ -     Num examples = 13914
10/19/2022 02:48:22 - INFO - __main__ -     Batch size = 256
10/19/2022 02:48:45 - INFO - __main__ -     eval_ppl = 15.14713
10/19/2022 02:48:45 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 02:51:33 - INFO - __main__ -     bleu-4 = 18.0 
10/19/2022 02:51:33 - INFO - __main__ -     ********************
10/19/2022 02:51:40 - INFO - __main__ -   epoch 2 step 15800 loss 2.3509
10/19/2022 02:51:52 - INFO - __main__ -   epoch 2 step 15900 loss 2.3144
10/19/2022 02:52:03 - INFO - __main__ -   epoch 2 step 16000 loss 2.2711
10/19/2022 02:52:15 - INFO - __main__ -   epoch 2 step 16100 loss 2.2867
10/19/2022 02:52:26 - INFO - __main__ -   epoch 2 step 16200 loss 2.3071
10/19/2022 02:52:38 - INFO - __main__ -   epoch 2 step 16300 loss 2.3153
10/19/2022 02:52:49 - INFO - __main__ -   epoch 2 step 16400 loss 2.2942
10/19/2022 02:53:01 - INFO - __main__ -   epoch 2 step 16500 loss 2.2938
10/19/2022 02:53:12 - INFO - __main__ -   epoch 2 step 16600 loss 2.2928
10/19/2022 02:53:24 - INFO - __main__ -   epoch 2 step 16700 loss 2.3409
10/19/2022 02:53:36 - INFO - __main__ -   epoch 2 step 16800 loss 2.2983
10/19/2022 02:53:47 - INFO - __main__ -   epoch 2 step 16900 loss 2.2814
10/19/2022 02:53:59 - INFO - __main__ -   epoch 2 step 17000 loss 2.3095
10/19/2022 02:54:10 - INFO - __main__ -   epoch 2 step 17100 loss 2.2791
10/19/2022 02:54:22 - INFO - __main__ -   epoch 2 step 17200 loss 2.3135
10/19/2022 02:54:33 - INFO - __main__ -   epoch 2 step 17300 loss 2.295
10/19/2022 02:54:45 - INFO - __main__ -   epoch 2 step 17400 loss 2.3105
10/19/2022 02:54:56 - INFO - __main__ -   epoch 2 step 17500 loss 2.3004
10/19/2022 02:55:08 - INFO - __main__ -   epoch 2 step 17600 loss 2.2705
10/19/2022 02:55:20 - INFO - __main__ -   epoch 2 step 17700 loss 2.2781
10/19/2022 02:55:31 - INFO - __main__ -   epoch 2 step 17800 loss 2.328
10/19/2022 02:55:43 - INFO - __main__ -   epoch 2 step 17900 loss 2.3318
10/19/2022 02:55:54 - INFO - __main__ -   epoch 2 step 18000 loss 2.33
10/19/2022 02:56:06 - INFO - __main__ -   epoch 2 step 18100 loss 2.2521
10/19/2022 02:56:17 - INFO - __main__ -   epoch 2 step 18200 loss 2.3014
10/19/2022 02:56:29 - INFO - __main__ -   epoch 2 step 18300 loss 2.3193
10/19/2022 02:56:41 - INFO - __main__ -   epoch 2 step 18400 loss 2.3037
10/19/2022 02:56:52 - INFO - __main__ -   epoch 2 step 18500 loss 2.3265
10/19/2022 02:57:04 - INFO - __main__ -   epoch 2 step 18600 loss 2.3161
10/19/2022 02:57:15 - INFO - __main__ -   epoch 2 step 18700 loss 2.3067
10/19/2022 02:57:27 - INFO - __main__ -   epoch 2 step 18800 loss 2.3282
10/19/2022 02:57:38 - INFO - __main__ -   epoch 2 step 18900 loss 2.3195
10/19/2022 02:57:50 - INFO - __main__ -   epoch 2 step 19000 loss 2.3183
10/19/2022 02:58:01 - INFO - __main__ -   epoch 2 step 19100 loss 2.2816
10/19/2022 02:58:13 - INFO - __main__ -   epoch 2 step 19200 loss 2.3131
10/19/2022 02:58:25 - INFO - __main__ -   epoch 2 step 19300 loss 2.2891
10/19/2022 02:58:36 - INFO - __main__ -   epoch 2 step 19400 loss 2.2946
10/19/2022 02:58:48 - INFO - __main__ -   epoch 2 step 19500 loss 2.3244
10/19/2022 02:58:59 - INFO - __main__ -   epoch 2 step 19600 loss 2.3221
10/19/2022 02:59:11 - INFO - __main__ -   epoch 2 step 19700 loss 2.3176
10/19/2022 02:59:23 - INFO - __main__ -   epoch 2 step 19800 loss 2.3038
10/19/2022 02:59:34 - INFO - __main__ -   epoch 2 step 19900 loss 2.2937
10/19/2022 02:59:46 - INFO - __main__ -   epoch 2 step 20000 loss 2.3087
10/19/2022 02:59:57 - INFO - __main__ -   epoch 2 step 20100 loss 2.3308
10/19/2022 03:00:09 - INFO - __main__ -   epoch 2 step 20200 loss 2.3166
10/19/2022 03:00:20 - INFO - __main__ -   epoch 2 step 20300 loss 2.3151
10/19/2022 03:00:32 - INFO - __main__ -   epoch 2 step 20400 loss 2.3081
10/19/2022 03:00:43 - INFO - __main__ -   epoch 2 step 20500 loss 2.3131
10/19/2022 03:00:55 - INFO - __main__ -   epoch 2 step 20600 loss 2.3262
10/19/2022 03:01:06 - INFO - __main__ -   epoch 2 step 20700 loss 2.3254
10/19/2022 03:01:18 - INFO - __main__ -   epoch 2 step 20800 loss 2.3332
10/19/2022 03:01:30 - INFO - __main__ -   epoch 2 step 20900 loss 2.3084
10/19/2022 03:01:41 - INFO - __main__ -   epoch 2 step 21000 loss 2.3347
10/19/2022 03:01:53 - INFO - __main__ -   epoch 2 step 21100 loss 2.2937
10/19/2022 03:02:04 - INFO - __main__ -   epoch 2 step 21200 loss 2.3311
10/19/2022 03:02:16 - INFO - __main__ -   epoch 2 step 21300 loss 2.3066
10/19/2022 03:02:28 - INFO - __main__ -   epoch 2 step 21400 loss 2.298
10/19/2022 03:02:39 - INFO - __main__ -   epoch 2 step 21500 loss 2.2991
10/19/2022 03:02:51 - INFO - __main__ -   epoch 2 step 21600 loss 2.2971
10/19/2022 03:03:02 - INFO - __main__ -   epoch 2 step 21700 loss 2.3017
10/19/2022 03:03:14 - INFO - __main__ -   epoch 2 step 21800 loss 2.3363
10/19/2022 03:03:26 - INFO - __main__ -   epoch 2 step 21900 loss 2.318
10/19/2022 03:03:37 - INFO - __main__ -   epoch 2 step 22000 loss 2.3177
10/19/2022 03:03:49 - INFO - __main__ -   epoch 2 step 22100 loss 2.3341
10/19/2022 03:04:00 - INFO - __main__ -   epoch 2 step 22200 loss 2.3108
10/19/2022 03:04:12 - INFO - __main__ -   epoch 2 step 22300 loss 2.3403
10/19/2022 03:04:24 - INFO - __main__ -   epoch 2 step 22400 loss 2.335
10/19/2022 03:04:35 - INFO - __main__ -   epoch 2 step 22500 loss 2.3125
10/19/2022 03:04:47 - INFO - __main__ -   epoch 2 step 22600 loss 2.3567
10/19/2022 03:04:58 - INFO - __main__ -   epoch 2 step 22700 loss 2.326
10/19/2022 03:05:10 - INFO - __main__ -   epoch 2 step 22800 loss 2.2994
10/19/2022 03:05:21 - INFO - __main__ -   epoch 2 step 22900 loss 2.3003
10/19/2022 03:05:33 - INFO - __main__ -   epoch 2 step 23000 loss 2.3135
10/19/2022 03:05:45 - INFO - __main__ -   epoch 2 step 23100 loss 2.3142
10/19/2022 03:05:56 - INFO - __main__ -   epoch 2 step 23200 loss 2.3426
10/19/2022 03:06:08 - INFO - __main__ -   epoch 2 step 23300 loss 2.352
10/19/2022 03:06:19 - INFO - __main__ -   epoch 2 step 23400 loss 2.3109
10/19/2022 03:06:31 - INFO - __main__ -   epoch 2 step 23500 loss 2.2855
10/19/2022 03:06:42 - INFO - __main__ -   epoch 2 step 23600 loss 2.3348
10/19/2022 03:06:44 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:06:44 - INFO - __main__ -     Num examples = 13914
10/19/2022 03:06:44 - INFO - __main__ -     Batch size = 256
10/19/2022 03:07:07 - INFO - __main__ -     eval_ppl = 15.55653
10/19/2022 03:07:07 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 03:09:53 - INFO - __main__ -     bleu-4 = 18.24 
10/19/2022 03:09:53 - INFO - __main__ -     ********************
10/19/2022 03:09:53 - INFO - __main__ -     Best bleu:18.24
10/19/2022 03:09:53 - INFO - __main__ -     ********************
10/19/2022 03:10:10 - INFO - __main__ -   epoch 3 step 23700 loss 2.1938
10/19/2022 03:10:21 - INFO - __main__ -   epoch 3 step 23800 loss 2.1449
10/19/2022 03:10:33 - INFO - __main__ -   epoch 3 step 23900 loss 2.1277
10/19/2022 03:10:44 - INFO - __main__ -   epoch 3 step 24000 loss 2.1189
10/19/2022 03:10:56 - INFO - __main__ -   epoch 3 step 24100 loss 2.1408
10/19/2022 03:11:08 - INFO - __main__ -   epoch 3 step 24200 loss 2.1369
10/19/2022 03:11:19 - INFO - __main__ -   epoch 3 step 24300 loss 2.1683
10/19/2022 03:11:31 - INFO - __main__ -   epoch 3 step 24400 loss 2.1616
10/19/2022 03:11:43 - INFO - __main__ -   epoch 3 step 24500 loss 2.1683
10/19/2022 03:11:54 - INFO - __main__ -   epoch 3 step 24600 loss 2.1353
10/19/2022 03:12:06 - INFO - __main__ -   epoch 3 step 24700 loss 2.1149
10/19/2022 03:12:17 - INFO - __main__ -   epoch 3 step 24800 loss 2.1523
10/19/2022 03:12:29 - INFO - __main__ -   epoch 3 step 24900 loss 2.1318
10/19/2022 03:12:41 - INFO - __main__ -   epoch 3 step 25000 loss 2.1719
10/19/2022 03:12:52 - INFO - __main__ -   epoch 3 step 25100 loss 2.1758
10/19/2022 03:13:04 - INFO - __main__ -   epoch 3 step 25200 loss 2.1381
10/19/2022 03:13:16 - INFO - __main__ -   epoch 3 step 25300 loss 2.1754
10/19/2022 03:13:27 - INFO - __main__ -   epoch 3 step 25400 loss 2.1802
10/19/2022 03:13:39 - INFO - __main__ -   epoch 3 step 25500 loss 2.1625
10/19/2022 03:13:50 - INFO - __main__ -   epoch 3 step 25600 loss 2.1439
10/19/2022 03:14:02 - INFO - __main__ -   epoch 3 step 25700 loss 2.1603
10/19/2022 03:14:14 - INFO - __main__ -   epoch 3 step 25800 loss 2.1469
10/19/2022 03:14:25 - INFO - __main__ -   epoch 3 step 25900 loss 2.1492
10/19/2022 03:14:37 - INFO - __main__ -   epoch 3 step 26000 loss 2.178
10/19/2022 03:14:48 - INFO - __main__ -   epoch 3 step 26100 loss 2.1869
10/19/2022 03:15:00 - INFO - __main__ -   epoch 3 step 26200 loss 2.1808
10/19/2022 03:15:11 - INFO - __main__ -   epoch 3 step 26300 loss 2.1742
10/19/2022 03:15:23 - INFO - __main__ -   epoch 3 step 26400 loss 2.156
10/19/2022 03:15:35 - INFO - __main__ -   epoch 3 step 26500 loss 2.1621
10/19/2022 03:15:46 - INFO - __main__ -   epoch 3 step 26600 loss 2.1616
10/19/2022 03:15:58 - INFO - __main__ -   epoch 3 step 26700 loss 2.1822
10/19/2022 03:16:09 - INFO - __main__ -   epoch 3 step 26800 loss 2.1744
10/19/2022 03:16:21 - INFO - __main__ -   epoch 3 step 26900 loss 2.1741
10/19/2022 03:16:32 - INFO - __main__ -   epoch 3 step 27000 loss 2.1726
10/19/2022 03:16:44 - INFO - __main__ -   epoch 3 step 27100 loss 2.1937
10/19/2022 03:16:56 - INFO - __main__ -   epoch 3 step 27200 loss 2.2044
10/19/2022 03:17:07 - INFO - __main__ -   epoch 3 step 27300 loss 2.194
10/19/2022 03:17:19 - INFO - __main__ -   epoch 3 step 27400 loss 2.1781
10/19/2022 03:17:30 - INFO - __main__ -   epoch 3 step 27500 loss 2.1847
10/19/2022 03:17:42 - INFO - __main__ -   epoch 3 step 27600 loss 2.1969
10/19/2022 03:17:53 - INFO - __main__ -   epoch 3 step 27700 loss 2.173
10/19/2022 03:18:05 - INFO - __main__ -   epoch 3 step 27800 loss 2.1969
10/19/2022 03:18:17 - INFO - __main__ -   epoch 3 step 27900 loss 2.1679
10/19/2022 03:18:28 - INFO - __main__ -   epoch 3 step 28000 loss 2.1597
10/19/2022 03:18:40 - INFO - __main__ -   epoch 3 step 28100 loss 2.1652
10/19/2022 03:18:51 - INFO - __main__ -   epoch 3 step 28200 loss 2.1607
10/19/2022 03:19:03 - INFO - __main__ -   epoch 3 step 28300 loss 2.2059
10/19/2022 03:19:14 - INFO - __main__ -   epoch 3 step 28400 loss 2.2194
10/19/2022 03:19:26 - INFO - __main__ -   epoch 3 step 28500 loss 2.1866
10/19/2022 03:19:38 - INFO - __main__ -   epoch 3 step 28600 loss 2.1993
10/19/2022 03:19:49 - INFO - __main__ -   epoch 3 step 28700 loss 2.2095
10/19/2022 03:20:01 - INFO - __main__ -   epoch 3 step 28800 loss 2.2019
10/19/2022 03:20:12 - INFO - __main__ -   epoch 3 step 28900 loss 2.1422
10/19/2022 03:20:24 - INFO - __main__ -   epoch 3 step 29000 loss 2.2221
10/19/2022 03:20:35 - INFO - __main__ -   epoch 3 step 29100 loss 2.1774
10/19/2022 03:20:47 - INFO - __main__ -   epoch 3 step 29200 loss 2.1836
10/19/2022 03:20:59 - INFO - __main__ -   epoch 3 step 29300 loss 2.1817
10/19/2022 03:21:10 - INFO - __main__ -   epoch 3 step 29400 loss 2.1962
10/19/2022 03:21:22 - INFO - __main__ -   epoch 3 step 29500 loss 2.1865
10/19/2022 03:21:34 - INFO - __main__ -   epoch 3 step 29600 loss 2.2139
10/19/2022 03:21:45 - INFO - __main__ -   epoch 3 step 29700 loss 2.1778
10/19/2022 03:21:57 - INFO - __main__ -   epoch 3 step 29800 loss 2.182
10/19/2022 03:22:08 - INFO - __main__ -   epoch 3 step 29900 loss 2.1864
10/19/2022 03:22:20 - INFO - __main__ -   epoch 3 step 30000 loss 2.1507
10/19/2022 03:22:31 - INFO - __main__ -   epoch 3 step 30100 loss 2.193
10/19/2022 03:22:43 - INFO - __main__ -   epoch 3 step 30200 loss 2.1951
10/19/2022 03:22:55 - INFO - __main__ -   epoch 3 step 30300 loss 2.1867
10/19/2022 03:23:06 - INFO - __main__ -   epoch 3 step 30400 loss 2.2037
10/19/2022 03:23:18 - INFO - __main__ -   epoch 3 step 30500 loss 2.2028
10/19/2022 03:23:29 - INFO - __main__ -   epoch 3 step 30600 loss 2.1556
10/19/2022 03:23:41 - INFO - __main__ -   epoch 3 step 30700 loss 2.1622
10/19/2022 03:23:53 - INFO - __main__ -   epoch 3 step 30800 loss 2.1954
10/19/2022 03:24:04 - INFO - __main__ -   epoch 3 step 30900 loss 2.1993
10/19/2022 03:24:16 - INFO - __main__ -   epoch 3 step 31000 loss 2.1894
10/19/2022 03:24:27 - INFO - __main__ -   epoch 3 step 31100 loss 2.1865
10/19/2022 03:24:39 - INFO - __main__ -   epoch 3 step 31200 loss 2.2273
10/19/2022 03:24:50 - INFO - __main__ -   epoch 3 step 31300 loss 2.1595
10/19/2022 03:25:02 - INFO - __main__ -   epoch 3 step 31400 loss 2.169
10/19/2022 03:25:11 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:25:11 - INFO - __main__ -     Num examples = 13914
10/19/2022 03:25:11 - INFO - __main__ -     Batch size = 256
10/19/2022 03:25:35 - INFO - __main__ -     eval_ppl = 16.21729
10/19/2022 03:25:35 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 03:28:22 - INFO - __main__ -     bleu-4 = 17.76 
10/19/2022 03:28:22 - INFO - __main__ -     ********************
10/19/2022 03:28:25 - INFO - __main__ -   epoch 4 step 31500 loss 2.1581
10/19/2022 03:28:37 - INFO - __main__ -   epoch 4 step 31600 loss 2.0663
10/19/2022 03:28:48 - INFO - __main__ -   epoch 4 step 31700 loss 2.0322
10/19/2022 03:29:00 - INFO - __main__ -   epoch 4 step 31800 loss 1.9993
10/19/2022 03:29:11 - INFO - __main__ -   epoch 4 step 31900 loss 2.0224
10/19/2022 03:29:23 - INFO - __main__ -   epoch 4 step 32000 loss 2.041
10/19/2022 03:29:35 - INFO - __main__ -   epoch 4 step 32100 loss 2.0476
10/19/2022 03:29:46 - INFO - __main__ -   epoch 4 step 32200 loss 2.0535
10/19/2022 03:29:58 - INFO - __main__ -   epoch 4 step 32300 loss 2.037
10/19/2022 03:30:09 - INFO - __main__ -   epoch 4 step 32400 loss 2.008
10/19/2022 03:30:21 - INFO - __main__ -   epoch 4 step 32500 loss 2.0624
10/19/2022 03:30:33 - INFO - __main__ -   epoch 4 step 32600 loss 2.0491
10/19/2022 03:30:44 - INFO - __main__ -   epoch 4 step 32700 loss 2.0519
10/19/2022 03:30:56 - INFO - __main__ -   epoch 4 step 32800 loss 2.0269
10/19/2022 03:31:07 - INFO - __main__ -   epoch 4 step 32900 loss 2.04
10/19/2022 03:31:19 - INFO - __main__ -   epoch 4 step 33000 loss 2.0694
10/19/2022 03:31:31 - INFO - __main__ -   epoch 4 step 33100 loss 2.0231
10/19/2022 03:31:42 - INFO - __main__ -   epoch 4 step 33200 loss 2.0374
10/19/2022 03:31:54 - INFO - __main__ -   epoch 4 step 33300 loss 2.0505
10/19/2022 03:32:06 - INFO - __main__ -   epoch 4 step 33400 loss 2.0364
10/19/2022 03:32:17 - INFO - __main__ -   epoch 4 step 33500 loss 2.041
10/19/2022 03:32:29 - INFO - __main__ -   epoch 4 step 33600 loss 2.0592
10/19/2022 03:32:40 - INFO - __main__ -   epoch 4 step 33700 loss 2.0239
10/19/2022 03:32:52 - INFO - __main__ -   epoch 4 step 33800 loss 2.0549
10/19/2022 03:33:04 - INFO - __main__ -   epoch 4 step 33900 loss 2.0556
10/19/2022 03:33:15 - INFO - __main__ -   epoch 4 step 34000 loss 2.0946
10/19/2022 03:33:27 - INFO - __main__ -   epoch 4 step 34100 loss 2.0273
10/19/2022 03:33:39 - INFO - __main__ -   epoch 4 step 34200 loss 2.0438
10/19/2022 03:33:50 - INFO - __main__ -   epoch 4 step 34300 loss 2.0658
10/19/2022 03:34:02 - INFO - __main__ -   epoch 4 step 34400 loss 2.0322
10/19/2022 03:34:13 - INFO - __main__ -   epoch 4 step 34500 loss 2.0397
10/19/2022 03:34:25 - INFO - __main__ -   epoch 4 step 34600 loss 2.0279
10/19/2022 03:34:37 - INFO - __main__ -   epoch 4 step 34700 loss 2.0805
10/19/2022 03:34:48 - INFO - __main__ -   epoch 4 step 34800 loss 2.0337
10/19/2022 03:35:00 - INFO - __main__ -   epoch 4 step 34900 loss 2.0761
10/19/2022 03:35:11 - INFO - __main__ -   epoch 4 step 35000 loss 2.0729
10/19/2022 03:35:23 - INFO - __main__ -   epoch 4 step 35100 loss 2.0448
10/19/2022 03:35:35 - INFO - __main__ -   epoch 4 step 35200 loss 2.0649
10/19/2022 03:35:46 - INFO - __main__ -   epoch 4 step 35300 loss 2.0618
10/19/2022 03:35:58 - INFO - __main__ -   epoch 4 step 35400 loss 2.0785
10/19/2022 03:36:09 - INFO - __main__ -   epoch 4 step 35500 loss 2.0344
10/19/2022 03:36:21 - INFO - __main__ -   epoch 4 step 35600 loss 2.0684
10/19/2022 03:36:33 - INFO - __main__ -   epoch 4 step 35700 loss 2.0572
10/19/2022 03:36:44 - INFO - __main__ -   epoch 4 step 35800 loss 2.0752
10/19/2022 03:36:56 - INFO - __main__ -   epoch 4 step 35900 loss 2.0676
10/19/2022 03:37:07 - INFO - __main__ -   epoch 4 step 36000 loss 2.0831
10/19/2022 03:37:19 - INFO - __main__ -   epoch 4 step 36100 loss 2.0604
10/19/2022 03:37:31 - INFO - __main__ -   epoch 4 step 36200 loss 2.0865
10/19/2022 03:37:42 - INFO - __main__ -   epoch 4 step 36300 loss 2.0407
10/19/2022 03:37:54 - INFO - __main__ -   epoch 4 step 36400 loss 2.0545
10/19/2022 03:38:05 - INFO - __main__ -   epoch 4 step 36500 loss 2.0703
10/19/2022 03:38:17 - INFO - __main__ -   epoch 4 step 36600 loss 2.0436
10/19/2022 03:38:28 - INFO - __main__ -   epoch 4 step 36700 loss 2.0893
10/19/2022 03:38:40 - INFO - __main__ -   epoch 4 step 36800 loss 2.0735
10/19/2022 03:38:52 - INFO - __main__ -   epoch 4 step 36900 loss 2.0544
10/19/2022 03:39:03 - INFO - __main__ -   epoch 4 step 37000 loss 2.0841
10/19/2022 03:39:15 - INFO - __main__ -   epoch 4 step 37100 loss 2.0923
10/19/2022 03:39:26 - INFO - __main__ -   epoch 4 step 37200 loss 2.0578
10/19/2022 03:39:38 - INFO - __main__ -   epoch 4 step 37300 loss 2.0474
10/19/2022 03:39:49 - INFO - __main__ -   epoch 4 step 37400 loss 2.0415
10/19/2022 03:40:01 - INFO - __main__ -   epoch 4 step 37500 loss 2.0677
10/19/2022 03:40:13 - INFO - __main__ -   epoch 4 step 37600 loss 2.0492
10/19/2022 03:40:24 - INFO - __main__ -   epoch 4 step 37700 loss 2.063
10/19/2022 03:40:36 - INFO - __main__ -   epoch 4 step 37800 loss 2.056
10/19/2022 03:40:47 - INFO - __main__ -   epoch 4 step 37900 loss 2.0718
10/19/2022 03:40:59 - INFO - __main__ -   epoch 4 step 38000 loss 2.0938
10/19/2022 03:41:10 - INFO - __main__ -   epoch 4 step 38100 loss 2.1065
10/19/2022 03:41:22 - INFO - __main__ -   epoch 4 step 38200 loss 2.039
10/19/2022 03:41:34 - INFO - __main__ -   epoch 4 step 38300 loss 2.0672
10/19/2022 03:41:45 - INFO - __main__ -   epoch 4 step 38400 loss 2.0804
10/19/2022 03:41:57 - INFO - __main__ -   epoch 4 step 38500 loss 2.0397
10/19/2022 03:42:08 - INFO - __main__ -   epoch 4 step 38600 loss 2.0618
10/19/2022 03:42:20 - INFO - __main__ -   epoch 4 step 38700 loss 2.0588
10/19/2022 03:42:31 - INFO - __main__ -   epoch 4 step 38800 loss 2.0774
10/19/2022 03:42:43 - INFO - __main__ -   epoch 4 step 38900 loss 2.0663
10/19/2022 03:42:55 - INFO - __main__ -   epoch 4 step 39000 loss 2.078
10/19/2022 03:43:06 - INFO - __main__ -   epoch 4 step 39100 loss 2.0852
10/19/2022 03:43:18 - INFO - __main__ -   epoch 4 step 39200 loss 2.0878
10/19/2022 03:43:29 - INFO - __main__ -   epoch 4 step 39300 loss 2.0607
10/19/2022 03:43:35 - INFO - __main__ -   
***** Running evaluation *****
10/19/2022 03:43:35 - INFO - __main__ -     Num examples = 13914
10/19/2022 03:43:35 - INFO - __main__ -     Batch size = 256
10/19/2022 03:43:58 - INFO - __main__ -     eval_ppl = 17.09659
10/19/2022 03:43:58 - INFO - __main__ -     ********************
Total: 1000
10/19/2022 03:46:42 - INFO - __main__ -     bleu-4 = 17.93 
10/19/2022 03:46:42 - INFO - __main__ -     ********************
  0%|          | 0/59 [00:00<?, ?it/s]  2%|▏         | 1/59 [00:37<36:37, 37.89s/it]  3%|▎         | 2/59 [01:15<35:54, 37.80s/it]  5%|▌         | 3/59 [01:58<37:21, 40.04s/it]  7%|▋         | 4/59 [02:42<38:16, 41.75s/it]  8%|▊         | 5/59 [03:24<37:41, 41.89s/it] 10%|█         | 6/59 [04:08<37:39, 42.64s/it] 12%|█▏        | 7/59 [04:48<35:58, 41.51s/it] 14%|█▎        | 8/59 [05:26<34:33, 40.65s/it] 15%|█▌        | 9/59 [06:14<35:41, 42.83s/it] 17%|█▋        | 10/59 [06:58<35:18, 43.24s/it] 19%|█▊        | 11/59 [07:43<34:53, 43.61s/it] 20%|██        | 12/59 [08:24<33:31, 42.80s/it] 22%|██▏       | 13/59 [09:02<31:50, 41.53s/it] 24%|██▎       | 14/59 [09:42<30:44, 40.99s/it] 25%|██▌       | 15/59 [10:23<30:09, 41.12s/it] 27%|██▋       | 16/59 [11:04<29:23, 41.01s/it] 29%|██▉       | 17/59 [11:46<28:57, 41.37s/it] 31%|███       | 18/59 [12:29<28:31, 41.75s/it] 32%|███▏      | 19/59 [13:12<28:02, 42.07s/it] 34%|███▍      | 20/59 [13:53<27:16, 41.95s/it] 36%|███▌      | 21/59 [14:33<26:10, 41.32s/it] 37%|███▋      | 22/59 [15:16<25:48, 41.85s/it] 39%|███▉      | 23/59 [15:55<24:26, 40.74s/it] 41%|████      | 24/59 [16:36<23:54, 40.99s/it] 42%|████▏     | 25/59 [17:26<24:41, 43.57s/it] 44%|████▍     | 26/59 [18:11<24:09, 43.94s/it] 46%|████▌     | 27/59 [18:47<22:14, 41.72s/it] 47%|████▋     | 28/59 [19:30<21:44, 42.07s/it] 49%|████▉     | 29/59 [20:10<20:47, 41.60s/it] 51%|█████     | 30/59 [20:51<20:00, 41.39s/it] 53%|█████▎    | 31/59 [21:34<19:31, 41.83s/it] 54%|█████▍    | 32/59 [22:15<18:37, 41.39s/it] 56%|█████▌    | 33/59 [22:55<17:46, 41.00s/it] 58%|█████▊    | 34/59 [23:36<17:11, 41.24s/it] 59%|█████▉    | 35/59 [24:18<16:31, 41.31s/it] 61%|██████    | 36/59 [25:01<15:58, 41.68s/it] 63%|██████▎   | 37/59 [25:41<15:06, 41.21s/it] 64%|██████▍   | 38/59 [26:20<14:16, 40.79s/it] 66%|██████▌   | 39/59 [26:59<13:23, 40.18s/it] 68%|██████▊   | 40/59 [27:42<12:57, 40.94s/it] 69%|██████▉   | 41/59 [28:22<12:10, 40.58s/it] 71%|███████   | 42/59 [29:04<11:39, 41.14s/it] 73%|███████▎  | 43/59 [29:45<10:58, 41.18s/it] 75%|███████▍  | 44/59 [30:25<10:11, 40.78s/it] 76%|███████▋  | 45/59 [31:09<09:42, 41.63s/it] 78%|███████▊  | 46/59 [31:49<08:56, 41.23s/it] 80%|███████▉  | 47/59 [32:29<08:08, 40.75s/it] 81%|████████▏ | 48/59 [33:05<07:14, 39.51s/it] 83%|████████▎ | 49/59 [33:46<06:38, 39.83s/it] 85%|████████▍ | 50/59 [34:26<05:59, 39.91s/it] 86%|████████▋ | 51/59 [35:06<05:19, 39.93s/it] 88%|████████▊ | 52/59 [35:45<04:38, 39.74s/it] 90%|████████▉ | 53/59 [36:31<04:09, 41.64s/it] 92%|█████████▏| 54/59 [37:11<03:25, 41.14s/it] 93%|█████████▎| 55/59 [37:51<02:42, 40.62s/it] 95%|█████████▍| 56/59 [38:29<01:59, 40.00s/it] 97%|█████████▋| 57/59 [39:07<01:18, 39.37s/it] 98%|█████████▊| 58/59 [39:49<00:40, 40.17s/it]100%|██████████| 59/59 [40:00<00:00, 31.49s/it]100%|██████████| 59/59 [40:00<00:00, 40.69s/it]
Total: 14918
10/19/2022 04:26:58 - INFO - __main__ -     bleu-4 = 19.36 
10/19/2022 04:26:58 - INFO - __main__ -     ********************
10/19/2022 04:26:59 - INFO - utils -   saved dataset in saved_models/code_sum/unixcoder/partial_freezing/python/freeze_bottom_6_layers/20221019021023/result.jsonl
